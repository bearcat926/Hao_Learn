# 第一部分 Hadoop基础知识


## 第1章 初识 Hadoop

Hadoop 为我们提供了一个可靠的且可扩展的存储和分析平台。此外，由于 Hadoop 运行在商用软件上且是开源的，因而可以说 Hadoop 的使用成本是在可承受范围内的。

要对多个硬盘中的数据并行进行读写数据，有两个问题要解决：
1. 硬件故障问题。
解决方式：复制（replication）-> 系统保存数据的复本（replica） ，一旦有系统发生鼓掌，就可以使用另外保存的复本。冗余硬盘阵列（RAID）就是按这个原理实现的。

2. 大多数分析任务需要以某种方式结合大部分数据来共同完成分析，各种分布式系统允许结合不同来源的数据进行分析，但保证其正确性是一个非常大的挑战。MapReduce 提出一个编程模型，抽象出这些硬盘读写问题并将其转换为对一个数据集的计算。

MapReduce 是一个批量查询处理器，能够在合理的时间范围内处理针对整个数据集的动态查询。从 MapReduce 的所有长处来看，它基本上是一个批处理系统，并不适合交互式分析，更适合离线使用场景。

第一个提供在线访问的组件是HBase，一种使用 HDFS 做底层存储的键值存储模型。HBase 不仅提供对单行的在线读写访问，还提供对数据块读写的批处理。

Hadoop 2 中 YARN（Yet Another Resource Negotiator）的出现意味着 Hadoop 有了新处理模型，它是一个集群资源管理系统，允许任何一个分布式程序（不仅仅是 MapReduce）基于 Hadoop 集群的数据而运行。

Interactive SQL（交互式 SQL）：利用 MapReduce 进行分发并使用一个分布式查询引擎，使得在 Hadoop 上获得 SQL 查询低延迟响应的同时还能保持对大数据集规模的可扩展性。

Iterative Processing（迭代处理）：许多算法自身具有迭代性，因此和那种每次迭代都从硬盘加载的方式相比，这种在内存中保存每次中间结果集的方式更加高效。但MapReduce 的架构不允许这样。

Stream Processing（流处理）：流系统，例如 Storm，Spark Streaming 或 Samza 使得在无边界数据流上运行实时、分布式的计算，并向 Hadoop 存储系统或外部系统发布结果成为可能。

Search（搜索）：Solr 搜索平台能够在 Hadoop 集群上运行，当文档加 HDFS 后就可对其进行索引，且根据 HDFS 中存储的索引为搜索查询提供服务。

为什么不能用配有大量硬盘的数据库来进行大规模数据分析？为什么需要Hadoop？
计算机硬盘的发展趋势：寻址时间的提升远远不敌传输速率的提升。寻址是将磁头移动到特定硬盘位置进行读写操作的过程，它导致了硬盘操作的延迟，而传输速率取决于硬盘的带宽。

![1566894063310](E:\git_repo\Hao_Learn\2019\8\img\1566894063310.png)

Hadoop 和关系型数据库的另一个区别在于它们所操作的数据集的结构化程度。

结构化数据（structured data）是具有既定格式的实体化数据，如 XML 文档或满足特定预定义格式的数据库表。这是 RDBMS 包括的内容。

半结构化数据（semi-structured data）比较松散，虽然可能有格式，但经常被忽略，所以它只能作为对数据结构的一般性指导。例如电子表格。

非结构化数据（unstructured data）没有什么特别的内部结构。例如纯文本或图像数据。Hadoop 对非结构化或半结构化数据非常有效，因为他是在处理数据时才对数据进行解释（即所谓的“读时模式”）。这种模式在提供灵活性的同时避免了 RDBMS 数据加载阶段带来的高开销，因为在 Hadoop 中仅仅是一个文件拷贝系统。

关系型数据往往是规范的（normalized），以保持其数据的完整性且不含冗余。规范给 Hadoop 处理带来了问题，因为它使记录读取成为非本地操作，而 Hadoop 的核心假设之一偏偏就是可以进行（高速的）流读写操作。

Web 服务器日志是典型的非规范化数据记录，这也是Hadoop 非常适用于分析各种日志文件的原因之一。注意，Hadoop 也能够做连接（join）操作，只不过这种操作没有在关系型数据库中用的多。

MapReduce 以及 Hadoop 中其他的处理模型是可以随着数据规模线性伸缩的。对数据分区后，函数原语（如 map 和 reduce）能够在各个分区上并行工作。这意味着，如果输入的数据量是原来的两倍，那么作业的运行时间也需要两倍。但如果集群规模扩展为原来的两倍，那么作业的运行速度却仍然与原来一样快。SQL 查询一般不具备该特性。

Hadoop 尽量在计算节点上存储数据，以实现数据的本地快速访问。数据本地化（data locality）特性是 Hadoop 数据处理的核心，并因此而获得良好的性能。意识到网络带宽是数据中心环境最珍贵的资源（到处复制数据很容易耗尽网络带宽）之后，Hadoop 通过显式网络拓扑结构在保留网络带宽，这种排列方式并没有降低 Hadoop 对计算密集型数据进行分析的能力。

MapReduce 有三大设计目标：
1. 为只需要短短几分钟或几个小时就可以完成的作业提供服务；
2. 运行于同一个内部有高速网络连接的数据中心内；
3. 数据中心内的计算机都是可靠的、专门的硬件。

Hadoop 是 Apache Lucene 创始人 Doug Cutting创建的，Lucene 是一个应用广泛的文本搜索系统库。Hadoop 起源于开源网络搜索引擎 Apache Nutch，后者本身也是 Lucene 项目的一部分。

## 第2章 关于MapReduce

MapReduce 是一种可用于数据处理的编程模型。该模型比较简单，但要想要写出有用的程序却不太容易。

MapReduce 程序本质上是并行运行的，因此可以将大规模的数据分析任务分发给任何一个拥有足够多机器的数据中心。

MapReduce 任务过程分为两个处理阶段：map 阶段和 reduce 阶段。每阶段都以键值对作为输入和输出，其类型由程序员来选择。程序员还需要写两个函数：map 函数和 reduce 函数。

p47



![1566899549356](E:\git_repo\Hao_Learn\2019\8\img\1566899549356.png)

![1566899515660](E:\git_repo\Hao_Learn\2019\8\img\1566899519101.png)