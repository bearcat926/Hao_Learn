# 第一章 计算机基础

## 1.1 走进0与1的世界

#### 为何负数不断地无符号向右移动的最小值是1呢？

在实际编程中，位移运算仅作用于整型（32 位）和长整型（64 位）数上，假如在整型数上移动的位数是32 位，**无论是否带符号位以及移动方向，均为本身**。因为移动的位数是个mod 32 的结果，即 `35 >> 1` 与 `35 >> 33` 是一样的结果。如果是长整型， mod 64，即 `35 << 1` 与`35 << 65`的结果是一样的。负数在无符号往右移动 63 位时，除最右边为1， 左边均为0，达到最小值1，如果 >>> 64，则为其原数值本身。

```java
public class Test{

	public static void main(String[] args) {
		int a = 35;
		int b = -35;

		System.out.println("==========正数============");
		System.out.println(a >>> 1);

		System.out.println(a >>> 27);
		System.out.println(a >>> 28);
		System.out.println(a >>> 29);
		System.out.println(a >>> 30);
		System.out.println(a >>> 31);
		System.out.println(a >>> 32);
		System.out.println(a >>> 33);
		System.out.println("==========负数============");
		System.out.println(b >>> 1);

		System.out.println(b >>> 27);
		System.out.println(b >>> 28);
		System.out.println(b >>> 29);
		System.out.println(b >>> 30);
		System.out.println(b >>> 31);
		System.out.println(b >>> 32);
		System.out.println(b >>> 33);
	}
	
}
```

结果：

```
==========正数============
17	//1
0	//27
0
0
0
0	//31
35	//32
17
==========负数============
2147483630	//1
31	//27
15
7
3
1	//31
-35	//32
2147483630
```

#### 异或运算 ^

异或运算没有短路功能，一般在哈希算法中用于离散哈希值，对应的位上不一样才是1。

## 1.2 浮点数

#### 浮点数表示

当前业界流行的浮点数标准是 `IEEE754` ，该标准规定了4种浮点数类型：单精度、双精度、延伸单精度、延伸双精度。前两种类型是最常用的。

**浮点数无法表示零值。**

范围：

| 精度       | 字节数 | 正数取值范围             | 负数取值范围             |
| ---------- | ------ | ------------------------ | ------------------------ |
| 单精度类型 | 4      | `1.4e-45 至 3.4e+38`     | `-3.4e+38 至 -1.4e-45`   |
| 双精度类型 | 8      | `4.9e-324 至 1.798e+308` | `1.798e+308 至 4.9e-324` |

#### 阶码位

IEEE754 标准规定阶码位存储的是指数对应的移码，而不是指数的原码或补码。

移码是将一个真值在数轴上正向平移一个偏移量之后得到的，即 [x]~移~ = x + 2^n-1^ （n为x的二进制位数，含符号位）。移码的几何意义是把真值映射到一个正数域，其特点是可以直观地反映两个真值的大小，即移码大的真值也大。

> 真值 = 阶码 - （2^n-1^ - 1）

#### 为什么偏移值为2^n-1^ - 1 而不是 2^n-1 呢？

因为8个二进制位能表示指数的取值范围为 [-128,127] ，现在将指数变成移码表示，即将区间 [-128,127] 正向平移到正数域，区间里的每个数都需要加上 128 ，从而得到阶码范围为[0,255 ] 。

由于计算机规定阶码全为 0 或全为 1 两种情况被当作特殊值处理（全 0 被认为是机器零，全 1 被认为是无穷大），去除这两个特殊值，阶码的取值范围变成了 [1,254] 。

如果偏移量不变仍为128 的话，则根据换算关系公式 [x]~阶~ = x + 128 得到指数的范围变成[-127,126]，指数最大只能取到 126 ，显然会缩小浮点数能表示的取值范围。

所以 IEEE754 标准规定单精度的阶码偏移量为 2^n-1^ - 1 （即 127 ），这样能表示的指数范围为[-126,127]，指数最大值能取到 127。

0**111-1111-0**111-1111-1111-1111-1111-1111

为了节约存储空间，将符合规格化位数的首个1省略，所以尾数表面上是23位，却表示了24位二进制数。

#### 加减运算

对两个采用科学计数法表示的数做加减法运算时，为了让小数点对齐就需要确保指数一样。

1. 零值检测。 
	检查参加运算的两个数中是否存在为 0 的数（ 0  在浮点数是一种规定，即阶码与尾数全为 0 ），因为浮点数运算过程比较复杂，如果其中一个数为 0,可以直接得出结果。
2. 对阶操作。 
	通过比较阶码的大小判断小数点位置是否对齐。IEEE754 规定对阶的移动方向为向右移动，即选择阶码小的数进行操作。
3. 尾数求和。
4. 结果规格化。
	如果运算的结果仍然满足规格化形式，则无须处理，否则需要通过尾数位的向左或右移动调整达到规格化形式。尾数位向右移动称为右规，反之称为左规。
5. 结果舍入。
	在对阶过程或右规时，尾数需要右移，最右端被移出的位会被丢弃， 从而导致结果精度的损失。为了减少这种精度的损失，先将移出的这部分数据保存起来，称为保护位，等到规格化后再根据保护位进行舍入处理。

#### 浮点数使用

在使用浮点数时推荐使用**双精度**，使用单精度由于表示区间的限制 ，计算结果会出现微小的误差。
1. 在要求绝对精确表示的业务场景下，比如金融行业的货币表示，推荐使用整型存储其最小单位的值，展示时可以转换成该货币的常用单位，比如人民币使用分存储，美元使用美分存储。
2. 在要求精确表示小数点 n 位的业务场景下，比如圆周率要求存储小数点后 1000 位数字，使用单精度和双精度浮点数类型保存是难以做到的，这时推荐采用数组保存小数部分的数据。
3. 在比较浮点数时，由于存在误差，往往会出现意料之外的结果，所以禁止通过判断两个浮点数是否相等来控制某些业务流程。
4. 在数据库中保存小数时，推荐使用 `decimal` 类型，禁止使用 float 类型和 double 类型。因为这两种类型在存储的时候，存在精度损失的问题。

## 1.3 字符集与乱码

实现 Unicode 的编码格式有三种：UTF-8、UTF-16、UTF-32，UTF ( Unicode Transformation Format ）即Unicode 字符集转换格式，可以理解为对Unicode 的压缩方式。根据二八原则，常用文字只占文字总数的 20% 左右。

在日常开发中，字符集如果不兼容则会造成乱码。

乱码的出现场景并不止于编码环境中，还有网页展示、文本转换、文件读取等。数据流从底层数据库到应用层，到Web 服务器，再到客户端显示，每位开发工程师都会碰到字符乱码的问题，排查起来是一个比较长的链路。

数据库是存储字符之源，在不同层次上都能够设置独立的字符集，如服务器级别、 schema 级别、表级别甚至列级别。为了减少麻烦，所有情况下的字符集设置最好是一致的。

## 1.4 CPU与内存

越往 CPU 核心靠近，存储越贵，速度越快。越往下，存储越便宜、速度越慢，当然容量也会更大。
程序员们最害怕的 OOM（Out Of Memory）通常来源于由于不恰当的编码方式而导致内存的资源耗尽 ，虽然现代内存的容量已经今非昔比，但仍然是可以在秒级内耗尽所有内存资源的。

内存的抽象就是线性空间内的字节数组，通过下标访问某个特定位置的数据，比如 C 语言使用 malloc() 进行内存的分配，然后使用指针进行内存的读与写；而以 Java 为代表的编程语言，内存就交给 JVM 进行自动分配与释放，这个过程称为垃圾回收机制。虽然垃圾回收机制能为程序员减负，但如果不加节制的话，同样会耗尽内存资源。

## 1.5 TCP / IP

#### 概述

TCP/IP ( Transmission Control Protocol I Internet Protocol ）中文译为传输控制协议／因特网互联协议，这个大家族里的其他知名协议还有 HTTP, HTTPS、 FTP、SMTP、UDP、 ARP、PPP、IEEE 802.x 等。它是当前流行的网络传输协议框架，从严格意义上讲它是一个协议族，因为 TCP、IP 是其中最为核心的协议，所以就把该协议族称为 TCP/IP 。

而另一个是耳熟能详的 ISO/OSI 的七层传输协议，其中 OSI( Open System Interconnection ）的出发点是想设计出计算机世界通用的网络通信基本框架，它已经被淘汰。

![1565492275741](E:\git_repo\Hao_Learn\2019\8\img\1565492275741.png)

- 链路层：单个0、1 是没有意义的，链路层以字节为单位把 0 与 1 进行分组，  定义数据帧，写入源和目标机器的物理地址、数据、校验位来传输数据。

![1565492513881](E:\git_repo\Hao_Learn\2019\8\img\1565492513881.png)

MAC 地址长 6个字节共 48 位，通常使用十六进制数表示。使用 ifconfig -a 命令即可看到 MAC 地址。MAC地址的前 24 位（3个字节）由管理机构统一分配，后24 位由厂商自己分配，保证网卡全球唯一。

- 网络层： 根据 IP 定义网络地址，区分网段。子网内根据ARP（Address Resolution Protocol，地址解析协议）进行 MAC 寻址，子网外进行路由转发数据包，这个数据包即 IP 数据包。
- 传输层： 数据包通过网络层发送到目标计算机后，应用程序在传输层定义逻辑端口，确认身份后，将数据包交给应用程序，实现端口到端口间通信。最典型的传输层协议是 UDP和TCP。UDP 只是在 IP 数据包上增加端口等部分信息，是面向无连接的，是不可靠传输，多用于视频通信、电话会议等（即使少一帧数据也无妨）。与之相反的TCP 是面向连接的。所谓面向连接，是一种端到端间通过失败重传机制建立的可靠数据传输方式，给人感觉是有一条固定的通路承载着数据的可靠传输。
- 应用层： 传输层的数据到达应用程序时，以某种统一规定的协议格式解读数据。比如，E-mail 在各个公司的程序界面、操作、管理方式都不一样，但是都能够读取邮件内容，是因为 SMTP （Simple Mail Transfer Protocol，简单邮件传输协议）就像传统的书信恪式一样，按规定填写邮编及收信人信息。

总结一下，程序在发送消息时，应用层按既定的协议打包数据，随后由传输层加上双方的端口号 ，由网络层加上双方的 IP 地址，由链路层加上双方的 MAC 地址，并将数据拆分成数据帧，经过多个路由器和网关后，到达目标机器。简而言之，就是按**端口 -> IP 地址 -> MAC 地址 **这样的路径进行数据的封装和发送，解包的时候反过来操作即可

#### IP 协议

IP 是面向无连接、无状态的，没有额外的机制保证发送的包是否有序到达。IP 首先规定出 IP 地址格式，该地址相当于在逻辑意义上进行了网段的划分，给每台计算机额外设置了一个唯一的详细地址。

IP 地址属于网络层，主要功能在 WLAN 内进行路由寻址，选择最佳路由。

![1565493293196](E:\git_repo\Hao_Learn\2019\8\img\1565493293196.png)

生存时间TTL（Time To Live），即数据包的生存时间 ，它是数据包可经过的最多路由器总数。TTL 初始值由源主机设置后，数据包在传输过程中每经过一个路由器，TTL 值则减 1 ，当该字段为 0 时，数据包被丢弃，并发送 ICMP 报文通知源主机，以防止源主机无休止地发送报文。这里扩展说一下 ICMP ( Internet Control Message Protocol，Internet控制报文协议 ），它是检测传输网络是否通畅、主机是否可达、路由是否可用等网络运行状态的协议。 ICMP 虽然并不传输用户数据，但是对评估网络健康状态非常重要，经常使用的 ping、tracert 命令就是基于 ICMP 检测网络状态的有力工具。

这里说明一下tracert命令，也被称为Windows路由跟踪实用程序，在cmd中使用tracert命令可以用于确定IP数据包访问目标时所选择的路径。

从左到右的5条信息分别代表了“生存时间”（每途经一个路由器结点自增1）、“三次发送的ICMP包返回时间”（共计3个，单位为毫秒ms）和“途经路由器的IP地址”（如果有主机名，还会包含主机名）。其中带有星号`*`的信息表示该次ICMP包返回时间超时。

如果在“tracert”命令后添加一个不存在的IP地址，tracert程序则会报错。

![1565493998028](E:\git_repo\Hao_Learn\2019\8\img\1565493998028.png)

IP 报文在互联网上传输时，可能要经历多个物理网络，才能从源主机到达目标主机。比如在手机上给某个 PC 端的朋友发送一个信息，经过无线网的 IEEE 802.1x 认证，转到光纤通信上，然后进入内部企业网 802.3 ，并最终到达目标 PC。由于不同硬件的物理特性不同，对数据帧的最大长度都有不同的限制，这个最大长度被称为最大传输单元，即 MTU ( Maximum Transmission Unit ）。那么在不同的物理网之间就可能需要对 IP 报文进行分片，这个工作通常由路由器负责完成。

IP是TCP／IP的基石，几平所有其他协议都建立在 IP 所提供的服务基础上进行传输，其中包括在实际应用中用于传输稳定有序数据的 TCP。

#### 既然链路层可以通过唯一的 MAC 地址找到机器，为什么还需要通过唯一的 IP 地址再来标识呢？

简单地说，在世界范围内，不可能通过广播的方式，从数以千万计的计算机里找到目标 MAC 地址的计算机而不超时。在数据投递时就需要对地址进行分层管理。

#### TCP建立连接

TCP（Transmission Control Protocol,  传输控制协议），是一种面向连接、确保数据在端到端间可靠传输的协议。面向连接是插在发送数据前，需要先建立一条虚拟的链路，然后让数据在这条链路上“流动”完成传输。为了确保数据的可靠传输，不仅需要对发出的每一个字节进行编号确认，校验每一个数据包的有效性，在出现超时情况时进行重传，还需要通过实现滑动窗口和拥塞控制等机制，避免网络状况恶化而最终影响数据传输的极端情形。每个 TCP 数据包是封装在 IP 包中的，每个 IP头的后面紧接着的是 TCP 头。

![1565535187390](E:\git_repo\Hao_Learn\2019\8\img\1565535187390.png)

协议第一行的两个端口号各占两个字节，分别表示了源机器和目标机器的端口号。这两个端口号与 IP 报头中的源 IP 地址和目标 IP 地址所组成的四元组可唯一标识一条TCP 连接。由于 TCP 是面向连接的 ，因此有服务端和客户端之分。需要服务端先在相应的端口上进行监听，准备好接收客户端发起的建立连接请求。当客户端发起第一个请求建立连接的 TCP 包时，目标机器端口就是服务端所监听的端口号。比如一些由国际组织定义的广为人知端口号一一代表 HTTP 服务的 80 端口、代表 SSH 服务的22 端口、代表 HTTPS 服务的 443 端口。可通过 netstat 命令列出机器上已建立的连接信息，其中包含唯一标识一条连接的四元组，以及各连接的状态等内容。

![1565535499323](E:\git_repo\Hao_Learn\2019\8\img\1565535499323.png)

协议第二行和第二行是序列号，各占 4 个字节。前者是指所发送数据包中数据部分第一个字节的序号，后者是指期望收到来自对方的下一个数据包中数据部分第一个字节的序号。

由于 TCP 报头中存在一些扩展字段，所以需要通过长度为 4 个 bit 的头部长度字段表示 TCP 报头的大小，这样接收方才能准确地计算出包中数据部分的开始位置。

TCP 的 FLAG 位由 6 个 bit 组成，分别代表 ACK、SYN、FIN、 URG、PSH、RST ，都以置1 表示有效。SYN ( Synchronize Sequence Numbers ）用作建立连接时的同步信号；ACK ( Acknowledgement ）用于对收到的数据进行确认，所确认的数据由确认序列号表示；FIN ( Finish ）表示后面没有数据需要发送，通常意昧着所建立的连接需要关闭了。

URG（紧急位）：设置为1时，首部中的紧急指针有效。PSH（推位）：当设置为1时，要求把数据尽快的交给应用层，不做处理，通常的数据中都会带有PSH，但URG只在紧急数据的时设置，也称“带外数据“；RST表示复位，用来异常的关闭连接。在发送RST包关闭连接时，不必等缓冲区的包都发出去（不像上面的FIN包），直接就丢弃缓存区的包发送RST包。而接收端收到RST包后，也不必发送ACK包来确认。

![1565717495945](E:\git_repo\Hao_Learn\2019\8\img\1565717495945.png)

三次握手有两个主要目的：信息对等和防止超时。先从信息对等角度来看，双方只有确定4 类信息（自己/对方的发报/收报能力），才能建立连接。再者是防止出现请求超时导致脏连接。 TTL 网络报文的生存时间往往都会超过 TCP 请求超时时间，如果两次握手就可以创建连接，传输数据并释放连接后，第一个超时的连接请求才到达 B 机器的话，B机器会以为是A 创建新连接的请求，然后确认同意创建连接。因为 A 机器的状态不是 SYN_SENT，所以直接丢弃了 B 的确认数据，以致最后只是 B 机器单方面创建连接完毕。

![1565717542453](E:\git_repo\Hao_Learn\2019\8\img\1565717542453.png)

从编程的角度， TCP 连接的建立是通过文件描述待（ File Descriptor ，fd） 完成的。通过创建套接字获得一个 fd，然后服务端和客户端需要基于所获得的 fd调用不同的函数分别进入监听状态和发起连接请求。由于 fd 的数量将决定服务端进程所能建立连接的数量 ，对于大规模分布式服务来说，当 fd 不足时就会出现 `open too many files` 错误而使得无法建立更多的连接。为此，需要注意调整服务端进程和操作系统所支持的最大文件句柄数。通过使用 `ulimit -n` 命令来查看单个进程可以打开文件句柄的数量。如果想查看当前系统各个进程产生了多少句柄，可以使用如下的命令：

>lsof -n | awk '{print $2}' | sort|uniq -c |sort -nr|more

![1565718109948](E:\git_repo\Hao_Learn\2019\8\img\1565718109948.png)

左侧列是句柄数，右侧列是进程号。

`lsof` 命令用于查看当前系统所打开 fd 的数量。在 Linux 系统中，很多资源都是以 fd 的形式进行读写的，除了提到的文件和 TCP 连接 UDP 数据报、输入输出设备等都被抽象成了 fd。

TCP 在协议层面支持 Keep Alive 功能，即隔段时间通过向对方发送数据表示连接处于健康状态。不少服务将确保连接健康的行为放到了应用层，通过定期发送心跳包检查连接的健康度。一旦心跳包出现异常不仅会主动关闭连接，还会回收与连接相关的其他用于提供服务的资源，确保系统资源最大限度地被有效利用。

#### TCP断开连接

TCP 是全双工通信，双方都能作为数据的发送方和接收方，但 TCP 连接也会有断开的时候。

![1565718820471](E:\git_repo\Hao_Learn\2019\8\img\1565718820471.png)

图中的红色字体所示的 TIME_WAIT 和 CLOSE_WAIT 分别表示主动关闭和被动关闭产生的阶段性状态，如果在线上服务器大量出现这两种状态，就会加重机器负载，也会影响有效连接的创建，因此需要进行有针对性的调优处理。

- TIME_WAIT：主动要求关闭的机器表示收到了对方的 FIN 报文，并发送出了ACK 报文，进入 TIME_WAIT 状态，等 2MSL 后即可进入到 CLOSED 状态。如果 FIN_WAIT_1 状态下，同时收到带 FIN 标志和 ACK 标志的报文时，可以直接进入 TIME_WAIT 状态，而无须经过 FIN_WAIT_2 状态。

- CLOSE_WAIT： 被动要求关闭的机器收到对方请求关闭连接的 FIN 报文，在第一次 ACK 应答后，马上进入 CLOSE_WAIT 状态。这种状态其实表示在等待关闭，并且通知应用程序发送剩余数据，处理现场信息，关闭相关资源。

在TME_WAIT 等待的 2MSL 是报文在网络上生存的最长时间，超过阈值便将报文丢弃。一般来说， MSL 大于 TTL 衰减至 0 的时间。在RFC793 中规定 MSL 为2 分钟。但是在当前的高速网络中， 2分钟的等待时间会造成资源的极大浪费，在高并发服务器上通常会使用更小的值。既然 TIME_WAIT 貌似是百害而无一利的，为何不直接关闭，进入 CLOSED 状态呢？原因有如下几点：

1. 确认被动关闭方能够顺利进入 CLOSED 状态。
	

假如最后一个 ACK 由于网络原因导致无法到达 B 机器，处于 LAST_ACK 机器通常 “自信” 地以为对方没有收到自己的 FIN+ACK 报文，所以会重发。 A 机器收到第二次的 FIN+ACK 报文，会重发一次 ACK ，并且重新计时。

2. 防止失效请求。

这样做是为了防止己失效连接的请求数据包与正常连接的请求数据包混淆而发生异常。因为 TIME_WAIT 状态无法真正释放句柄资源，在此期间，Socket 中使用的本地端口在默认情况下不能再被使用。该限制对于客户端机器来说是无所谓的，但对于高并发服务器来说，会极大地限制有效连接的创建数量，成为性能瓶颈。所以，建议将高并发服务器 TIME_WAIT 超时时间调小。

在服务器上通过变更`/etc/sysctl.conf` 文件来修改该省略值（秒）：`net.ipv4.tcp_fin_timeout = 30` （建议小于 30 秒为宜）。
修改完之后执行`/sbin/sysctl -p` 让参数生效即可。可以通过如下命令：

>netstat -n |awk '/^tcp/	{++S[$NF]}	END	{for(a in S)	print	a,	S[a] }'

查看各连接状态的计数情况，为了使数据快速生效， 2MSL 从 240 秒更改为5 秒。
在`sysctl.conf` 中还有其他连接参数也用来不断地调优服务器 TCP 连接能力，以提升服务器的有效利用率。如何快速地使连接资源被释放和复用，参数的优化往往可以取得事半功倍的效果。

TIME_WAIT 是挥手四次断开连接的尾声，如果此状态连接过多，则可以通过优化服务器参数得到解决。如果不是对方连接的异常，一般不会出现连接无法关闭的情况。但是 CLOSE_WAIT 过多很可能是程序自身的问题，比如在对方关闭连接后，程序没有检测到，或者忘记自己关闭连接。在某次故障中，外部请求出现超时的情况，当时的 Apache 服务器使用的是默认的配置方式，通过命令`netstat -ant|grep -i "443"|grep CLOSE_ WAIT|wc -l`发现在HTTPS 的 443 端口上堆积了 2.1 万个左右的CLOSE_WAIT 状态。经排查发现，原来是某程序处理完业务逻辑之后没有释放流操作，但程序一直运行正常，直到运营活动时才大量触发该业务逻辑，最终导致故障的产生。

#### 连接池

RPC 服务集群的注册中心与服务提供方、消费方之间，消息服务集群的缓存服务器和消费者服务器之间，应用后台服务器和数据库之间，都会使用**连接池**来提升性能。

数据库连接池负责分配、管理和释放连接，这是一种以内存空间换取时间的策略，能够明显地提升数据库操作的性能。但如果数据库连接管理不善，也会影响到整个应用集群的吞吐量。连接池配置错误加上**慢SQL** ，就像屋漏偏逢连夜雨，可以瞬间让一个系统进入服务超时假死宕机状态。

> 导致慢 SQL 的原因：
> 1. SQL编写问题
   >- 与索引相关的规则：
     - 字段类型转换导致不用索引，如字符串类型的不用引号，数字类型的用引号等，这有可能会用不到索引导致全表扫描；
     - mysql 不支持函数转换，所以字段前面不能加函数，否则这将用不到索引；
     - 不要在字段前面加减运算；
     - 字符串比较长的可以考虑索引一部份减少索引文件大小，提高写入效率；
     - like % 在前面用不到索引；
     - 根据联合索引的第二个及以后的字段单独查询用不到索引；
     - 不要使用 select * ；
     - 排序请尽量使用升序 ;
     - or 的查询尽量用 union 代替 （InnoDB）；
     - 复合索引高选择性的字段排在前面；
     - order by / group by 字段包括在索引当中减少排序，效率会更高。
   >     - 尽量规避大事务的 SQL，大事务的 SQL 会影响数据库的并发性能及主从同步；
     - 分页语句 limit 的问题；
     - 删除表所有记录请用 truncate，不要用 delete；
     - 不让 mysql 干多余的事情，如计算；
     - 输写 SQL 带字段，以防止后面表变更带来的问题，性能也是比较优的 ( 涉及到数据字典解析，请自行查询资料)；
     - 在 Innodb上用 select count( * )，因为 InnoDB 会存储统计信息；
     - 慎用 Order by rand()。
>2. 锁
>3. 业务实例相互干绕对 IO/CPU 资源争用
>4. 服务器硬件
>5. MYSQL BUG
>在日常开发工作中，我们可以做一些工作达到预防慢 SQL 问题，比如在上线前预先用诊断工具对 SQL 进行分析。常用的分析诊断工具有：mysql dumpslow ;  mysql profile ;  mysql explain

连接数的创建是受到服务器操作系统的`fd`（文件描述符）数量限制的。创建更多的活跃连接，就需要消耗更多的`fd`，系统默认单个进程可同时拥有 1024 个`fd`，该值虽然可以适当调整，但如果无限制地增加，会导致服务器在`fd`的维护和切换上消耗过多的精力，从而降低应用吞吐量。

在双十一的场景里，应用服务器的全链路上不论是连接池的峰值处理，还是应用之间的调用频率，都会有相关的限流措施和降级预案。

一般可以把连接池的最大连接数设置在 30 个左右，理论上还可以设置更大的值，但是 DBA（Database Adiministrator） 一般不会允许，因为往往只有出现了慢 SQL 才需要使用更多的连接数。这时候通常需要优化应用层逻辑或者创建数据库索引，而不是一昧地采用加大连接数这种治标不治本的做法。极端情况下甚至会导致数据库服务不晌应，进而影响其他业务。

从经验上来看，在数据库层面的请求应答时间必须在100ms 以内，秒级的 SQL查询通常存在巨大的性能提升空间，有如下应对方案：

 1. 建立高效且合适的索引。
 2. 排查连接资源未显式关闭的情形。
	 	要特别注意在 ThreadLocal 或流式计算中使用数据库连接的地方。
 3. 合并短的请求。
	 	根据 CPU 的空间局部性原理，对于相近的数据， CPU会一起提取到内存中。另外，合并请求也可以有效减少连接的次数。
 4. 合理拆分多个表 join 的 SQL ，若是超过三个表则禁止 join 。
	 	如果表结构建得不合理，应用逻辑处理不当，业务模型抽象有问题，那么三表 join 的数据量由于笛卡儿积操作会呈几何级数增加，所以不推荐这样的做法。另外，对于需要join 的字段，数据类型应保持绝对一致。多表关联查询时，应确保被关联的字段要有索引。
 5. 使用临时表。
	 	在不断的嵌套查询中，已经无法很好地利用现有的索引提升查询效率，所以把中间结果保存到临时表，然后重建索引，再通过临时表进行后续的数据操作。
 6. 应用层优化。
 7. 改用其他数据库。因为不同数据库针对的业务场景是不同的。
    [NoSQL数据库探讨](https://blog.csdn.net/hguisu/article/details/5748732)

## 1.6 信息安全

#### 黑害与安全

现代黑客攻击的特点是分布式、高流量、深度匿名。黑客的攻击手段十分多样，大体可分为非破坏性攻击和破坏性攻击。**非破坏性攻击**一般是为了扰乱系统的运行，使之暂时失去正常对外提供服务的能力，比如 DDoS 攻击等。**破坏性攻击**主要会造成两种后果：系统数据受损或者信息被窃取，比如 CSRF 攻击等。黑客使用的攻击手段有病毒式、洪水式、系统漏洞式等。
现今云端提供商的优势在于能提供套完整的安全解决方案。离开云端提供商 ，一个小企业要从头到尾地搭建一套安全防御体系，技术成本和资源成本将是难以承受的。所以互联网企业都要建立一套完整的信息安全体系，遵循 CIA 原则 即保密性（ Confidentiality ) ，完整性（ Integrity )，可用性（ Availability ）：

- 保密性。 对需要保护的数据（比如用户的私人信息等）进行保密操作，无论是存储还是传输，都要保证用户数据及相关资源的安全。在实际编程中，通常使用加密等手段保证数据的安全。
- 完整性。访问的数据需要是完整的，而不是缺失的或者被篡改的 不然用户访问的数据就是不正确的。在实际编写代码中，一定要保证数据的完整性，通常的做法是对数据进行签名和校验（比如 MD5和数字签名等）。
- 可用性。 服务需要是可用的。如果连服务都不可用，也就没有安全这一说了。对于这种情况通常使用访问控制、限流等手段解决。

以上三点是安全中最基本的三个要素，后面谈到的 Web 安全问题，都是围绕这三点来展开的。

#### SQL 注入

SQL 注入是注入式攻击中的常见类型，即由于未将代码与数据进行严格的隔离 ，导致在读取用户数据的时候，错误地把数据作为代码的一部分执行而导致一些安全问题。
预防手段：
1. 过滤用户输入参数中的特殊字符 ，从而降低被 SQL注入的风险。
2. 禁止通过字符串拼接的 SQL 语句 ，严恪使用参数绑定传入的 SQL 参数。
3. 合理使用数据库访问框架提供的防注入机制。

#### XSS 与 CSRF

跨站脚本攻击，即`Cross-Site Scripting` ，为了不和前端开发中层叠样式表 `CSS` 的名字冲突，简称为XSS。 XSS 是指黑客通过技术手段，向正常用户请求的 HTML 页面中插入恶意脚本，从而可以执行任意脚本。 XSS主要分为反射型 XSS 、存储型 XSS和DOM型XSS。XSS 主要用于信息窃取、破坏等目的。

跨站请求伪造（ Cross-Site Request Forgery ），简称 CSRF， 也被称为 One-click Attack，即在用户并不知情的情况下，冒充用户发起请求，在当前已经登录的 Web 应用程序上执行恶意操作，如恶意发帖、修改密码、发邮件等。

在防范 XSS 上，主要通过对用户输入数据做过滤或者转义。比如 Java 开发人员可以使用 Jsoup 框架对用户输入字符串做 XSS 过滤，或者使用框架提供的工具类对用户输入的字符串做 HTML 转义，例如 Spring 框架提供的 HtmlUtils 。前端在浏览器展示数据时，也需要使用安全的 API 展示数据，比如使用 innerText 而不是innerHTML 。

CSRF 有别于 XSS ，从攻击效果上，两者有重合的地方。从技术原理上两者有本质的不同，XSS 是在正常用户请求的 HTML 页面中执行了黑客提供的恶意代码；CSRF是黑客直接盗用用户浏览器中的登录信息，冒充用户去执行黑客指定的操作。

防范 CSRF 漏洞主要通过以下方式：
1. CSRF Token 验证，利用浏览器的同源限制，在 HTTP 接口执行前验证页面或者 Cookie 中设置的 Token ，只有验证通过才继续执行请求。
2. 人机交互 ，比如在调用上述网上银行转账接口时校验短信验证码。

XSS 问题出在用户数据没有过滤、转义；CSRF 问题出在 HTTP 接口没有防范不受信任的调用。

#### HTTPS

安全套接字层( Secure Socket Layer, SSL ）。SSL 协议工作于传输层与应用层之间，为应用提供数据的加密传输。而 HTTPS 的全称是 HTTP over SSL ，简单的理解就是在之前的 HTTP 传输上增加了 SSL 协议的加密能力。

我们可以通过对称加密算法对数据进行加密，比如 DES ，即 一个主站与用户之间可以使用相同的密钥对传输内容进行加解密。但密钥几乎没有什么保密性可言，被盗之后就会被破解。

RSA 把密码革命性地分成公钥和私钥，由于两个密钥并不相同，所以称为非对称加密。私钥是用来对公钥加密的信息、进行解密的，是需要严格保密的。公钥是对信息进行加密，任何人都可以知道，包括黑客。

非对称加密的安全性是基于大质数分解的困难性，在非对称的加密中公钥和私钥是一对大质数函数。计算两个大质数的乘积是简单的，但是这个过程的逆运算（即将这个乘积分解为两个质数）是非常困难的。而在 RSA 的算法中，从一个公钥和密文中解密出明文的难度等同于分解两个大质数的难度。因此在实际传输中，可以把公钥发给对方。一方发送信息时，使用另一方的公钥进行加密生成密文。收到密文的一方再用私钥进行解密，这样一来，传输就相对安全了。

但是非对称加密并不是完美的，它有一个很明显的缺点是加密和解密耗时长，只适合对少量数据进行处理。而且在解决了加密危机之后又产生了信任危机。

CA ( Certificate Authority）就是颁发 HTTPS 证书的组织。 HTTPS 是当前网站的主流文本传输协议，在基于 HTTPS 进行连接时，就需要数字证书。

```
访问一个 HTTPS 的网站的大致流程如下：
1. 浏览器向服务器发送请求，请求中包括浏览器支持的协议，并附带一个随机数。
2. 服务器收到请求后，选择某种非对称加密算法，把数字证书签名公钥、身份信息发送给浏览器，同时也附带一个随机数。
3. 浏览器收到后，验证证书的真实性，用服务器的公钥发送握手信息给服务器。
4. 服务器解密后，使用之前的随机数计算出一个对称加密的密钥，以此作为加密信息并发送。
5. 后续所有的信息发送都是以对称加密方式进行的。
```

传输层安全协议（ Transport Layer Security，TLS）的概念。这里先解释 TLS和SSL 的区别。 TLS 可以理解成 SSL 协议 3.0 版本的升级，所以 TLS 1.0 版本也被标识为 SSL 3.1 版本。但对于大的协议栈而言，SSL 和 TLS 并没有太大的区别，因此在 Wireshark 里，分层依然用的是安全套接字层（SSL）标识。

在整个 HTTPS 的传输过程中，主要分为两部分：首先是 HTTPS 的握手，然后是数据的传输。前者是建立一个 HTTPS 的通道，并确定连接使用的加密套件及数据传输使用的密钥。而后者主要使用密钥对数据加密并传输。

首先来看 HTTPS 是如何进行握手的，如图 1-28 所示是一个完整的 SSL 数据流和简单流程。

![1565768288645](E:\git_repo\Hao_Learn\2019\8\img\1565768288645.png)

第一，客户端发送了 Client Hello 协议的请求：在 Client Hello 中最重要的信息是 Cipher Suites 字段，这里客户端会告诉服务端自己支持哪些加密的套件。比如在这次 SSL 连接中，客户端支持的加密套件协议如图 1-29 所示。

![1565768515498](E:\git_repo\Hao_Learn\2019\8\img\1565768515498.png)

第二，服务端在收到客户端发来的 Client Hello 的请求后，会返回一系列的协议数据，并以一个没有数据内容的 Server Hello Done 结束。这些协议数据有的是单独发送，有的则是合并发送， 这里分别解释下几个比较重要的协议，如图 1-30 所示。

![1565768642195](E:\git_repo\Hao_Learn\2019\8\img\1565768642195.png)

1. Server Hell 协议。

主要告知客户端后续协议中要使用的 TLS 协议版本，这个版本主要和客户端与服务端支持的最高版本有关。比如本次确认后续的 TLS 协议版本是 TLS v1.2 ，并为本次连接分配 个会话 ID ( Session ID ）。此外，还会确认后续采用的加密套件（ Cipher Suite ）， 这里确认使用的加密套件为TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 。该加密套件的基本含义为：使用非对称协议加密 （RSA） 进行对称协议加密 （AES） 密钥的加密，并使用对称加密协议 （AES） 进行信息的加密。

2. Certificate 协议。

主要传输服务端的证书内容。

3. Server Key Exchange。

如果在 Certificate 协议中未给出客户端足够的信息，则会在 Server Key Exchange 进行补充。比如在本次连接中 Certificate 未给出证书的公钥 （Public Key）， 这个公钥的信息将会通过 Server Key Exchange 发送给客户端。

4. Certificate Request。
	这个协议是一个可选项，当服务端需要对客户端进行证书验证的时候，才会向客户端发送一个证书请求（Certificate Request）。

5. 最后以 Server Hello Done 作为结束信息，告知客户端整个 Server Hello 过程结束。

第三，客户端在收到服务端的握手信息后，根据服务端的请求，也会发送一系列的协议。

1. Certificate。

它是可选项。因为上文中服务端发送了 Certificate Request 需要对客户端进行证书验证，所以客户端要发送自己的证书信息。

2. Client Key Exchange。

它与上文中 Server Key Exchange 类似， 是对客户端 Certificate 信息的补充。

3. Certification Verity。 

对服务端发送的证书信息进行确认。

4. Change Cipher Spec。

该协议不同于其他握手协议（Handshake Protocol ），而是作为一个独立协议告知服务端，客户端已经接收之前服务端确认的加密套件，并会在后续通信中使用该加密套件进行加密。

5.  Encrypted Handshake Message。

用于客户端给服务端加密套件加密一段 Finish 的数据，用以验证这条建立起来的加解密通道的正确性。

第四，服务端在接收客户端的确认信息及验证信息后，会对客户端发送的数据进行确认，这里也分为几个协议进行回复。

1. Change Cipher Spec。
	

通过使用私钥对客户端发送的数据进行解密，并告知后续将使用协商好的加密套件进行加密传输数据。

2. Encrypted Handshake Message。

与客户端的操作相同，发送一段 Finish 的加密数据验证加密通道的正确性。

最后，如果客户端和服务端都确认加解密无误后，各自按照之前约定的 Session Secret 和 Application Data 进行加密传输。


# 第二章 面向对象

## 2.1 OOP 理念

面向过程的结构相对松散，强调如何流程化地解决问题；面向对象的思维更加内聚，强调高内聚、低藕合，先抽象模型，定义共性行为，再解决实际问题。

面向对象思维，以对象模型为核心，丰富模型的内涵，扩展模型的外延，通过模型的行为组合去共同解决某一类问题，抽象能力显得尤为重要；封装是一种对象功能内聚的表现形式，使模块之间耦合度变低，更具有维护性；继承使子类能够继承父类，获得父类的部分属性和行为，使模块更有复用性；多态使模块在复用性基础上更加有扩展性，使运行期更有想象空间。抽象是面向对象思想最基础的能力之一，正确而严谨的业务抽象和建模分析能力是后续的封装、继承、多态的基础。

#### 抽象

在面向对象的思维中，抽象分为归纳和演绎。前者是从具体到本质，从个性到共性，将一类对象的共同特征进行归一化的逻辑思维过程；后者则是从本质到具体，从共性到个性，逐步形象化的过程。在归纳的过程中，需要抽象出对象的属性和行为的共性，难度大于演绎。演绎是在已有问题解决方案的基础上，正确地找到合适的使用场景。

Java 之父 Gosling 设计的 Object 类，是任何类的默认父类，是对万事万物的抽象，是在哲学方向上进行的延伸思考，高度概括了事物的自然行为和社会行为。

|抽象问题|Object类的实现|
|------|--------|
|我是谁？|getClass() 说明本质上是谁，而 toString() 是当前职位的名片。|
|我从哪里来？|Object() 构造方法是生产对象的基本步骤，clone() 是繁殖对象的另一种方式。|
|我到哪里去？|finalize() 在对象销毁时触发的方法。|
|世界是否因你而不同？|hashCode() 和 equals() 就是判断与其他元素是否相同的一组方法。|
|与他人如何协调？|wait() 和 notify() 是对象间通信与协作的一组方法。|

clone()  方法分为浅拷贝、一般深拷贝和彻底深拷贝 。浅拷贝只复制当前对象的所有基本数据类型，以及相应的引用变量，但没有复制引用变量指向的实际对象；而彻底深拷贝是在成功 clone 一个对象之后，此对象与母对象在任何引用路径上都不存在共享的实例对象 ，即**深拷贝把所有引用变量所指向的变量都拷贝了一份**，但是引用路径递归越深，则越接近 JVM 底层对象，且发现彻底深拷贝实现难度越大。介于浅拷贝和彻底深拷贝之间的都是一般深拷贝。归根结底， 慎用 Object 的 clone() 方法来拷贝对象，因为对象的 clone() 方法默认是浅拷贝，若想实现深拷贝，则需要覆写 clone () 方法实现引用对象的深度遍历式拷贝。

随着时代的发展，当初的抽象模型部分不适用当下的技术潮流，比如 finalize()方法在 JDK9 之后直接被标记为过时方法。而 wait() 和 notify() 同步方式事实上已经被同步信号、锁、阻塞集合等取代。

#### 封装

封装是在抽象基础上决定信息是否公开，以及公开等级，核心问题是以什么样的方式暴露哪些信息。抽象是要找到属性和行为的共性，属性是行为的基本生产资料，具有一定的敏感性，不能直接对外暴露；封装的主要任务是对属性、数据、部分内部敏感行为实现隐藏。对属性的访问与修改必须通过定义的公共接口来进行，某些敏感方法或者外部不需要感知的复杂逻辑处理， 一般也会进行封装。封装使面向对象的世界变得单纯，对象之间的关系变得简单，各人自扫门前雪，耦合度变弱，有利于维护。

设计模式七大原则之一的迪米特法则就是对于封装的具体要求，即 A模块使用B 模块的某个接口行为，对 B 模块中除此行为之外的其他信息知道得尽可能少。

#### 继承

继承是面向对象编程技术的基石，允许创建具有逻辑等级结构的类体系，形成一个继承树，让软件在业务多变的客观条件下，某些基础模块可以被直接复用、间接复用或增强复用，父类的能力通过这种方式赋予子类。继承把代码变得更有层次感，更有扩展性，为多态打下语法基础。

人人都说继承是 is-a 关系，那么如何衡量当前的继承关系是否满足 is-a 关系呢？判断标准即是否符合里氏代换原则（ Liskov Substitution Principle, LSP ）。 LSP 是指任何父类能够出现的地方，子类都能够出现。在实际代码环境中，如果父类引用直接使用子类引用来代替，可以编译正确并执行，输出结果符合子类场景的预期，那么说明两个类之间符合 LSP 原则，可以使用继承关系。

继承的使用成本很低，一个关键字就可以使用别人的方法，似乎更加轻量简单。想复用别人的代码，跳至脑海的第一反应是继承它，所以继承像抗生素一样容易被滥用，我们传递的理念是谨慎使用继承，认清继承滥用的危害性，即方法污染和方法爆炸。

方法污染是指父类具备的行为，通过继承传递给子类，子类并不具备执行此行为的能力 ，比如鸟会飞，驼鸟继承鸟，发现飞不了，这就是方法污染。子类继承父类则说明子类对象可以调用父类对象的一切行为。在这样的情况下，总不能在继承时，添加注释说明哪几个父类方法不能在子类中执行，更不能覆写这些无法执行的父类方法，抛出异常，以阻止别人的调用。

方法爆炸是指继承树不断扩大，底层类拥有的方法虽然都能够执行，但是由于方法众多，其中部分方法并非与当前类的功能定位相关，很容易在实际编程中产生选择困难症。在实际故障中，因为方法爆炸，父类的某些方法签名和子类非常相似，在 IDE 中，输入`类名＋. `之后，在自动提示的极为相似的方法签名中选择错误，导致线上异常。综上所述，提倡组合优先原则来扩展类的能力，即优先采用组合或聚合的类关系来复用其他类的能力，而不是继承。

#### 多态

多态是以上述的三个面向对象特性为基础，根据运行时的实际对象类型，同一个方法产生不同的运行结果，使同一个行为具有不同的表现形式。

我们来明确两个非常容易混淆的概念 `override` 和 `overload`，`override`译成 `覆写`， 是子类实现接口，或者继承父类时，保持方法签名完全相同，实现不同的方法体，是**垂直方向**上行为的不同实现。`overload`译成`重载`，方法名称是相同的，但是参数类型或参数个数是不相同的，是**水平方向**上行为的不同实现。

多态是指在编译层面无法确定最终调用的方法体，以覆写为基础来实现面向对象特性，在运行期由 JVM 进行动态绑定，调用合适的覆写方法体来执行。重载是编译期确定方法调用，属于静态绑定，本质上重载的结果是完全不同的方法，所以本书认为多态专指覆写。严格意义上来说，多态并不是面向对象的一种特质，而是一种由继承行为衍生而来的进化能力而已。

## 2.3 类

类的定义由访问级别、类型、类名、是否抽象、是否静态、泛型标识、继承或实现关键字、父类或接口名称等组成。类的访问级别有 public 和无访问控制符，类型分 class、interface、enum。
Java 类主要由两部分组成：成员和方法。在定义 Java 类时，推荐首先定义变量，然后定义方法。由于公有方法是类的调用者和维护者最关心的方法，因此最好首屏展示；保护方法虽然只被子类关心，但也可能是模板设计模式下的核心方法，因此重要性仅次于公有方法；而私有方法对外部来说是一个黑盒实现，因此一般不需要被特别关注；最后是 gette /setter 方法，虽然它们也是公有方法，但是因为承载的信息价值较低，一般不包含业务逻辑，所以所有 getter/setter 方法须放在类最后。

#### 接口与抽象类

定义类的过程就是抽象和封装的过程，而接口与抽象类则是对实体类进行更高层次的抽象，仅定义公共行为和特征。

|语法维度|抽象类|接	口|
|------------|----------|------------|
|定义关键字|abstract|interface|
|子类继承或实现关键字|extends|implements|
|方法实现|可以有|不能有，但在JDK8及之后，允许有default实现|
|方法访问控制符|无限制|有限制，默认是public abstract类型|
|属性访问控制符|无限制|有限制，默认是public static final类型|
|静态方法|可以有|不能有，但在JDK8及之后，允许实现|
|静态/非静态代码块|可以有|不能有|
|本类型之间扩展|单继承|多继承|
|本类型之间扩展关键字|extends|extends|

抽象类在被继承时体现的是 `is-a` 关系，接口在被实现时体现的是 `can-do` 关系。与接口相比，抽象类通常是对同类事物相对具体的抽象，通常包含抽象方法、实体方法、属性变量。如果一个抽象类只有一个抽象方法，那么它就等 于一个接口。 `is-a`关系需要符合里氏代换原则；`can-do`关系要符合接口隔离原则，实现类要有能力去实现并执行接口中定义的行为。

抽象类是模板式设计，而接口是契约式设计。抽象类包含一组相对具体的特征，性格偏内向，可以存在不同版本的实现；接口是开放的，性格偏外向，它就像一份合同，定义了方法名、参数、返回值，甚至抛出异常的类型。谁都可以来实现它，但想实现它的类必须遵守这份接口约定合同。

接口是顶级的“类”，虽然关键字是 interface ，但是编译之后的字节码扩展名还`.class`。抽象类是二当家，接口位于顶层，而抽象类对各个接口进行了组合，然后实现部分接口行为，其中 AbstractCollection 是最典型的抽象类：

```java
public abstract class AbstractCollection<E> implements Collection<E> {
	//Collection 定义的抽象方法，但本类没有实现
	//Collection 接口定义的方法，size()这个方法对于链表和顺序表有不同的实现方式
	public abstract int size();
	
	//实现Collection接口的这个方法，因为对AbstractCollection的子类他们判空的方式的一致的，这就是模板式设计，对于所有他的子类,实现共同的方法体，通过多态调用到子类的具体size()实现
	public boolean isEmpty(){
		return size() == 0;
	}
}
```

Java 语言中类的继承采用单继承形式，避免继承泛滥、菱形继承、循环继承，甚至“四不像”实现类的出现。在JVM中，一个类如果有多个直接父类，那么方法的绑定机制会变得非常复杂。接口继承接口，关键字是 extends ，而不是 implements，允许多重继承，是因为接口有契约式的行为约定，没有任何具体实现和属性，某个实体类在实现多重继承后的接口时，只是说明`can do many things `。当纠结定义接口还是抽象类时，优先推荐定义为接口，遵循接口隔离原则，按某个维度划分成多个接口，然后再用抽象类去 implements 某些接口，这样做可方便后续的扩展和重构。

#### 内部类

在一个 `.java` 源文件中，只能定义一个类名与文件名完全一致的公开类，使用`public class` 关键字来修饰。但在面向对象语言中，任何一个类都可以在内部定义另外一个类 ，前者为外部类，后者为内部类。内部类本身就是类的一个属性 ，与其他属性定义方式一致。

比如，属性字段`private static String str` ，由访问控制符、是否静态、类型、变量名组成，而内部类 `private static class Inner{}`，也是按这样的顺序来定义的，类型可以为 class、enum ，甚至是 interface ，当然在内部类中定义接口是不推荐的。

内部类具体分为如下四种：

- 静态内部类，如： static class StaticInnerClass {} ;
- 成员内部类，如： private class InstancelnnerClass {} ;
- 局部内部类，定义在方法或者表达式内部；
- 匿名内部类，如： (new Thread () {} ).start() 。

无论是什么类型的内部类，都会编译成一个独立的 `.class` 文件。

![1565878774945](E:\git_repo\Hao_Learn\2019\8\img\1565878774945.png)

外部类与内部类之间使用 $ 符号分隔，匿名内部类使用数字进行编号，而方法内部类，在 类名前还有一个编号来标识是哪个方法。匿名内部类和静态内部类是比较常用的方式。而静态内部类是最常用的内部表现形式，外部可以使用 OuterClass.StaticInnerClass 直接访问，类加载与外部类在同一个阶段进行，JDK 源码中，定义包内可见静态内部类的方式很常见，这样做的好处是：作用域不会扩散到包外；可以通过`外部类 内部类`的方式直接访问；内部类可以访问外部类申的所有静态属性和方法。

```Java
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    volatile V val;
    volatile Node<K,V> next ; 
}
```

如上所示的源码是在 ConcurrentHashMap 中定义的 Node 静态内部类，用于表示一个节点数据，属于包内可见 ，包内其他集合要用到这个 Node 直接使用`ConcurrentHashMap.Node`。

仅包内可见可以阻止外部程序随意使用此类来生成对象，Node的父类 Entry 是 Map 的静态内部类，之所以可以被 Node 成功继承，是因为两个外部类同属一个包。

在 JDK 源码中，使用内部类封装某种属性和操作的方式比较常见，比如应用类加载器 Launcher的AppClassLoader, ReentrantLock中 AbstractQueuedSynchronizer 的内部类 Sync, ArrayList 中的私有静态内部类SubList。内部类中还可以定义内部类，形成多层嵌套 如在 ThreadLocal 静态内部类 ThreadLocalMap 中还定义一个内部类 Entry。

![1565879947217](E:\git_repo\Hao_Learn\2019\8\img\1565879947217.png)

#### 访问权限控制

面向对象的核心思想之一就是封装，只把有限的方法和成员公开给别人，这也是迪米特法则的内在要求，使外部调用方对方法体内的实现细节知道得尽可能少。如何实现封装呢？需要使用某些关键字来限制类外部对类内属性和方法的随意访问，这些关键字就是访问权限控制符。在在任何情况下，类外部实例化出来的对象均无法调用私有方法。

![1565880777933](E:\git_repo\Hao_Learn\2019\8\img\1565880777933.png)

无访问权限控制符仅对包内可见，但千万不要说成 default，它并非访问权限控制符的关键字 ，另外，在 JDK8 接口中引入 default 默认方法实现，更加容易混淆两者释义。

在定义类时，推荐访问控制级别从严处理：
1. 如果不允许外部直接通过 new 创建对象，构造方法必须是 private。
2. 工具类不允许有 public 或 default 构造方法。
3. 类非静态成员变量并且与子类共享，必须是 protected。
4. 类非静态成员变量并且仅在本类使用，必须是 private。
5. 类静态成员变量如果仅在本类使用，必须是 private。
6. 若是静态成员变量，必须考虑是否为 final。
7. 类成员方法只供类内部调用，必须是 private。
8. 类成员方法只对继承类公开，那么限制为 protected。

#### this 与 super

对象实例化时，至少有一条从本类出发抵达 Object 的通路，而打通这条路的两个主要工兵就是 this 和 super ，逢山开路，遇水搭桥。但是 this 和 super 往往是默默无闻的，在很多情况下可以省略，比如：

- 本类方法调用本类属性。
- 本类方法调用另一个本类方法。
- 子类构造方法隐含调用 super () 。

任何类在创建之初，都有一个默认的空构造方法，它是 super ()  的一条默认通路。构造方法的参数列表决定了调用通路的选择；如果子类指定调用父类的某个构造方法，super 就会不断往上溯源；如果没有指定，则 默认调用 super () 。**如果父类没有提供默认的构造方法，子类在继承时就会编译错误**，如果父类坚持不提供默认的无参构造方法，必须在本类的无参构造方法中使用super 方式调用父类的有参构造方法。

如果 this 和 super 指代构造方法，则必须**位于方法体的第一行**。在一个构造方法中， this 和 super **只能出现一个 ，且只能出现一次**，否则在实例化对象时，会因子类调用到多个父类构造方法而造成混乱。

由于 this 和 super 都在实例化阶段调用，所以不能在静态方法和静态代码块中使用 this 和 super 关键字。this 还可以指代当前对象，比如在同步代码块`synchronized(this){...}`中，super 并不具备此能力。但 super 也有自己的特异功能，子类覆写父类方法时，可以使用 super 调用父类同名的实例方法。

![1565965442824](E:\git_repo\Hao_Learn\2019\8\img\1565965442824.png)

#### 类关系

证明类之间没关系是一个涉及业务、架构、模块边界的问题，往往由于业务模型的抽象角度不同而不同，是一件非常棘手的事情。如果找到了没有关系的点，就可以如庖丁解牛一样，进行架构隔离、模块解耦等工作。有关系的情况下，包括如下5种类型：

- 继承：extends (is-a)
- 实现：implements (can-do)
- 组合：类是成员变量 (contains-a)
- 聚合：类是成员变量 (has-a)
- 依赖：import类 (use-a)

继承和实现是比较容易理解的两种类关系。在架构设计中，要注意组合、聚合和
依赖这三者的区别。组合体现的是非常强的整体与部分的关系， 同生共死，部分不能在整体之间共享；聚合是一种可以拆分的整体与部分的关系，是非常松散的暂时组合，部分可以被拆出来给另一个整体；
依赖是除组合和聚合外的类与类之间的关系，这个类只要 import ，那就是依赖关系。

![1565966007465](E:\git_repo\Hao_Learn\2019\8\img\1565966007465.png)

随着业务和架构的发展，类与类的关系是会发生变化的，必须用发展的眼光看待类图。在业务重构过程中，往往会把原来强组合的关系拆开来，供其他模块调用，这就是类图的一种演变。

#### 序列化

内存中的数据对象只有转换为二进制流才可以进行数据持久化和网络传输。将数据对象转换为二进制流的过程称为对象的序列化（ Serialization ）。反之，将二进制流恢复为数据对象的过程称为反序列化（ Deserialization ）。序列化需要保留充分的信息以恢复数据对象，但是为了节约存储空间和网络带宽，序列化后的二进制流又要尽可能小。序列化常见的使用场景是RPC框架的数据传输。常见的序列化方式有三种：

1. Java 原生序列化。

Java 类通过实现 Serializable 接口来实现该类对象的序列化，这个接口非常特殊，没有任何方法，只起标识作用。Java 序列化保留了对象类的元数据（如类、成员变量、继承类信息等），以及对象数据等，兼容性最好，但不支持跨语言，而且性能一般。

实现 Serializable 接口的类建议设置 serialVersionUID 字段值，如果不设置，那么每次运行时，编译器会根据类的内部实现，包括类名、接口名、方法和属性等来自动生成 serialVersionUID 。如果类的源代码有修改，那么重新编译后serialVersionUID 的取值可能会发生变化。因此实现 Serializable 接口的类一定要显式地定义serialVersionUID 属性值。修改类时需要根据兼容性决定是否修改 serialVersionUID值：

- 如果是兼容升级，请不要修改 serialVersionUID 字段，避免反序列化失败。
- 如果是不兼容升级，需要修改 serialVersionUID 值，避免反序列化混乱。

使用 Java 原生序列化需注意， Java 反序列化时**不会调用类的无参构造方法，而是调用 native 方法将成员变量赋值为对应类型的初始值**。基于性能及兼容性考虑，不推荐使用 Java 原生序列化。

2.  Hessian 序列化。 

Hessian 序列化是一种支持动态类型、跨语言、基于对象传输的网络协议。 Java 对象序列化的二进制流可以被其他语言（如 C++、Python ）反序列化。 Hessian 协议具有如下特性：

- 自描述序列化类型。不依赖外部描述文件或接口定义，用一个字节表示常用基础类型，极大缩短二进制流。
- 语言无关，支持脚本语言。
- 协议简单，比 Java 原生序列化高效。

相比 Hessian 1.0，Hessian 2.0 中增加了压缩编码，其序列化二进制流大小是 Java序列化的 50% 序列化耗时是 Java 序列化的 30 ，反序列化耗时是 Java 反序列化的20%。

Hessian 会把复杂对象所有属性存储在一个 Map 中进行序列化。所以在父类、子类存在同名成员变量的情况下，Hessian 序列化时，先序列化子类 ，然后序列化父类，因此反序列化结果会导致子类同名成员变量被父类的值覆盖。

3.  JSON 序列化。

JSON ( JavaScript Object Notation ）是一种轻量级的数据交换格式。 JSON 序列化就是将数据对象转换为 JSON 字符串。在序列化过程中抛弃了类型信息，所以反序列化时只有提供类型信息才能准确地反序列化。相比前两种方式，JSON 可读性比较好，方便调试。

序列化通常会通过网络传输对象，而对象中往往有敏感数据，所以序列化常常成为黑客的攻击点，攻击者巧妙地利用反序列化过程构造恶意代码，使得程序在反序列化的过程中执行任意代码。 Java 工程中广泛使用的 Apache Commons Collections、Jackson、fastjson 等都出现过反序列化漏洞。如何防范这种黑客攻击呢？有些对象的敏感属性不需要进行序列化传输 ，可以加 `transient` 关键字，避免把此属性信息转化为序列化的二进制流。如果一定要传递对象的敏感属性，可以使用对称与非对称加密方式独立传输，再使用某个方法把属性还原到对象中。应用开发者对序列化要有一定的安全防范意识，对传入数据的内容进行校验或权限控制，及时更新安全漏洞，避免受到攻击。

## 2.4 方法

#### 方法签名

方法签名包括方法名称和参数列表，是 JVM 标识方法的唯一索引，不包括返回值，更加不包括访问权限控制符、异常类型等。

无论是对于基本数据类型，还是引用变量， Java 中的参数传递都是值复制的传递过程。对于引用变量，复制指向对象的首地址，双方都可以通过自己的引用变量修改指向对象的相关属性。

**可变参数**是在 JDK5 版本中引入的，主要为了解决当时的反射机制和 printf 方法问题，适用于不确定参数个数的场景。可变参数通过“参数类型 ..．”的方式定义，如 PrintStream 类中 printf 方法使用了可变参数：

```Java
public PrintStream printf(String format , Object ... args) {
	return format (format , args) ;
}
//调用printf方法示例
System.out.printf("%d", n); 	//第1处
System.out.printf("%d %s",n,"something");	//第2处
```

看上去可变参数使方法调用更简单，省去了手工创建数组的麻烦。如果在实际开发过程中使用不当，会严重影响代码的可读性和可维护性。因此，使用时要谨慎小心，尽量不要使用可变参数编程。如果一定要使用，则只有相同参数类型，相同业务含义的参数才可以，并且一个方法中只能有一个可变参数，且这个可变参数必须是该方法的最后一个参数。此外，建议不要使用 Object 作为可变参数。

参数预处理包括两种：
1. 入参保护。

虽然“入参保护”被提及的频率和认知度远低于参数校验，但是其重要性却不能被忽略。入参保护实质上是对服务提供方的保护，常见于批量接口。虽然批量接口能处理一批数据，但其处理能力并不是无限的，因此需要对入参的数据量进行判断和控制，如果超出处理能力，可以直接返回错误给客户端。

2. 参数校验。

基于防御式编程理念，在方法内，无论是对方法调用方传入参数的理性不信任 ，还对参数有效值的检测都是非常有必要的。但是由于方法间交互是非常频繁的，如果所有方法都进行参数校验，就会导致重复代码及不必要的检查影响代码性能。综合两个方面考虑，汇总需要进行参数校验和无须处理的场景。

需要进行参数校验的场景：

- 调用频度低的方法。
- 执行时间开销很大的方法。此情形中，参数校验时间几乎可以忽略不计，但 如果因为参数错误导致中间执行回退或者错误，则得不偿失。
- 需要极高稳定性和可用性的方法。
- 对外提供的开放接口。
- 敏感权限入口。

不需要进行参数校验的场景：

- 极有可能被循环调用的方法，但在方法说明里必须注明外部参数检查。
- 底层调用频度较高的方法。参数错误不太可能到底层才会暴露问题。一般DAO层与 Service 层都在同一个应用中，部署在同一台服务器中，所以可以省略DAO 的参数校验。
- 声明成 private 只会被自己代码调用的方法。如果能够确定调用方法的代码传
入参数已经做过检查或者肯定不会有问题，此时可以不校验参数。

#### 构造方法

构造方法（ Constructor ）是方法名与类名相同的特殊方法，在新建对象时调用，可以通过不同的构造方法实现不同方式的对象初始化，它有如下特征：

1. 构造方法名称必须与类名相同。
2. 构造方法是没有返回类型的，即使是void也不能有。**它返回对象的地址，并赋值给引用变量**。
3. 构造方法不能被继承，不能被覆写，不能被直接调用。调用途径有三种：一是通过 new 关键字，二是在子类的构造方法中通过 super 调用父类的构造方法，三是通过反射方式获取并使用。
4. 类定义时提供了默认的无参构造方法。但是如果显式定义了有参构造方法，此无参构造方法就会被覆盖；如果依然想拥有，就需要进行显式定义。
5. 构造方法可以私有。外部无法使用私有构造方法创建对象。

在接口中不能定义构造方法，在抽象类中可以定义。在枚举类中，构造方法是特
殊的存在，它可以定，但不能加 public 修饰，因为它默认是 private 的，是绝对的单例，不允许外部以创建对象的方式生成枚举对象。

单一职责，对于构造方法同样适用 ，构造方法的使命就是在构造对象时进行传参操作，所以不应该在构造方法中引入业务逻辑。推荐将初始化业务逻辑放在某个方法中，比如 init() ， 当对象确认完成所有初始化工作之后，再显式调用。

类中的 static { ... ｝代码被称为类的静态代码块，在类初始化时执行，优先级很高，且只运行一次，在第二次对象实例化时，不会运行。

父子类静态代码块和构造方法的执行顺序：
1. 父类静态代码块
2. 子类静态代码块
3. 父类构造方法
4. 子类构造方法

#### 类内方法

除构造方法外，类中还可以有三类方法：实例方法、静态方法、静态代码块。

1. 实例方法

又称为非静态方法。实例方法比较简单，它必须依附于某个实际对象，并可以通过引用变量调用其方法。类内部各个实例方法之间可以相互调用，也可以直接读写类内变量 ，且不用通过 this 。**当 .class 字节码文件加载之后，实例方法并不会被分配方法入口地址，只有在对象创建之后才会被分配**。实例方法可以调用静态变量和静态方法，当从外部创建对象后，应尽量使用`类名.静态方法`来调用，而不是对象名，一来为编译器减负，二来提升代码可读性。

2. 静态方法

又称为类方法。当类加载后，即分配了相应的内存空间，由于生命周期的限制，使用静态方法需要注意两点：

- 静态方法中不能使用实例成员变量和实例方法。
- 静态方法不能使用 super 和 this 关键字 ，这两个关键字指代的都是需要被创建出来的对象。

通常静态方法用于定义工具类的方法等，静态方法如果使用了可修改的对象，那么在并发时会存在线程安全问题。所以，**工具类的静态方法与单例通常是相伴而生的**。

3. 静态代码块

在代码的执行方法体中，非静态代码块和静态代码块比较特殊。非静态代码块又称为局部代码块，是极不推荐的处理方式，本节不再展开。而静态代码块在类加载的时候就被调用，并且只执行一次。静态代码块是先于构造方法执行的特殊代码块。静态代码块不能存在于任何方法体内，包括类静态方法和属性变量。

某框架的初始化代码如下所示：

```Java
public class RpcProviderBean｛
    public void init() throws RpcRuntimeException {
        this.initRegister();
        this.publish();
        //其他逻辑
    }
    public void initRegister() {
        if (this.inited.compareAndSet (false, true)) {
            this.checkConfig() ;
            this.metadata.init() ;
        }
    }
    public void publish( ) {
    //将本地服务信息、发送到注册中心
    }
}
```

#### getter 与 setter

在实例方法中有一类特殊的方法，即 getter 与 setter 方法，它们一般不包含任何业务逻辑，仅仅是为类成员属性提供读取和修改的方法，这样设计有两点好处：

1. 满足面向对象语言封装的特性。 

尽可能将类中的属性定义为 private ，针对属性值的访问与修改需要使用相应的 getter 与 setter 方法 而不是直接对 public 的属性进行读取和修改。

2. 有利于统一控制。 

虽然直接对属性进行读取、修改的方式和使用相应的getter 与 setter 方法在效果上是一样的，但是前者难以应对业务的变化。例如，业务要求对某个属性值的修改要增加统一的权限控制，如果有 setter 作为统一的属性修改方法更容易实现，这种情况在一些使用反射的框架中作用尤其明显。

建议在类定义中，类内方法定义顺序依次是：公有方法或保护方法＞私有方法＞ getter/setter 方法。

最典型的 getter 与 setter 方法使用是在 POJO ( Plain Ordinary Java Object， 简单的Java 对象）类中。常见的 POJO 类包括 DO(Domain Object)、 BO(Business Object)、 DTO(Data Transfer Object)、 VO （View Object）、 AO(Application Object)。

#### 同步与异步

同步调用是刚性调用，是阻塞式操作，必须等待调用方法体执行结束。而异步调用是柔性调用，是非阻塞式操作，在执行过程中，如调用其他方法，自己可以继续执行而不被阻塞等待方法调用完毕。

异步调用通常用在某些耗时长的操作上，这个耗时方法的返回结果，可以使用某种机制反向通知，或者再启动一个线程轮询。反向通知方式需要异步系统和各个调用它的系统进行耦合，而轮询对于没有执行完的任务会不断地请求，从而加大执行机器的压力。

异步处理的任务是非时间敏感的。比如，在连接池中，异步任务会定期回收空闲线程。

#### 覆写

为有些子类是延迟加载的，甚至是网络加载的，所以最终的实现需要在运行期判断，这就是所谓的动态绑定。动态绑定是多态性得以实现的重要因素，元空间有一个方法表保存着每个可以实例化类的方法信息， JVM可以通过方法表快速地激活实例方法。

如果某个类覆写了父类的某个方法，则方法表中的方法指向引用会指向子类的实现处，通常这也被称作向上转型。

向上转型时，通过父类引用执行子类方法时需要注意以下两点：

1. 无法调用到子类中存在而父类本身不存在的方法。
2. 可以调用到子类中覆写了父类的方法，这是一种多态实现。

想成功地覆写父类方法，需要满足以下 4个条件：

1. 访问权限不能变小。

访问控制权限变小意味着在调用时父类的可见方法无法被子类多态执行，比如父类中方法是用 public 修饰的，子类覆写时变成 private ，则破坏了封装。

2. 返回类型能够向上转型成为父类的返回类型。

虽然方法返回值不是方法签名的一部分，但是在覆写时，父类的方法表指向了子类实现方法 ，编译器会检查返回值是否向上兼容。注意，这里的向上转型必须是严格的继承关系，数据类型基本不存在通过继承向上转型的问题。比如 int 与 Integer 是非兼容返回类型，不会自动装箱；再比如，如果子类方法返回 int ，而父类方法返回 long ，虽然数据表示范围更大，但是它们之间没有继承关系；返回类型是 Object 的方法，能够兼容任何对象，包括class、 enum、 interface 等类型。

3. 异常也要能向上转型成为父亲的异常。

异常分为 checked 和 unchecked 两种类型。如果父类抛出一个 checked 异常，则子类只能抛出此异常或此异常的子类。而 unchecked 异常不用显式地向上抛出，所以没有任何兼容问题。

4. 方法名、参数类型及个数必须严格一致。

为了使编译器准确地判断是否是覆写行为 ，所有的覆写方法必须加＠Override 注解。此时编译器会自动检查覆写方法签名是否一致，避免了覆写时因写错方法名或方法参数而导致覆写失败。

综上所述，方法的覆写可以总结成容易记忆的口诀：`一大两小两同`。

- 一大：子类的方法访问权限控制符只能相同或变大。
- 两小：抛出异常和返回值只能变小，且能够转型成父类对象。子类的返回值、抛出异常类型必须与父类的返回值、抛出异常类型存在继承关系。
- 两同：方法名和参数必须完全相同。

覆写只能针对非静态、非 final 、非构造方法。由于静态方法属于类，如果父类和子类存在同名静态方法，那么两者都可以被正常调用。如果方法有 final 修饰 ，则表示此方法不可被覆写。

如果想在子类覆写的方法中调用父类方法 ，则可以使用 super 关键字。

## 2.5 重载

在同一个类中，如果多个方法有相同的名字、不同的参数，即称为重载，比如一个类中有多个构造方法。String类中的 valueOf 也是比较著名的重载案例，它有9 个方法，可以将输入的基本数据类型、数组、 Object 等转化成为字符串。

![1566035631923](E:\git_repo\Hao_Learn\2019\8\img\1566035631923.png)

![1566035609428](E:\git_repo\Hao_Learn\2019\8\img\1566035609428.png)

第一处与第二处的区别是后者加了 varargs 标识，即可变参数了 varargs 标识，即可变参数，参数个数可以是 0 或多个，也就是说，它和第1、 2、3 个方法都是有可能争抢地盘的。

JVM 在重载方法中，选择合适的目标方法的顺序如下：
1. 精确匹配。
2. 如果是基本数据类型，自动转换成更大表示范围的基本类型。
3. 通过自动拆箱与装箱。
4. 通过子类向上转型继承路线依次匹配。
5. 通过可变参数匹配。

null 可以匹配任何类对象，在查找目标方法时，是从最底层子类依次向上查找的。

父类的公有实例方法与子类的公有实例方法可以存在重载关系。不管继承关系如何复杂，重载在编译时可以根据规则知道调用哪种目标方法。所以，重载又称为静态绑定。

## 2.6 泛型

泛型的本质是类型参数化，解决不确定具体对象类型的问题。在面向对象编程语言中，允许程序员在强类型校验下定义某些可变部分，以达到代码复用的目的。

Java 在引入泛型前，表示可变类型 ，往往存在类型安全的风险。

泛型可以定义在类、接口、方法中，编译器通过识别尖括号和尖括号内的字母来解析泛型。在泛型定义时，约定俗成的符号包括 E 代表 Element ，用于集合中的元素；T 代表 the Type of object ，表示某个类；K 代表 key、V 代表 Value ，用于键值对元素。

1. 尖括号里的每个元素都指代一种未知类型，如 String 出现在尖括号里，它就不是   ，而仅仅是一个代号。类名后方定义的泛型`<T>`和 get ()前方定义的`<T>`是两个指代，可以完全不同，互不影响。

2. 尖括号的位置非常讲究，必须在类名之后或方法返回值之前。

3. 泛型在定义处只具备执行Object方法的能力，因此想在 get() 内部执行string.longValue() + alibaba.intValue() 是做不到的，此时泛型只能调用 Object 类中的方法，如 toString() 。

4. 对于编译之后的字节码指令，其实没有这些花头花脑的方法签名，充分说明了泛型只是一种编写代码时的语法检查。在使用泛型元素肘，会执行强制类型转换。

![1566038549508](E:\git_repo\Hao_Learn\2019\8\img\1566038549508.png)

这就是坊间盛传的类型擦除。 CHECKCAST 指令在运行时会检查对象实例的类型是否匹配，如果不匹配，则抛出运行时异常 ClassCastxception 。

泛型就是在编译期增加了一道检查而己，目的是促使程序员在使用泛型时安全放置和使用数据。使用泛型的好处包括：

- 类型安全。放置的是什么，取出来的自然是什么，不用担心会抛出ClassCastException 异常。
- 提升可读性。从编码阶段就显式地知道泛型集合、泛型方法等处理的对象类型是什么
- 代码重用。泛型合并了同类型的处理代码，使代码重用度变高。

## 2.7 数据类型

#### 基本数据类型

基本数据类型是指不可再分的原子数据类型，内存中直接存储此类型的值，通过内存地址即可直接访问到数据，并且此内存区域只能存放这种类型的值。

refvar 是面向对象世界中的引用变量，也叫引用句柄，本书认为它也是一种基本数据类型。

前 8 种都有相应的包装数据类型，除 char 的对应包装类名为Character, int 为Integer 外，其他所有对应的包装类名就是把首字母大写即可。

![1566039107712](E:\git_repo\Hao_Learn\2019\8\img\1566039107712.png)

- JVM 并没有针对 boolean 数据类型进行赋值的专用字节码指令，`boolean flag= false` 就是用 CONST ，即常数 0 来进行赋值。
- byte 的默认值以一个字节的 0 表示，在默认值的表示上使用了强制类型转化；。
- char 的默认值只能是单引号的 '\u0000' 表示 NUL ，注意不是 null，它就是一个空的不可见字符，在码表中是第一个，其码值为0，与 '\n' 换行之类的不可见控制符的理解角度是一样的。

引用分成两种数据类型：引用变量本身和引用指向的对象。为了强化这两个概念的区分，本书把引用变量（ Reference Variable ）称为` refvar` ，而把引用指向的实际对象（ Referred Object ）简称为 `refobj`。

refvar 是基本的数据类型，它的默认值是 null ，存储 refobj 的首地址，可以直接使用双等号`==`进行等值判断。而平时使用 refvar.hashCode() 返回的值，只是对象的某种哈希计算，可能与地址有关，与 refvar 本身存储的内存单元地址是两回事。作为一个引用变量，不管它是指向包装类、集合类、字符串类还是自定义类， refvar 均占4B 空间。**注意它与真正对象 refobj 之间的区别**。无论 refobj 是多么小的对象，最小占用的存储空间是 12B（用于存储基本信息， 称为对象头），但由于存储空间分配必须是 8B 的倍数，所以初始分配的空间至少是 16B 。

一个 refvar 至多存储一个 refobj 的首地址，一个 refobj 可以被多个 refvar 存储下它的首地址，即一个堆内对象可以被多个 refvar 引用指向。如果 refobj 均没有被任何refvar 指向，那么它迟早会被垃圾回收。而 refvar 的内存释放，则与其他基本数据类型类似。

基本数据类型 int 占用 4 个字节，而对应的包装类 Integer 实例对象占用 16 个字节。这里可能会有人问 Integer 里边的代码就只占用 16B ？这是因为字段属性除成员属性 int value外， 其他的如 MAX_VALUE、 MIN_VALUE 等都是静态成员变量在类加载时就分配了内存，与实例对象容量无关。此外，类定义中的方法代码不占用实例对象的任何空间。IntegerCache 是 Integer 的静态内部类，容量占用也与实例对象无关。由于 refobj 对象的基础大小是 12B ，再加上 int是4B，所以 Integer 实例对象占用 16B ，按此推算 Double 对象占用的存储容量是 24B (12+8 ，8 的倍数)。

![1566047545513](E:\git_repo\Hao_Learn\2019\8\img\1566047545513.png)

对象的内部结构分为三块存储区域：
![1566047613016](E:\git_repo\Hao_Learn\2019\8\img\1566047613016.png)

1. 对象头（Object Header）：

对象头占用 12 个字节，存储内容包括对象标记 (markOop) 和类元信息（klassOop) 。对象标记存储对象本身运行时的数据，如哈希码、 GC 标记、锁信息、线程关联信息等，这部分数据在 JVM 上占用 8 个字节，称为`Mark Word`。为了存储更多的状态信息，对象标记的存储格式是非固定的（具体与JVM的实现有关）。类元信息存储的是对象指向它的类元数据（即 Klass ）的首地址，占用 4个字节，与 refvar 开销一致。
	
2. 实例数据（Instance Data）：

存储本类对象的实例成员变量和所有可见的父类成员变量。如 Integer 的实例成员只有一个 `private int value`，占用 4 个字节，所以加上对象头为 16 个字节；再如，上述示例代码的 RefObjDemo 对象大小为 48 个字节，一个子类 RefObjSon 继承 RefObjDemo，即使子类内部是空的， new RefObjSon 的对象也是占用 48 个字节。

3. 对齐填充（Padding）

对象的存储空间分配单位是 8 个字节，如果一个占用大小为 16 个字节的对象，增加一个成员变量 byte 类型，此时需要占用 17 个字节，但是也会分配 24个字节进行对齐填充操作。
	
#### 包装类型

包装类的存在解决了基本数据类型无法做到的事情：泛型类型参数、序列化、类型转换、高频区间数据缓存，尤其是最后一项。我们都知道 Integer 会缓存`-128 ~ 127` 之间的值，对于 `Integer var = ?`在`-128 ~ 127` 之间的赋值， Integer对象由 IntegerCache.cache 产生，会复用已有对象，这个区间内的 Integer 值可以直接使用`==`进行判断，但是这个区间之外的所有数据都会在堆上产生，并不会复用已有对象，这是一个大问题。因此，推荐所有包装类对象之间值的比较，全部使用 equals () 方法。

事实上，除 Float 和 Double 外，其他包装数据类型都会缓存，6 个包装类直接赋值时，就是调用对应包装类的静态工厂方法 valueOf() 。

```java
@HotSpotIntrinsicCandidate
public static Integer valueOf(int i) {
	if (i >= IntegerCache.low && i <= IntegerCache.high)
		return IntegerCache.cache[i + (-IntegerCache.low)];
	return new Integer(i)；
}
```
如上源代码，赋值数据 i 在缓存区间内直接返回缓存中的 Integer 对象，否则就会 new 一个对象。在 JDK9 直接把 new 的构造方法过时，推荐使用valueOf ()，合理利用缓存，提升程序性能。

Boolean使用静态 final 变量定义， valueOf() 就是返回这两个静态值；Integer是唯一可以修改缓存范围的包装类，在 VM options 加入参数`-XX:AutoBoxCacheMax=7777`，即可设置最大缓存值为 7777。

合理掌握包装类的缓存策略，防止遇到问题是一个方面，使自己的程序性能最大化，更是程序员的情怀所在。在选择使用包装类还是基本数据类型时，推荐使用如下方式：

1. 所有的 POJO 类属性必须使用包装数据类型。
2. RPC 方法的返回值和参数必须使用包装数据类型。
3. 所有的局部变量推荐使用基本数据类型。

#### 字符串

String 是只读字符串，典型的 immutable( 不变的 )对象，对它的任何改动，其实都是创建一个新对象，再把引用指向该对象。 String 对象赋值操作后，会在常量池中进行缓存，如果下次申请创建对象时，缓存中已经存在，则直接返回相应引用给创建者。

StringBuffer 则可以在原对象上进行修改，是线程安全的。 JDK5 引入的 StringBuilder 与 StringBuffer 均继承自 `AbstractStringBuilder`，两个子类的很多方法都是通过`super.方法()` 的方式调用抽象父类中的方法，此抽象类在内部与 String 一样，也是以字符数组的形式存储字符串的。 StringBuilder 是非线程安全的 ，把是否需要进行多线程加锁交给工程师决定操作效率比 StringBuffer 高。线程安全的对象先产生是因为计算机的发展总是从单线程到多线程，从单机到分布式。

在非基本数据类型的对象中，String 是仅支持直接相加操作的对象。这样操作比较方便，但在循环体内，字符串的连接方式应该使用 StringBuilder的append 方法进行扩展。

# 第三章 代码风格

## 3.1命名规约

抽象类命名使用 Abstract 或 Base 开头。枚举类名带上 Enum 后缀，枚举成员名称需要全大写，单词间用下画线隔开。

命名最好望文知义，即在不需要额外解释的情况下，仅从名称上就能够理解某个词句的确切含义，从而减少注释内容，达到自解释的目的。

#### 常量

根据作用域区分，分为全局常量、类内常量、局部常量。全局常量是指类的公开静态属性，使用 public static final 修饰；类内常量是私有静态属性，使用private static final 修饰，局部常量分为方法常量和参数常量，前者是在方法或代码块内定义的常量，后者是在定义形式参数时，增加 final 标识，表示此参数值不能被修改。

![1566090152540](E:\git_repo\Hao_Learn\2019\8\img\1566090152540.png)

常量在代码中具有穿透性，使用甚广。如果没有一个恰当的命名，就会给代码阅读带来沉重的负担，甚至影响对主干逻辑的理解。首当其冲的问题就是到处使用魔法值。魔法值即“共识层面“上的常量，直接以具体的数值或者字符出现在代码中。这些不知所云的魔法值极大地影响了代码的可读性和可维护性。

![1566090865458](E:\git_repo\Hao_Learn\2019\8\img\1566090865458.png)

枚举类型几乎是固定不变的全局常量，使用频率高、范围广，所以枚举常量都需要添加清晰的注释，比如业务相关信息或注意事项等；后续还会再追加，并且没有扩展信息的常量应该用不能实例化的抽象类的全局常量来表示。

![1566090901520](E:\git_repo\Hao_Learn\2019\8\img\1566090901520.png)

系统成长到某个阶段后，重构是种必然选择。优秀的架构设计不是去阻止未来切重构的可能性，毕竟技术枝、业务方向和规模都在不断变化，而是尽可能让重构来得晚一些，重构幅度小一些。

TreeMap 源码中，表示红黑树节点颜色的 RED = false，BLACK = true 就被定义成为类内常量，以方便理解。

## 3.2 代码展示风格

#### 缩进、空格与空行

缩进表示层次对应关系。推荐采用 4 个空格缩进，禁止使用 Tab 键。

空格用于分隔不同的编程元素。空格可以让运算待、数值、注释、参数等各种编程元素之间错落有致，方便快速定位。空格的使用有如下约定：
1. 任何二目、三目运算符左右两边都必须加一个空格。
2. 注释的双斜线与注释内容之间有且仅有一个空格。
3. 方法参数在定义和传入时，多个参数逗号后边必须加空格。
4. 没有必要增加若干空格使变量的赋值等号与上一行对应位置的等号对齐。
5. 如果是大括号内为空，则简洁的写成{} 即可，大括号中间无须换行和空格。
6. 左右小括号与括号内部的相邻字符之间不要出现空格。
7. 左大括号前需要加空格。

空行用来分隔功能相似、逻辑内聚、意思相近的代码片段，使得程序布局更加清晰。在浏览代码时，空行可以起到自然停顿的作用，提升阅读代码的体验。哪些地方需要空行呢？在方法定义之后、属性定义与方法之间、不同逻辑、不同语义、不同业务的代码之间都需要通过空行来分隔。

#### 换行与高度

代码中需要限定每行的字符个数，以便适配显示器的宽度，以及方便CodeReview 时进行 diff 比对。对于无节制的行数字符，需要不断地拉取左右滚动条或者键盘移动光标，那是多么差的体验。因此 约定单行字符数不超过 120 个，超出则需要换行，换行时遵循如下原则：

1. 第二行相对第一行缩进 4 个空格，从第三行开始，不再继续缩进，参考示例。
2. 运算符与下文一起换行。
3. 方法调用的点符号与下文一起换行。
4. 方法调用中的多个参数需要换行时，在逗号后换行。
5. 在括号前不要换行。

除注释之外，方法签名、左右大括号、方法内代码、空行、回车及任何不可见字符的总行数不超过 80 行。为什么是 80 行？心理学认为人对事物的印象通常不能超过 3 这个魔法数，三屏是人类短期记忆的极限，而 80 行在一般显示器上是两屏半的代码量。另外，通过对阿里代码抽样调查显示 只有不到 5% 的方法才会超过 80 而这些方法通常都有明显的优化空间。

#### 控制语句

控制语句是底层机器码跳转指令的实现。方法内部的跳转控制主要由条件判断语句和循环语句实现。跳转能力使程序能够处理复杂逻辑，具备像人一样的判断能力和记忆回溯能力。循环严格意义上也是一种跳转。

控制语句是最容易出现 Bug 的地方，所以特别需要代码风格的约束，而不是天马行空地乱跳。控制语句必须遵循如下约定：

1. 在 if、else、for、while、do-while 等语句中必须使用大括号。即使只有一行代码也需要加上大括号。

2. 在条件表达式中不允许有赋值操作，也不允许在判断表达式中出现复杂的逻辑组合。有些控制语句的表达式逻辑相当复杂，与、或、取反混合运算甚至穿插了赋值操作，理解成本非常高，甚至会产生误解。要解决这个问题，有一个非常简单的办法：**将复杂的逻辑运算赋值给一个具有业务含义的布尔变量**。

3. 多层嵌套不能超过3层。多层嵌套在哪里都不受欢迎，是因为条件判断和分支逻辑数量呈指数关系。如果非得使用多层嵌套，请使用状态设计模式。对于超过 3 层的 if-else 的逻辑判断代码，可以使用卫语句、策略模式、状态模式等来实现，其中卫语句示例如下：

![1566100919498](E:\git_repo\Hao_Learn\2019\8\img\1566100919498.png)

4. 避免采用取反逻辑符。取反逻辑不利于快速理解，并且取反逻辑写法必然存在对应的正向逻辑写法。

## 3.3代码注释

#### 注释三要素

注释要求能够准确反映设计思想和代码逻辑；能够描述业务含义使其他工程师能迅速了解背景知识。书写注释要满足优雅注释三要素：

1. Nothing is strange

完全没有注释的大段代码对于阅读者来说形同天书。注释是给自己看的，即使离写完代码很长时间，也能清晰地理解当时的思路，注释也是给维护者看的，使其能够快速理解代码逻辑。

2. Less is more 

从代码可读性及维护成本方面来讲，代码中的注释，定是精华中的精华。

首先，真正好的代码是自解释的，准确的变量命名加上合理的代码逻辑，无须过多的文字说明就足以让其他工程师理解代码的功能。如果代码需要大量的注释来说明解释，那么工程师应该思考是否可以优化代码表现力。其次，泛滥的注释不但不能帮助工程师理解代码，而且会影响代码的可读性，甚至会增加程序的维护成本。

3. Advance with the times

与时俱进的重要性对于开发工程师来说是不言而喻的。针对一段有注释的代码，如果程序员修改了代码逻辑，但是没有修改注释，就会导致注释无法跟随代码前进的脚步，误导后续开发者。因此，任何对代码的修改，都应该同时修改注释。
	
#### 注释格式

1. Javadoc 规范

类、类属性和类方法的注释必须遵循 Javadoc 规范，使用文档注释`/** *`的格式。特别强调对枚举的注释是必需的。每句实在太特殊了，它的代码极为稳定。如果它的定义和使用出现错误，通常影响较大。

2. 简单注释

包括单行注释和多行注释。特别强调此类注释不允许写在代码后方，必须写在代码上方，这是为了避免注释的参差不齐，导致代码版式混乱。双画线注释往往使用在方法内部，此时的注释是提供给程序开发者、维护者和关注方法细节的调用者查看的。

注释的作用更应该是画龙点睛的，通常添加在非常必要的地方，例如复杂算法或需要警示的特殊业务场景等。

# 第4章 走进JVM

## 4.1 字节码

Java 所有的指令有 200 个左右，一个字节 (8 位) 可以存储 256 种不同的指令信息，一个这样的字节称为字节码 (Bytecode) 。在代码的执行过程中， JVM 将字节码解释执行，屏蔽对底层操作系统的依赖；JVM 也可以将字节码编译执行，如果是热点代码，会通过 JIT 动态地编译为机器码，提高执行效率。

![1566102418401](E:\git_repo\Hao_Learn\2019\8\img\1566102418401.png)

起始的 4个字节非常特殊，即绿色框的 cafe babe 是 Gosling 定义的 一个魔法数，意思是 Coffee Baby ，其十进制值为 3405691582 。它的作用是：标志该文件是一个 Java 类文件，如果没有识别到该标志，说明该文件不是 Java 类文件或者文件已受损，无法进行加载。而红色框代表当前版本号， 0x37 的十进制为 55 ，是 JDK11 的内部版本号。

纯数字的字节码阅读起来像天书一样难，当初汇编语言为了改进机器语言，使用助记符来替代对应的数字指令。JVM在字节码上也设计了一套操作码助记符，使用特殊单词来标记这些数字。

字节码主要指令如下：

1. 加载或存储指令

在某个栈帧中，通过指令操作数据在虚拟机栈的局部变量表与操作栈之间来回传输，常见指令如下。

- 将局部变量加载到操作栈中。如ILOAD（将 int 类型的局部变量压入栈）和   ALOAD （将对象引用的局部变量压入栈）等。
- 从操作栈顶存储到局部标量表。 ISTORE、 ASTORE等。
- 将常量加载到操作栈顶 ，这是极为高频使用的指令。 ICONST, BIPUSH SIPUSH LDC 等。
- ICONST 加载的是`-1 ~ 5`的数（ICONST 与 BIPUSH 的加载界限， 在`-1 ~ 5`之外的数字使用 BIPUSH 指令加载）。
- BIPUSH ，即 Byte Immediate PUSH ，加载`-128 ~ 127` 之间的数。
- SIPUSH ，即Short Immediate PUSH，加载`-32768 ~ 32767` 之间的数。
- LDC ，即 Load Constant，在`-2147483648 ~ 2147483647` 或者是字符串时，JVM 采用 LDC 指令压入枝中。

2. 运算指令

对两个操作栈帧上的值进行运算，并把结果写入操作栈顶，如 IADD、IMUL 等。

3. 类型转换指令

显式转换两种不同的数值类型。如 I2L 、D2F 等。

4. 对象创建与访问指令

根据类进行对象的创建、初始化、方法调用相关指令，常见指令如下：

- 创建对象指令。如NEW、NEWARRAY等。
- 访问属性指令。如GETFIELD、PUTFIELD、GETSTATIC等。
- 检查实例类型指令。如 INSTANCEOF、CHECKCAST等。

5. 操作栈管理指令

JVM提供了直接控制操作栈的指令，常见指令如下：

- 出栈操作。如POP即一个元素，POP2即两个元素。
- 复制栈顶元素并压入栈。如DUP。

6. 方法调用与返回指令

常见指令如下：

- INVOKEVIRTUAL ：调用对象的实例方法。
- INVOKESPECIAL ：调用实例初始化方法、私有方法、父类方法等。
- INVOKESTATIC ：调用类静态方法。
- RETURN：返回 VOID 类型。

7. 同步指令

JVM 使用方法结构中的 ACC_SYNCHRONIZED 标志同步方法，指令集中有MONITORENTER 和 MONITOREXIT 支持 synchronized 语义。

除字节码指令外，还包含一些额外信息。例如， LINENUMBER 存储了字节码与源码行号的对应关系，方便调试的时候正确地定位到代码的所在行；LOCALVARIABLE 存储当前方法中使用到的局部变量表。

![1566105302731](E:\git_repo\Hao_Learn\2019\8\img\1566105302731.png)

词法解析是通过空格分隔出单词、操作符、控制符等信息，将其形成 token 信息流，传递给语法解析器；在语法解析时，把词法解析得到的 token 信息流按照 Java 语法规则组装成一棵语法树，如图 4-2 虚线框所示；在语义分析阶段，需要检查关键字的使用是否合理、类型是否匹配、作用域是否正确等；当语义分析完成之后，即可生成字节码。

字节码必须通过类加载过程加载到 JVM 环境后，才可以执行。执行有三种模式第一，解释执行；第二， JIT 编译执行；第三，JIT 编译与解释混合执行（主流JVM 默认执行模式）。

混合执行模式的优势在于解释器在启动时先解释执行，省去编译时间。随着时间推进 JVM 通过热点代码统计分析 ，识别高频的方法调用、循环体、公共模块等，基于强大的 JlT 动态编译技术，将热点代码转换成机器码，直接交给 CPU执行。 JIT 的作用是将 Java 字节码动态地编译成可以直接发送给处理器指令执行的机器码。

![1566107111781](E:\git_repo\Hao_Learn\2019\8\img\1566107111781.png)

注意解释执行与编译执行在线上环境微妙的辩证关系。机器在热机状态可以承受的负载要大于冷机状态（刚启动时 ），如果以热机状态时的流量进行切流，可能使处于冷机状态的服务器因无法承载流量而假死。

在生产环境发布过程中 ，以分批的方式进行发布 ，根据机器数量划分成多个批次，每个批次的机器数至多占到整个集群的 1/8 。

## 4.2 类加载过程

在冯 · 诺依曼定义的计算机模型中，任何程序都需要加载到内存才能与 CPU 进行交流。字节码 .class 文件同样需要加载到内存中，才可以实例化类。

ClassLoader 正是准备粮草的先行军，它的使命就是提前加载 .class 类文件到内存中。在加载类时，使用的是 Parents Delegation Model ，译为`双亲委派模型`，这个译名有些不妥。如果意译的话，则译作 `溯源委派加载模型`更加贴切。

Java 的类加载器是一个运行时核心基础设施模块，主要是在启动之初进行类的 Load、 Link、 Init，即加载、链接、初始化。

第一步，Load 阶段读取类文件产生二进制流，并转化为特定的数据结构，初步校验 cafe babe 魔法数、常量池、文件长度、是否有父类等，然后创建对应类的 java.Jang.Class 实例。

第二步，Link 阶段包括验证、准备、解析三个步骤。验证是更详细的校验，比如 final 是否合规、类型是否正确、静态变量是否合理等；准备阶段是为静态变量分配内存，并设定默认值，解析类和方法确保类与类之间的相互引用正确性，完成内存结构布局。

第三步，Init 阶段执行类构造器＜clinit> 方法，如果赋值运算是通过其他类的静
态方法来完成的，那么会马上解析另外一个类，在虚拟机栈中执行完毕后通过返回值进行赋值。

![1566107945279](E:\git_repo\Hao_Learn\2019\8\img\1566107945279.png)

类加载是一个将 .class 字节码文件实例化成 Class 对象并进行相关初始化的过程。在这个过程中， JVM 会初始化继承树上还没有被初始化过的所有父类，并且会执行这个链路上所有未执行过的静态代码块、静态变量赋值语句等。某些类在使用时，也可以按需由类加载器进行加载。

全小写的 class 是关键字，用来定义类，而首字母大写的 Class ，它是所有 class 的类。

![1566108418725](E:\git_repo\Hao_Learn\2019\8\img\1566108418725.png)

- 第 1 处说明：Class 类下的 newInstance() 在JDK9 中已经置为过时，应使用`getDeclaredConstructor().newlnstance()`的方式。这里着重说明一下 new 与 new Instance 的区别。 new 是强类型校验，可以调用任何构造方法，在使用 new 操作的时候，这个类可以没有被加载过。而 Class 类下的 newInstance 是弱类型，只能调用无参数构造方法，如果没有默认构造方法，就抛 InstantiationException 异常；如果此构造方法没有权限访问，则抛出
IllegalAccessException 异常。 Java 通过类加载器把类的实现与类的定义进行解耦，所以是实现面向接口编程、依赖倒置的必然选择。
- 第 3 处说明：private 成员在类外是否可以修改？通过 setAccessible(true) 操作，即可使用大写 Class 类的 set 方法修改其值。如果没有这一步，则抛出如下异常：

![1566108751186](E:\git_repo\Hao_Learn\2019\8\img\1566108751186.png)

类加载器是如何定位到具体的类文件并读取的呢？类加载器类似于原始部落结构 存在权力等级制度。最高的一层是家族中威望最高的 Bootstrap ，它是在 JVM 启动时创建的， 通常由与操作系统相关的本地代码实现，是最根基的类加载器，负责装载最核心的 Java类， 比如 0bject、System、String 等；第二层是在 JDK9 版本中，称为 Platform ClassLoader ，即平台类加载器，用以加载一些扩展的系统类，比如 XML、加密、压缩相关的功能类等，而 JDK9 之前的加载器是Extension ClassLoader ；第三层是 Application ClassLoader 的应用类加载器，主要是加载用户定义的 CLASSPATH 路径下的类。第二、三层类加载器为Java 语言实现，用户也可以自定义类加载器。

```Java
// 正在使用的类加载器：jdk.internal.loader.ClassLoaders$AppClassLoad@69d0a
ClassLoader c = TestWhoLoad.class.getClassLoader();
// AppClassLoader 的父加载器是PlatformClassLoader
ClassLoader c1 = c.getParent();
// PlatformClassLoader 的父加载器是 Bootstarp。它是用c++实现的，返回null
ClassLoader c2 = c1.getParent();
```
代码上方的注释内容为 JDK11 的执行结果。在 JDK8 环境中，执行结果如下：

```
sun.misc.Launcher\$AppClassLoader@14dad5dc
sun.misc.Launcher\$ExtClassLoader@6e0be858
null 
```

AppClassLoader 的 Parent 是 Bootstrap，它是通过 C/C＋＋ 实现的，并不存在于JVM 体系内 ，所以输出为 null，类加载器具有等级制度，但是并非继承关系，以组合的方式来复用父加载器的功能，这也符合组合优先原则。

![1566109712214](E:\git_repo\Hao_Learn\2019\8\img\1566109712214.png)

低层次的当前类加载器，不能覆盖更高层次类加载器已经加载的类。如图 4-6 所示，左侧绿色箭头向上逐级询问是否已加载此类，直至 Bootstrap ClassLoader ，然后向下逐级尝试是否能够加载此类，如果都加载不了，则通知发起加载请求的当前类加载器 ，准予加载。在右侧的三个小标签里，列举了此层类加载器主要加载的代表性类库，事实上不止于此。通过如下代码可以查看 Bootstrap 所有已经加载的类库：

```Java
URL[] urLs = sun.misc.Launcher.getBootstrapClassPath().getURLs();
for (java.net.URL url : urLs) {
	System.out.println(url.toExternalForm());
}
```
执行结果如下：

![1566110245338](E:\git_repo\Hao_Learn\2019\8\img\1566110245338.png)

Bootstrap 加载的路径可以追加，不建议修改或删除原有加载路径。 在 JVM 中增加如下启动参数，则能通过 Class.forName 正常读取到指定类，说明此参数可以增加Bootstrap 的类加载路径：
`-Xbootclasspath/a:/Users/yangguanbao/book/easyCoding/byJdkl l/src 
`
如果想在启动时观察加载了哪个 jar 包中的哪个类，可以增加`-XX:+TraceClassLoading`参数，此参数在解决类冲突时非常实用，毕竟不同的 JVM 环境对于加载类的顺序并非是一致的。有时想观察特定类的加载上下文，由于加载的类数量众多 ，调试时很难捕捉到指定类的加载过程，这时可以使用条件断点功能。比如，想查看 HashMap 的加载过程，在 loadClass 处打个断点，并且在 condition 框内输入如图 4-7 所示条件。

![1566110604986](E:\git_repo\Hao_Learn\2019\8\img\1566110604986.png)

需要自定义类加载器的情况下：
1. 隔离加载类。 在某些框架内进行中间件与应用的模块隔离，把类加载到不同的环境。
2. 修改类加载方式。类的加载模型并非强制， 除Bootstrap外， 其他的加载并非一定要引入，或者根据实际情况在某个时间点进行按需进行动态加载。
3. 扩展加载源。比如从数据库、网络 ，甚至是电视机机顶盒进行加载。
4. 防止源码泄露。Java 代码容易被编译和篡改，可以进行编译加密。那么类加载器也需要自定义，还原加密的字节码。

实现自定义类加载器的步骤：继承 ClassLoader ，重写 findClass() 方法，调用
defineClass() 方法。一个简单的类加载器实现的示例代码如下：

```Java
public class CustomClassLoader extends ClassLoader {
	@Override
	protected Class<?> findClass(String name) throws ClassNotFoundException {
		try {
			byte[] result = getClassFromCustomPath(name);
			if (result == null) {
				throw new FileNotFoundExceoption();
			} else {
				return defineClass(name, result, 0, result.length);
			}
		} catch (Exception e) {
			e.printStackTrace();
		}
		throw new ClassNotFoundException(name);
	}

	private byte[] getClassFromCustomPath (String name) {
		//从自定义路径中加载指定类
	}
}

public static void main(String[] args) {
	CustomClassLoader customClassLoader = new CustomClassLoader();
	try {
		Class<?> clazz = Class.forName("One", true, customClassLoader);
		Object obj = clazz.newInstance();
		System.out.println(obj.getClass()
			.getClassLoader());
	} catch (Exception e) {
		e.printStackTrace();
	}
}
```
执行结果如下：`classloader.CustomClassLoader@5e481248 `

由于中间件一般都有自己的依赖 jar 包，在同一个工程内引用多个框架时，往往被迫进进类的仲裁。按某种规则 jar 包的版本被统一指定 ，导致某些类存在包路径、类名相同的情况，就会引起类冲突 ，导致应用程序出现异常。主流的容器类框架都会自定义类加载器，实现不同中间件之间的类隔离，有效避免了类冲突。

#### 4.3 内存布局

内存是非常重要的系统资源，是硬盘和 CPU 的中间仓库及桥梁，承载着操作系统和应用程序的实时运行。 JVM 内存布局规定了 Java 在运行过程中内存申请、分配、管理的策略 ，保证了 JVM 的高效稳定运行。不同的 JVM 对于内存的划分方式和管理机制存在着部分差异。

![1566115381445](E:\git_repo\Hao_Learn\2019\8\img\1566115381445.png)

1. Heap（堆区）

Heap 是 OOM 故障最主要的发源地，它存储着几乎所有的实例对象，堆由垃圾收集器自动回收，堆区由各子线程共享使用。通常情况下，它占用的空间是所有内存区域中最大的，但如果无节制地创建大量对象，也容易消耗完所有的空间。堆的内存空间既可以固定大小，也可以在运行时动态地调整，通过如下参数设定初始值和最大值，比如 `-Xms256M -Xmxl024M` ，其中`-X`表示它是 JVM 运行参数， ms 是 memory start 的简称， mx 是 memory max 的简称，分别代表最小堆容量和最大容量。但是在通常情况下，服务器在运行过程中，堆空间不断地扩容与回缩，势必形成不必要的系统压力，所以在线上生产环境中 JVM 的 Xms 和 Xmx 设置成一样大小，避免在 GC 后调整堆大小时带来的额外压力。

堆分成两大块：新生代和老年代。对象产生之初在新生代，步入暮年时进入老年代，但是老年代也接纳在新生代无法容纳的超大对象。

新生代 = 1个 Eden 区＋Survivor 区。绝大部分对象在 Eden 区生成，当Eden 区装填满的时候，会触发 Young Garbage Collection ，即 YGC。垃圾回收的时候，在 Eden 区实现清除策略，没有被引用的对象则直接回收。依然存活的对象会被移送到 Survivor 区，这个区真是名副其实的存在。Survivor 区分为 S0 和 S1 两块内存空间，送到哪块空间呢？每次 YGC 的时候， 将存活的对象复制到未使用的那块空间，然后将当前正在使用的空间完全清除，交换两块空间的使用状态。如果 YGC 要移送的对象大于 Survivor 区容量的上限 ，则直接移交给老年代。假如一些没有进取心的对象以为可以一直在新生代的 Survivor 区交换来交换去，那就错了。每个对象都有一个计数器，每次 YGC 都会加1。

`-XX:MaxTenuringThreshold` 参数能配置计数器的值到达某个阈值的时候，对象从新生代晋升至老年代。如果该参数配置为1 ，那么对象会从新生代的 Eden 区直接移至老年代。默认值是 15 ，可以在 Survivor 区交换 14 次之后，晋升至老年代。

![1566116425601](E:\git_repo\Hao_Learn\2019\8\img\1566116425601.png)	

如果 Survivor 区无法放下，或者超大对象的阈值超过上限，则尝试在老年代中进行分配，如果老年代也无法放下，则会触发 Full Garbage Collection，即FGC。如果依然无法放下， 则抛出 OOM。堆内存出现 OOM 的概率是所有内存耗尽异常中最高的。出错时的堆内信息对解决问题非常有帮助，所以给 JVM 设置运行参数 `-XX:+HeapDumpOnOutOfMemoryError` ，让 JVM 遇到 OOM 异常时能输出堆内信息，特别是对相隔数月才出现的 OOM 异常尤为重要。

在不同的 JVM 实现及不同的回收机制中，堆内存的划分方式是不一样的。

2. Metaspace（元空间）

本书源码解析和示例代码基本采用 JDK11 版本， JVM 则为 Hotspot。早在 JDK8 版本中，元空间的前身 Perm 区已经被淘汰。在 JDK7 及之前的版本中，只有 Hotspot 才有 Perm 区，译为永久代，它在启动时固定大小，很难进行调优，并且 FGC 时会移动类元信息。在某些场景下，如果动态加载类过多，容易产生 Perm 区的 OOM。比如某个实际 Web 工程中，因为功能点比较多，在运行过程中，要不断动态加载很多的类，经常出现致命错误。

![1566117033363](E:\git_repo\Hao_Learn\2019\8\img\1566117033363.png)

为了解决该问题，需要设定运行参数 `-XX:MaxPermSize = 1280m`，如果部署到新机器上，往往会因为 JVM 参数没有修改导致故障再现。不熟悉此应用的人排查问题时往往苦不堪言，除此之外，永久代在垃圾回收过程中还存在诸多问题。所以， JDK8 使用元空间替换永久代。在 JDK8 及以上版本中，设定MaxPermSize数， JVM 在启动时并不会报锚，但是会提示：
`Java HotSpot 64Bit Server VM warning: ignoring option MaxPem1Size=2560m; support was removed in 8.0`

区别于永久代，元空间在本地内存中分配。在 JDK8 里，Perm 区中的所有内容中，字符串常量移至堆内存，其他内容包括类元信息、字段、静态属性、方法、常量等都移动至元空间内。

3. JVM Stack（虚拟机栈）

栈（Stack ）是一个先进后出的数据结构，就像子弹的弹夹，最后压入的子弹先发射，压在底部的子弹最后发射，撞针只能访问位于顶部的那一颗子弹。

相对于基于寄存器的运行环境来说，JVM是基于栈结构的运行环境。栈结构移植性更好，可控性更强。JVM中的虚拟机栈是描述 Java 方法执行的内存区域，它是线程私有的。栈中的元素用于支持虚拟机进行方法调用。每个方法从开始调用到执行完成的过程，就是栈帧从入栈到出栈的过程。在活动线程中，只有位于栈顶的帧才是有效的，称为当前枝帧，正在执行的方法称为当前方法，栈帧是方法运行的基本结构。在执行引擎运行时，所有指令都只能针对当前栈帧进行操作。而 StackOverflowError 表示请求的栈溢出，导致内存耗尽，通常出现在递归方法中。

![1566118162183](E:\git_repo\Hao_Learn\2019\8\img\1566118162183.png)

虚拟机栈通过压栈和出栈的方式，对每个方法对应的活动栈帧进行运算处理，方法正常执行结束，肯定会跳转到另一个栈帧上。在执行的过程中，如果出现异常，会进行异常回溯，返回地址通过异常处理表确定。栈帧在整个 JVM 体系中的地位颇高，包括局部变量表、操作栈、动态连接、方法返回地址等。

- **局部变量表**是存放方法参数和局部变量的区域。相对于类属性变量的准备阶段和初始化阶段来说，局部变量没有准备阶段，必须显式初始化。如果是非静态方法，则在index[0]位置上存储的是方法所属对象的实例引用，随后存储的是参数和局部变量。字节码指令中的 STORE 指令可以将操作栈中计算完成的局部变量写回局部变量表的存储空间内。

- **操作栈**是一个初始状态为空的桶式结构栈。在方法执行过程中，会有各种指令往栈中写入和提取信息。JVM 的执行引擎是基于栈的执行引擎，其中的栈指的就是操作栈。字节码指令集的定义都是基于栈类型的，栈的深度在方法元信息的 stack 属性中，下面用一段简单的代码说明操作栈与局部变量表的交互：

![1566119766352](E:\git_repo\Hao_Learn\2019\8\img\1566119766352.png)

第 1 处说明：局部变量表就像一个中药柜，里面有很多抽屉，依次编号为 0, 1, 2, 3, ...  , n ，字节码指令 ISTORE_1 就是打开 1号抽屉，把栈顶中的数 13 存进去。栈是一个很深的竖桶，任何时候只能对桶口元素进行操作，所以数据只能在栈顶进行存取。某些指令可以直接在抽屉里进行，比如 iinc 指令，直接对抽屉里的数值进行＋1操作。程序员面试过程中， 常见的 i++ 和 ++i 的区别，可以从字节码上对比出来，如表 4-1 所示。

![1566120192626](E:\git_repo\Hao_Learn\2019\8\img\1566120192626.png)

在表 4-1 左列中， iload_1 从局部变量表的第 1 号抽屉里取出一个数 ，压入栈顶，下一步直接在抽屉里实现 +1 的操作， 而这个操作对栈顶元素的值没有影响 。所以 istore_2 只是把栈顶元素赋值给 a；表格右列，先在第 1 号抽屉里执行 +1 操作，然后通过 iload_1 把第 1 号抽屉里的数压入栈顶， 所以 istore_2 存入的是 +1 之后的值。

这里延伸一个信息 ，i++ 并非原子操作。即使通过 volatile 关键字进行修饰，多个线程同时写的话，也会产生数据互相覆盖的问题。

- 每个栈帧中包含一个在常量池中对当前方法的引用，目的是支持方法调用过程的**动态连接**。

- 方法执行时有两种退出情况：第一，正常退出，即正常执行到任何方法的返回字节码指令，如RETURN、IRETURN、ARETURN 等；第二， 异常退出。无论何种退出情况，都将返回至方法当前被调用的位置。 方法退出的过程相当于弹出当前栈帧，退出可能有三种方式：
	- 返回值压入上层调用栈帧。
	- 异常信息抛给能够处理的栈帧。
	- PC 计数器指向方法调用后的下一条指令。

4. Native Method Stacks （本地方法栈）

本地方法栈（ Native Method Stack ）在 JVM 内存布局中，也是线程对象私有的，但是虚拟机栈 “主内”， 而本地方法栈 “主外”。这个“内外” 是针对 JVM 来说的，本地方法栈为 Native 方法服务。线程开始调用本地方法时，会进入一个不再受 JVM 约束的世界。本地方法可以通过 JNI ( Java Native Interface）来访问虚拟机运行时的数据区 ，甚至可以调用寄存器，具有和 JVM 相同的能力和权限。当大量本地方法出现时，势必会削弱 JVM 对系统的控制力，因为它的出错信息都比较黑盒。对于内存不足的情况，本地方法栈还是会抛出 `native heap OutOfMemory`

重点说一下 JNI 类本地方法。最著名的本地方法应该是System.currentTimeMillis() , JNI 使 Java 深度使用操作系统的特性功能，复用非 Java 代码。但是在项目过程中，如果大量使用其他语言来实现 JNI 就会丧失跨平台特性，威胁到程序运行的稳定性。假如需要与本地代码交互，就可以用中间标准框架进行解耦，这样即使本地方法崩溃也不至于影响到 JVM 的稳定。当然，如果要求极高的执行效率、偏底层的跨进程操作等，可以考虑设计为 JNI 调用方式。

5. Program Counter Register（程序计数寄存器）

在程序计数寄存器（Program Counter Register, PC）中， Register 的命名源于 CPU 的寄存器， CPU 只有把数据装载到寄存器才能够运行。寄存器存储指令相关的现场信息，由于 CPU 时间片轮限制，众多线程在并发执行过程中，任何一个确定的时刻，一个处理器或者多核处理器中的一个内核，只会执行某个线程中的一条指令。这样必然导致经常中断或恢复，如何保证分毫无差呢？每个线程在创建后，都会产生自己的程序计数器和栈帧，程序计数器用来存放执行指令的偏移量和行号指示器等，线程执行或恢复都要依赖程序计数器。程序计数器在各个线程之间互不影响，此区域也不会发生内存溢出异常。

最后，从线程共享的角度来看，堆和元空间是所有线程共享的，而虚拟机栈、本
地方法栈、程序计数器是线程内部私有的。

![1566121254574](E:\git_repo\Hao_Learn\2019\8\img\1566121254574.png)

#### 4.4 对象实例化

Java 是面向对象的静态强类型语言，声明并创建对象的代码很常见，根据某个类声明一个引用变量指向被创建的对象，并使用此引用变量操作该对象。在实例化对象的过程中，JVM 中发生了什么化学反应呢？

1. 下面从最简单的 `Object ref = new Object()` 代码进行分析，利用 `javap -verbose -p` 命令查看对象创建的字节码如下：

![1566123921007](E:\git_repo\Hao_Learn\2019\8\img\1566123921007.png)

- NEW：如果找不到 Class 对象，则进行类加载。加载成功后，则在堆中分配内存，从 Object 开始到本类路径上的所有属性值都要分配内存。分配完毕之后，进行零值初始化。在分配过程中，注意引用是占据存储空间的，它是一个变量，占用 4 个字节。这个指令完毕后，将指向实例对象的引用变量压入虚拟机栈顶。

- DUP：在栈顶复制该引用变量，这时的栈顶有两个指向堆内实例对象的引用变量。如果＜init> 方法有参数，还需要把参数压入操作栈中。两个引用变量的目的不同，其中压至底下的引用用于赋值，或者保存到局部变量表，另一个栈顶的引用变量作为句柄调用相关方法。
- INVOKESPECIAL：调用对象实例方法，通过栈顶的引用变量调用`＜init>` 方法。`<clinit>` 是类初始化时执行的方法 而`＜init>` 是对象初始化时执行的方法。

2. 前面所述的是从字节码的角度看待对象的创建过程，现在从执行步骤的角度来分析：

- 确认类元信息是否存在。当 JVM 接收到 new 指令时，首先在 metaspace 内检查需要创建的类元信息是否存在。若不存在，那么在双亲委派模式下，使用当前类加载器以ClassLoader＋包名＋类名为 Key 进行查找对应的 .class 文件。如果没有找到文件，则抛出 ClassNotFoundException 异常，如果找到，则进行类加载，并生成对应的 Class 类对象。
- 分配对象内存。首先计算对象占用空间大小，如果实例成员变量是引用变量，仅分配引用变量空间即可，即 4个字节大小，接着在堆中划分一块内存给新对象。在分配内存空间时，需要进行同步操作，比如采用 CAS ( Compare And Swap ）失败重试、区域加锁等方式保证分配操作的原子性。
- 设定默认值。成员变量值都需要设定为默认值，即各种不同形式的零值。
- 设置对象头。设置新对象的哈希码、 GC 信息、锁信息、对象所属的类元信息等。这个过程的具体设置方式取决于 JVM 实现。
- 执行 init 方法。初始化成员变量，执行实例化代码块，调用类的构造方法，并把堆内对象的首地址赋值给引用变量。

## 4.5 垃圾回收

Java 会对内存进行自动分配与回收管理，使上层业务更加安全，方便地使用内存实现程序逻辑。在不同的 JVM 实现及不同的回收机制中，堆内存的划分方式是不一样的。这里简要介绍垃圾回收（ Garbage Collection, GC ）。垃圾回收的主要目的是清除不再使用的对象，自动释放内存。

GC 如何判断对象是否可以被回收的呢？为了判断对象是否存活，JVM 引入了GC Roots 。如果 一个对象与 GC Roots 之间没有直接或间接的引用关系，比如某个失去任何引用的对象，或者两个互相环岛状循环引用的对象等，判决这些对象“死缓”，是可以被回收的。什么对象可以作为 GC Roots 呢？比如类静态属性中引用的对象、常量引用的对象、虚拟机栈中引用的对象、本地方法栈中引用的对象等。

有了判断对象是否存活的标准后，再了解一下垃圾固收的相关算法。最基础的为`标记－清除算法`，该算法会从每个 GC Roots 出发，依次标记有引用关系的对象，最后将没有被标记的对象清除。但是这种算法会带来大量的空间碎片，导致需要分配一个较大连续空间时容易触发 FGC。为了解决这个问题，又提出了`标记－整理算法`，该算法类似计算机的磁盘整理，首先会从 GC Roots 出发标记存活的对象，然后将存活对象整理到内存空间的一端，形成连续的已使用空间，最后把已使用空间之外的部分全部清理掉，这样就不会产生空间碎片的问题。`Mark-Copy 算法`，为了能够并行地标记和整理将空间分为两块，每次只激活其中一块，垃圾回收时只需把存活的对象复制到另一块未激活空间上，将未激活空间标记为己激活，将己激活空间标记为未激活，然后清除原空间中的原对象。堆内存空间分为较大的Eden 和两块较小 Survivor ，每次只使用 Eden 和 Survivor 的一块。这种情形下的`Mark-Copy 算法`减少了内存空间的浪费。`Mark-Copy 算法`现作为主流的 YGC 算法进行新生代的垃圾回收。

垃圾回收器（ Garbage Collector ）是实现垃圾回收算法并应用在 JVM 环境中的内存管理模块。当前实现的垃圾回收器有数十种，本节只介绍 Serial 、CMS、G1三种。

Serial 回收器是一个主要应用于 YGC 的垃圾回收器，采用串行单线程的方式完 GC 任务，其中` Stop The World `简称 STW ，即垃圾回收的某个阶段会暂停整个应用程序的执行。 FGC 的时间相对较长，频繁 FGC 会严重影响应用程序的性能。主要流程如图 4-13 所示。

![1566125416917](E:\git_repo\Hao_Learn\2019\8\img\1566125416917.png)

CMS 回收器（ Concurrent Mark Sweep Collector ）是回收停顿时间比较短、目前比较常用的垃圾回收器。它通过初始标记（ Initial Mark ）、并发标记（ Concurrent Mark ）、重新标记（ Remark ） 、并发清除（ Concurrent Sweep）四个步骤完成垃圾回收工作。第 1、3 步的初始标记和重新标记阶段依然会引发 STW ，而第 2、4 步的并发标记和并发清除两个阶段可以和应用程序并发执行，也是比较耗时的操作，但并不影响应用程序的正常执行。由于 CMS 采用的是 `标记－清除算法`，因此产生大量的空间碎片。为了解决这个问题， CMS 可以通过配置 `-XX:+UseCMSCompactAtFullCollection` 参数，强制 JVM 在 FGC 完成后对老年代进行压缩， 执行一次空间碎片整理，但是空间碎片整理阶段也会引发 STW 。为了减少 STW 次数， CMS 还可以通过配置`-XX:+CMSFullGCsBeforeCompaction=n` 参数，在执行了 n次 FGC 后， JVM 再在老年代执行空间碎片整理。

Hotspot 在 JDK7 推出了新一代 G1 ( Garbage-First Garbage Collector）垃圾回收，通过`-XX:+UseG1GC` 参数启用。和 CMS 相比， G1具备压缩功能，能避免碎片问题，G1 的暂停时间更加可控。性能总体还是非常不错的，简要结构如图 4-14 所示。

![1566125868295](E:\git_repo\Hao_Learn\2019\8\img\1566125868295.png)

G1 将 Java 堆空间分割成了若干相同大小的区域，即 region ，包括 Eden、Survivor、Old、Humongous 四种类型。其中， Humongous 是特殊的 Old 类型，专门放置大型对象。这样的划分方式意味着不需要一个连续的内存空间管理对象。G1将空间分为多个区域，优先回收垃圾最多的区域。 G1 采用的是`Mark-Copy 算法`，有非常好的空间整合能力，不会产生大量的空间碎片。G1 的一大优势在于可预测的停顿时间，能够尽可能快地在指定时间内完成垃圾回收任务。在 JDK11中，已经将 G1 设为默认垃圾回收器，通过 jstat 命令可以查看垃圾回收情况，如图 4-15 所示，在 YGC 时 S0/S1 并不会交换。

![1566126093204](E:\git_repo\Hao_Learn\2019\8\img\1566126093204.png)

S0/S1 的功能由 G1 中的 Survivor region 来承载。通过 GC 日志可以观察到完整的垃圾回收过程如下，其中就有 Survivor regions 的区域从 0个到 1个。

![1566126128284](E:\git_repo\Hao_Learn\2019\8\img\1566126128284.png)

红色标识的为 G1 中的四种 region 都处于 Heap 中。G1 执行时使用 4个 worker并发执行，在初始标记时，还是会触发 STW ，如第一步所示的 Pause。


# 第五章 异常与日志

如果异常在当前方法的处理能力范围之内且没有必要对外透出，那么就直接捕获异常并做相应处理；否则向上抛出，由上层方法或者框架来处理。

但是无论采用哪种方式处理异常，都严禁捕获异常后什么都不做或打印一行日志了事。如果在方法内部处理异常，需要根据不同的业务场景进行定制处理，如重试、回滚等操作。如果向上抛出异常，需要在异常对象中添加上下文参数、局部变量、运行环境等信息，这样有利于排查问题。

![1566197555436](E:\git_repo\Hao_Learn\2019\8\img\1566197555436.png)

在与数据库交互时可能会发生网络连接不通、数据库锁超时、插入数据失败等异常，向上归一化为 DAOException 异常。

## 5.1 异常分类

JDK 中定义了一套完整的异常机制，所有异常都是 Throwable 的子类，分为 Error（致命异常）和 Exception（非致命异常）。 Error 是一种非常特殊的异常类型，它的出现标识着系统发生了不可控的错误，例如 StackOverflowError 、OutOfMemoryError 。针对此类错误，程序无法处理，只能人工介入。 Exception 又分 checked 异常 （受检异常）和 unchecked 异常（非受检异常）。

checked 异常是需要在代码中显式处理的异常，否则会编译出错。常见的 checked 异常包括 JDK 中定义的 SQLException、ClassNotFoundException 等。

check 异常可以进一步细分为两类：

- 无能为力、引起注意型。针对此类异常，程序无法处理，如字段超长等导致SQLException，即使做再多的重试对解决异常也没有任何帮助，一般处理此类异常的做法是完整地保存异常现场，供开发工程师介入解决。
- 力所能及、坦然处置型。如发生未授权异常 （UnAuthorizedException），程序可跳转至权限申请页面。

在Exception中，unchecked 异常是运行时异常，它们都继承自 RuntimeException ，不需要程序进行显式的捕捉和处理，unchecked 异常可以进一步细分为 3 类：

- 可预测异常（Predicted Exception）：常见的可预测异常包括IndexOutOtBoundsException，NullPointerException等，基于对代码的性能和稳定性要求，此类异常不应该被产生或者抛出，而应该提前做好边界检查、空指针判断等处理。显式的声明或者捕获此类异常会对程序的可读性和运行效率产生很大影响。
- 需捕捉异常（Caution Exception），例如在使用 Dubbo 框架进行 RPC 调用时产生的远程服务超时异常 DubboTimeoutException，此类异常是客户端必须显式处理的异常，不能因服务端的异常导致客户端不可用，此时处理方案可以是重试或者降级处理等。
- 可透出异常（Ignored Exception），主要是指框架或系统产生的且会自行处理的异常，而程序无须关心。例如针对 Spring 框架中抛出的 NoSuchRequestHandlingMethodException 异常， Spring 框架会自己完成异常的处理，默认将自身抛出的异常自动映射到合适的状态码，比如启动防护机制跳转到 404 页面。

综上所述，异常分类结构如图 5-1 所示：

![1566198421276](E:\git_repo\Hao_Learn\2019\8\img\1566198421276.png)

## 5.2 try代码块

finally 代码块是必选执行的代码块，不管是否有异常产生，即使发生`OutOfMemoryError`也会执行，通常用于处理善后清理工作。如果 finally 代码块没有执行，那么有三种可能：

1. 没有进入 try 代码块。
2. 进入 try 代码块，但是代码运行中出现了死循环或死锁状态。
3. 进入 try 代码块，但是执行了 System.exit() 操作。

注意， finally 是在 return 表达式运行后执行的，此时将要 return 的结果已经被暂存起来，待finally 代码块执行结束后再将之前暂存的结果返回，但如果 finally 中有 return ，那么会返回finally 中的值。

finally 代码块的职责不在于对变量进行赋值等操作，而是清理资源、释放连接、关闭管道流等操作，例如 Lock、ThreadLocal、InputStream 等这些需要进行强制释放和清除的对象都得在finally 代码块中进行显式的清理，避免产生内存泄漏，或者资源消耗。

分析 try 代码块与锁的关系：
lock 方法可能会抛出 unchecked 异常，如果放在 try 代码块中，必然触发 finally 中的 unlock 方法执行。对未加锁的对象解锁会抛出 unchecked 异常，如 IllegalMonitorStateException 虽然是因为加锁失败而造成程序中断的，但是真正加锁失败的原因可能会被后者覆盖。所以在 try 代码块之前调用lock() 方法，避免由于加锁失败导致 finally 调用 unlock() 抛出异常。

## 5.3 异常的抛与接

我们要使捕获的异常与被抛出的异常是完全匹配的，或者捕获的异常是被抛出异常的父类。

传递异常信息的方式是通过抛出异常对象，还是把异常信息转成信号量封装在特定对象中，这需要方法提供者和方法调用者之间达成契约，只有大家都照章办事，才不会产出误解。推荐对外提供的开放接口使用错误码；公司内部跨应用远程服务调用优先考虑使用 Result 对象来封装错误码、错误描述信息；而应用内部则推荐直接抛出异常对象。

如果使用抛异常的返回方式，一旦调用方没有捕获，就会产生运行时错误，导致程序中断；此外，如果抛出的异常中不添加栈信息，只是 new 自定义异常并加入自定义的错误信息，对于调用端解决问题的帮助不会太大；如果加了栈信息，在频繁调用出错的情况下，信息序列化和传输的性能损耗也是问题。所以推荐在远程服务调用中使用 Result 对象封装异常信息。

我们推荐方法的返回值可以为 null ，不强制返回空集合或者空对象等，但是必须添加注释充分说明什么情况下会返回 null 值。防止 NPE 一定是调用方的责任，需要调用方进行事先判断。

## 5.4 日志

记录应用系统日志主要有三个原因：记录操作轨迹、监控系统运行状况、回溯系统故障。

记录操作行为及操作轨迹数据，可以数据化地分析用户偏好，有助于优化业务逻辑，为用户提供个性化的服务。例如，通过 access.log 记录用户的操作频度和跳转链接，有助于分析用户的后续行为。

全面有效的日志系统有助于建立完善的应用监控体系，由此工程师可以实时监控系统运行状况，及时预警，避免故障发生。监控系统运行状况，是指对服务器使用状态，如内存、 CPU 等使用情况；应用运行情况，如响应时间，QPS 等交互状态；应用错误信息，如空指针、 SQL 异常等的监控。

当系统发生线上问题时，完整的现场日志有助于工程师通过回溯系统故障快速定位问题。

#### 日志规范

推荐的日志文件命名方式为 `appName_logType_logName.log`。其中 logType 为日志类型，推荐分类有 stats、monitor、visit 等；logName 为日志描述。这种命名的好处是通过文件名就可以知道日志文件属于什么应用，什么类型 ，什么目的，也有利于归类查找。

如果日志存储周期较短，如 7 天，那么针对有些具备以“周”为频次发生的异常就无法被发现，相反，若日志保存周期过长，又会对磁盘存储空间造成较大压力，产生不必要的资源消耗。因此综合两个方面考虑，代码规约推荐日志文件至少保存 7 天，可以根据日志文件的重要程度、
文件大小及磁盘空间再自行延长保存时间。

日志是有级别的。针对不同的场景，日志被分为五种不同的级别，按照重要程度由低到高排序：

- DEBUG 级别日志：记录对调试程序有帮助的信息。
- INFO 级别日志：用来记录程序运行现场，虽然此处并未发生错误，但是对排查其他错误具有指导意义。
- WARN 级别日志：也可以用来记录程序运行现场，但是更偏向于表明此处有出现潜在错误的可能。
- ERROR 级别日志：表明当前程序运行发生了错误，需要被关注。但是当前发生的错误，没有影响系统的继续运行。
- FATAL 级别日志：表明当前程序运行出现了严重的错误事件，并且将会导致应用程序中断。

1. 预先判断日志级别

对于 DEBUG 、INFO 级别的日志，必须使用条件输出或者使用占位符的方式打印。该约定综合考虑了程序的运行效率和日志打印需求。

![1566202502986](E:\git_repo\Hao_Learn\2019\8\img\1566202502986.png)

2. 避免无效日志打印

生产环境禁止输出 DEBUG 日志且有选择地输出 INFO 日志。
使用 INFO、 WARN 级别来记录业务行为信息时，一定要控制日志输出量，以免磁盘空间不足。同时要为日志文件设置合理的生命周期，及时清理过期的日志。
避免重复打印，务必在日志配置文件中设置 `additiviity=false` ，示例如下：
`<loggername= "com.taobao.ecrm.member.config" additivity=” false" >`

3. 区别对待错误日志

ERROR 级别日志只记录系统逻辑错误、异常或者违反重要的业务规则，一旦出现就需要人为介入。其他错误都可以归为 WARN级别。

4. 保证记录内容完整

日志记录的内容包括现场上下文信息与异常堆栈信息，所以打印时需要注意以下两点：

- 记录异常时，一定要输出异常堆栈，例如：`logger.error("xxx"+e.getMessage(),e)`
- 日志中如果输出对象实例，要确保实例类重写了 toString ()，否则只会输出对象的 hashCode 值，没有实际意义。

综上所述，日志是一个系统必不可少的组成部分，但日志打印并非多多益善，过多的日志会降低系统性能，也不利于快速定位问题，所以记录日志时一定请思考三个问题： ①日志是否有人看； ②看到这条日志能做什么 ；③能不能提升问题排查效率。

#### 日志框架

日志框架分为三大部分，包括日志门面、日志适配器、日志库。利用门面设计模式，即Facade  来进行解耦，使日志使用变得更加简单。

![1566203205629](E:\git_repo\Hao_Learn\2019\8\img\1566203205629.png)

1. 日志门面

门面设计模式是面向对象设计模式中的一种，日志框架采用的就是这种模式，类似 JDBC 的设计理念。它只提供一套接口规范，自身不负责日志功能的实现，目的是让使用者不需要关注底层具体是哪个日志库来负责日志打印及具体的使用细节等。目前用得最为广泛的日志门面有两种： slf4j 和 commons-logging 。

2. 日志库

它具体实现了日志的相关功能，主流的日志库有三个，分别是 log4j、log-jdk、logback。最早 Java 要想记录日志只能通过 System.out 或 System. error 来完成，非常不方便。log4j 就是为了解决这一问题而提出的，它是最早诞生的日志库。接着 JDK 也在 1.4 版本引入了一个日志库 `java.util.logging.Logger`，简称 log-jdk。这样市面上就出现两种日志功能的实现，开发者在使用时需要关注所使用的日志库的具体细节。logback 是最晚出现的，它与 log4j 出自同一个作者，是log4j 的升级版且本身就实现了 slf4j 的接口。

3. 日志适配器

日志适配器分两种场景：

- 日志门面适配器，因为 slf4j 规范是后来提出的，在此之前的日志库是没有实现 slf4j 的接口的，例如 log4j；所以，在工程里要想使用 slf4j + log4j 的模式，就额外需要一个适配器（slf4j- log4j12）来解决接口不兼容的问题。
- 日志库适配器，在一些老的工程里，一开始为了开发简单而直接使用了日志库API来完成日志打印，随着时间的推移想将原来直接调用日志库的模式改为业界标准的门面模式（例如 slf4j+logback组合），但老工程代码里打印日志的地方太多了，难以改动，所以需要一个适配器来完成从旧日志库的 API 到 slf4j 的路由，这样在不改动原有代码的情况下也能使用 slf4j 来统一管理日志，而且后续自由替换具体日志库也不成问题。

以 Maven工程为例介绍如何在工程里进行日志集成。
如果是新工程，则推荐使用 slf4j + logback 模式。因为 logback 自身实现了 slf4j的接口，无须额外引入适配器，另外 logback 是 log4j 的升级版，具备比 log4j 更多的优点，可通过如下配置进行集成：

```xml
<dependency>
    <groupid>org.slf4]</groupid>
    <artifactid>slf4j-api</artifactid>
    <version>${slf4j-api.version}</version>
</dependency>
<dependency>
    <groupid>ch.qos.logback</groupid>
    <artifactid>logback-classic</artifactid>
    <version>${logback-classic.version}</version>
</dependency>
<dependency>
    <groupid>ch.qos.logback</groupid>
    <artifactid>logback core</artifactid>
    <version>${logback-core.version}</version>
</dependency> 
```
再加上一个日志配置文件（如logback.xml、log4j.xml 等），并在工程启动时加载，然后就可以进行日志打印了，示例代码如下·

```Java
private static final Logger logger= LoggerFactory.getLogger(Abc.class); 
```

注意，logger 被定义为 static 变量，是因为这个 logger 与当前类绑定，避免每次 new 一个新对象，造成资源浪费，甚至引发 OutOfMernoryError 问题。

另外，在使用 slf4j＋日志库模式肘，要防止日志库冲突，一旦发生则可能会出现日志打印功能失效的问题。

# 第六章 数据结构与集合

## 6.1 数据结构

#### 数据结构定义

数据结构是指逻辑意义上的数据组织方式及其相应的处理方式。

1. 什么是逻辑意义？

数据结构的抽象表达非常丰富，而实际物理存储的方式相对单一。比如，二叉树在磁盘中的存储真的是树形排列吗？并非如此。树的存储可能是基于物理上的顺序存储方式，可以理解为一个格子一个格子连续地放，设想有 7 个节点的二叉树，第一个格子放根节点，第二个格子放左子树根节点；并且根据引用知道左叶子在后续的哪个格子里，第三个格子放右子树根节点，依此类推。此外，树的存储也可能是基于物理上的链式存储方式，这里不再详细展开。

2. 什么是数据组织方式？

逻辑意义上的组织方式有很多，比如树、图、队列、哈希等。树可以是二叉树、三叉树、 B+树等，图可以是有向图或无向图，队列 是先进先出的线性结构；哈希是根据某种算法直接定位的数据组织方式。

3. 什么是数据处理方式？

在既定的数据组织方式上，以某种特定的算法实现数据的增加、删除、修改、查找和遍历。不同的数据处理方式往往存在着非常大的性能差异。

#### 数据结构分类

数据结构是算法实现的基石，它是一种体现基础逻辑思维的内功心法，也是计算机从业人员能力图谱中的重要一项。如果完全不懂数据结构，很难写出优秀的代码。有缺陷的底层数据结构容易导致系统风险高、可扩展性差，所以需要认真地对数据结构进行设计和评审。从直接前继和直接后继个数的维度来看，大体可以将数据结构分为以下四类。

1. 线性结构

0 至 1个直接前继和直接后继。当线性结构非空时，有唯一的首元素和尾元素，除两者外，所有的元素都有唯一的直接前继和直接后继。线性结构包括顺序表、链表、栈、队列等，其中栈和队列是访问受限的结构。栈是后进先出，即 Last In，First-Out ，简称 LIFO ；队列是先进先出，即 First-In，First-Out ，简称 FIFO 。

2. 树结构

0 至 1 个直接前继和 0 至 n 个直接后继（n 大于或等于 2）。树是一种非常重要的有层次的非线性数据结构，像自然界的树一样。由于树结构比较稳定和均衡，在计算机领域中得到广泛应用。

3. 图结构

0 至 n 个直接前继和直接后继（n 大于或等于 2）。图结构包括简单图、多重图、有向图和无向图等。

4. 哈希结构

没有直接前继和直接后继。哈希结构通过某种特定的哈希函数将索引与存储的值关联起来，他是一种查找效率非常高的数据结构。

不同的数据组织方式和处理方式带来了一个新的问题：如何衡量数据处理的性能。

数据结构的复杂度分为空间复杂度和时间复杂度两种，在存储设备越来越便宜的情况下，时间复杂度成为重点考量的因素。算法时间复杂度是一种衡量计算性能的指标，反映了程序执行时间随输入规模增长而增长的量级，在很大程度上能够反映出算法性能的优劣与否。而这个量级通常用大写的 *O* 和一个函数描述，如 *O*(*n*^3^) 表示程序执行时间随输入规模呈现三次方倍的增长，这是比较差的算法实现。从最好到最坏的常用算法复杂度排序如下：常数级 *O*(1) 、对数级 *O*(log*n*) 、线性级 *O*(*n*)  、线性对数级 *O*(*n*logn)  、平方级 *O*(*n*^2^)、立方级 *O*(*n*^3^) 、指数级 *O*(2^n^) 等。有人觉得在实际编程中没有必要去纠结算法复杂度，因为现实中的数据量有限，执行时间相差无几。但是，数据规模并非静止不变，优秀的程序实现不会因为数据规模的急剧上升导致程序性能的急剧下降。

最后以 “猜数字” 为例进一步理解时间复杂度，主持人从`1 ~ 100` 的范围内任选一个数字，玩家随机猜一个数，如果没有猜中，主持人会提示猜大了还是猜小了，继续这样的循环 ，直到猜对为止。显而易见，如果要猜测，最多要猜 100 次，最少只用猜 1 次。经验表明，玩家总会往中间砍一段，平均猜测次数总在七八次左右。通过模拟程序运行 1 亿次，完全随机的情况下，平均猜测的次数是 7.47 次， 近似二分法猜测的是 5.8 次，时间复杂度为 *O*(log*n*) 。

## 6.2 集合框架图

![1566207900950](E:\git_repo\Hao_Learn\2019\8\img\1566207900950.png)

在集合框架图中，红色代表接口，蓝色代表抽象类，绿色代表并发包中的类，灰色代表早期线程安全的类（基本已经弃用）。可以看到，与 Collection 相关的 4 条线分别是 List、Queue、Set、Map，它们的子类会映射到数据结构中的表、树、哈希等。对集合框架图的深刻理解，有利于对集合的宏观把控，并写出更高质量的程序。

#### List 集合

List 集合是线性数据结构的主要实现，集合元素通常存在明确的上一个和下一个元素，也存在明确的第一个元素和最后一个元素。List 集合的遍历结果是稳定的。该体系最常用的是 ArrayList 和 LinkedList 两个集合类。

Array List 是容量可以改变的非线程安全集合。内部实现使用数组进行存储，集合扩容时会创建更大的数组空间，把原有数据复制到新数组中。 ArrayList 支持对元素的快速随机访问，但是插入与删除时速度通常很慢，因为这个过程很有可能需要移动其他元素。

LinkedList 的本质是双向链表。与 ArrayList 相比 ，LinkedList 的插入和删除速度更快，但是随机访问速度则很慢。测试表明，对于 10 万条的数据，与 ArrayList 相比，随机提取元素时存在数百倍的差距。除继承 AbstractList 抽象类外， LinkedList 还实现了另一个接口 Deque ，即 `double-ended queue` 。这个接口同时具有队列和栈的性质。LinkedList 包含 3 个重要的成员：size 、frist 、last。size 是双向链表中节点的个数。first 和 last 分别指向第一个和最后一个节点的引用。 LinkedList 的优点在于可以将零散的内存单元通过附加引用的方式关联起来，形成按链路顺序查找的线性结构，内存利用率较高。

#### Queue 集合

Queue（ 队列 ）是一种先进先出的数据结构，队列是一种特殊的线性表，它只允许在表的一端进行获取操作，在表的另一端进行插入操作。当队列中没有元素时，称为空队列。自从 BlockingQueue （阻塞队列 ）问世以来，队列的地位得到极大的提升，在各种高并发编程场景中，由于其本身 FIFO 的特性和阻塞操作的特点，经常被作为 Buffer（数据缓冲区）使用。

#### Map 集合

Map 集合是以 `Key-Value` 键值对作为存储元素实现的哈希结构， Key 按某种哈希函数计算后是唯一的，Value 则是可以重复的。 Map 类提供三种 Collection 视图，在集合框架图中，Map 指向 Collection 的箭头仅表示两个类 间的依赖关系，可以使用keySet() 查看所有的 Key，使用 values() 查看所有的Value ，使用 entrySet() 查看所有的键值对。最早用于存储键值对的 Hashtable 因为性能瓶颈已经被淘汰，而如今广泛使用的 HashMap 线程是不安全的。ConcurrentHashMap 是线程安全的，在 JDK8 进行了锁的大幅度优化，体现出不错的性能。在多线程并发场景中，优先推荐使 ConcurrentHashMap ，而不是 HashMap 。TreeMap 是 Key 有序的 Map 类集合。

#### Set 集合

Set 是不允许出现重复元素的集合类型。 Set 体系最常用的是 HashSet , TreeSet 和 LinkedHashSet 三个集合类。 HashSet 从源码分析是使 HashMap 来实现的，只是 Value 固定为一个静态对象，使用 Key 保证集合元素的唯一性，但它不保证集合元素的顺序。 TreeSet 也是如此，从源码分析是使用 TreeMap 来实现的，底层为树结构，在添加新元素到集合中时，按照某种比较规则将其插入合适的位置，保证插入后的集合仍然是有序的。 LinkedHashSet 继承自HashSet，具有HashSet 的优点，内部使用链表维护了元素插入顺序。

## 6.3 集合初始化

集合初始化通常进行分配容量 、设置特定参数等相关工作。我们以使用频率较高 ArrayList 和 HashMap 为例，简要说明初始化的相关工作，并解释为什么在任何情况下，都需要显式地设定集合容量的初始大小。ArrayList 是存储单个元素的顺序表结构， HashMap 是存储 KV 键值对的哈希式结构。分析两者的初始化相关源码，洞悉它们的容量分配、参数设定等相关逻辑，有助于更好地了解集合特性，提升代码质量。
下面先从 ArrayList 源码说起：

![1566222017510](E:\git_repo\Hao_Learn\2019\8\img\1566222017510.png)

第 1 处说明：正数带符号右移的值肯定是正值，所以 `oldCapacity + (oldCapacity >> 1)`的结果可能超过 int 可以表示的最大值，反而有可能比参数的 minCapacity 更小，则返回值为 (size + 1) 的 minPacacity。
注意：
`Integer.MAX_VALUE + 1 = -2147483648`；
`Integer.MIN_VALUE - 1 = 2147483647`

第 2 处说明：如果原始容量是 13 ，当新添加 1 个元素时，依据程序中的计算方法得出 13 的二进制数为 1101 ，随后右移 1 位操作后得到二进制数 110 ，即十进制数 6 ，最终扩容的大小计算结果为 `oldCapacitiy + (oldCapacity >> 1) = 13 + 6 = 19` 。使用位运算主要是基于计算效率的考虑。在 JDK7 之前的公式，扩容计算方式和结果为 `oldCapacitiy × 3 ÷ 2 + 1 = 13 × 3 ÷ 2 + 1 = 20`

ArrayList 真正数据的数组由 transient 修饰，表示此字段在类的序列化时将被忽略。因为集合序列化时系统会调用 writeObject 写入流中，在网络客户端反序列化的 readObject 时，会重新赋值到新对象的 elementData 中。为什么多此一举？因为 elementData 容量经常会大于实际存储元素的数 ，所以只需发送真正有实际值的数组元素即可。

ArrayList 使用无参构造时，默认大小为 10 ，也就是说在第一次 add 的时候分配为 10 的容量，后续的每次扩容都会调用 Array.copyOf 方法，创建新数组再复制。可以想象，假如需要将 1000 个元素放置在 ArrayList ，采用默认构造方法，则需要被动扩容 13 次才可以完成存储。若初始化时便指定了容量的初始大小，可以**避免被动扩容和数组复制的额外开销**。最后，进一步设想，如果这个值达到更大量级， 却没有注意初始的容量分配问题，那么无形中造成的性能损耗是非常大的，甚至导致 OOM 的风险。

再来看一下 HashMap ，如果它需要放置 1000 个元素 ，同样没有设置初始容量大小，随着元素的不断增加，则需要被动扩容 7 次才可以完成存储。扩容时需要重建 hash 表非常影响性能。在 HashMap 中有两个比较重要的参数：Capacity Load Factor ，其中 Capacity 决定了存储容量的大小，默认为 16 ，而 LoadFactor 决定了填充比例，一般使用默认的 0.75 。基于这两个参数的乘积， HashMap 内部用 threshold 变量表示 HashMap 中能放入的元素个数。HashMap 容量并不会在 new 的时候分配，而是在第一次 put 的时候完成创建的，源码如下：

```Java
public V put(K key, V value) {
	if (table == EMPTY_TABLE) {
		inflateTable(threshold);
	}
	// ...
}

private void inflateTable(int toSize) {
	// Find a power of 2 >= toSize
	int capacity = roundUpToPowerOf2(toSize);

	threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1);
	table = new Entry[capacity];
	initHashSeedAsNeeded(capacity);
}

final boolean initHashSeedAsNeeded(int capacity) {
	boolean currentAltHashing = hashSeed != 0;
	boolean useAltHashing = sun.misc.VM.isBooted() &&
			(capacity >= Holder.ALTERNATIVE_HASHING_THRESHOLD);
	boolean switching = currentAltHashing ^ useAltHashing;
	if (switching) {
		hashSeed = useAltHashing
			? sun.misc.Hashing.randomHashSeed(this)
			: 0;
	}
	return switching;
}
```

为了提高运算速度，设定 HashMap 容量大小为 2^n^，这样的方式使计算落槽位置更快。如果初始化 HashMap 的时候通过构造器指定了 initialCapacity ，则会先计算出比 initialCapacity 大的 2 的幂存入 threshold ，在第一次 put 时会按照这个 2 的幂初始化数组大小，此后每次扩容都是增加 2 倍。如果没有指定初始值， log~2~1000 = 9.96 ，结合源码分析可知，如果想要容纳 1000 个元素，必须经过 7 次扩容。HashMap 的扩容还是有不小的成本的，如果提前能够预估出 HashMap 内要放置的元素数量，就可以在初始化时合理设置容量大小，避免不断扩容带来的性能损耗。

综上所述，集合初始化时，指定集合初始值大小。如果暂时无法确定集合大小，
那么指定相应的默认值，这也要求我们记得各种集合的默认值大小， ArrayList 大小为 10 ，HashMap 默认值为 16 。牢记每种数据结构的默认值和初始化逻辑 也是开发工程师基本素质的体现。

## 6.4 数组与集合

数组是一种顺序表，在各种高级语言中，它是组织和处理数据的一种常见方式，我们可以使用索引下标进行快速定位并获取指定位置的元素。数组的下标从 0 开始，但这并不符合生活常识，这源于 BCPL 语言，它将指针设置在 0 的位置，用数组下标作为直接偏移量进行计算。为什么下标不从 1 开始呢？如果是这样，计算偏移量就要使用当前下标减 1 的操作。加减法运算对 CPU 来说是一种双数运算，在数组下标使用频率极富的场景下，这种运算是十分耗时的。在 Java 体系中，数组用以存储同一类型的对象，一旦分配内存后则无法扩容。提倡类型与中括号紧挨相连来定义数组，因为在 Java 的世界里，万物皆为对象。

在 new String[] 的方括号内填写如果写的是负数，并不会编译出错，但运行时会抛出异常： NegativeArraySizeException 。

对于动态大小的数组，集合提供了 Vector、ArrayList 两个类，前者是线程安全，性能较差，基本弃用，而后者是线程不安全，它是使用频率最高的集合之一。

数组的遍历优先推荐 JDK5 引进的 foreach 方式，即 for(类型 元素名:数组名)的方式，可以在不使用下标的情况下遍历数组，也可以使用 JDK8 的函数式接口进行遍历：
```Java
Arrays.asList(args).stream().forEach(x -> System.out.println(x));
Arrays.asList(args).stream().forEach(System.out::println);
```
length 是数组对象的一个属性，而不是方法，但 String 类是使用 length() 方法来获取字符串长度的。

Arrays 是针对数组对象进行操作的工具类，包括数组的排序、查找、对比、拷贝等操作。尤其是排序，在多个 JDK 版本中在不断地进化，比如原来的归并排序改成 Timsort ，明显地改善了集合的排序性能。另外，通过这个工具类也可以把数组转成集合。

数组与集合都是用来存储对象的容器，前者性质单一，方便易用；后者类型安全，功能强大，且两者之间必然有互相转换的方式。毕竟它们的性格迥异，在转换过程中，如果不注意转换背后的实现方式，很容易产生意料之外的问题。转换分成两种情况，数组转集合和集合转数姐。在数组转集合的过程中，注意是否使用了视图方式直接返回数组中的数据。我们以 Arrays.asList()  为例，它把数组转换成集合时，不能使用其修改集合相关的方法，它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。示例源码如下：

![1566226560148](E:\git_repo\Hao_Learn\2019\8\img\1566226560148.png)

事实证明，可以通过 set() 方法修改元素的值，原有数组相应位置的值同时也会被修改，但是不能进行修改元素个数的任何操作，否则均会抛出UnsupportedOperationException 异常。Arrays.asList 体现的是适配器模式，后台的数据仍是原有数组， set() 方法即间接对数组进行值的修改操作。 asList的返回对象是一个Arrays 的内部类 ArrayList 类（或许命名为 InnerArrayList 更容易识别），它并没有实现集合个数的相关修改方法，这也正是抛出异常的原因。
Arrays.asList 的源码如下：

```Java
public static <T> List<T> asList(T... a) {
	return new ArrayList<>(a); 
}
```
此处的 ArrayList 十分简单，只提供了个别方法的实现，如下所示：

![1566226996177](E:\git_repo\Hao_Learn\2019\8\img\1566226996177.png)

第 1 处的 final 引用，用于存储集合的数组引用始终被强制指向原有数组（引用不能变，但数组的值可以改变）。这个内部类并没有实现任何修改集合元素个数的相关方法 那这个
UnsupportedOperat onException 异常是从哪里抛出来的呢？是ArrayList的父类 AbstractList 

![1566265511789](E:\git_repo\Hao_Learn\2019\8\img\1566265511789.png)

在使用数组转集合时，需要使用 java util.ArrayList 直接创建一个新集合，参数就是 Arrays .asList 返回的不可变集合，源码如下：

```Java
List<Object> objectList = new java.util.ArrayList<Object>(Arrays.asList(数组));
```
相对于数组转集合来说，集合转数组更加可控，毕竟是从相对自由的集合容器转为更加苛刻的数组。什么情况下集合需要转成数组呢？适配别人的数组接口，或者进行局部方法计算等。

![1566266222956](E:\git_repo\Hao_Learn\2019\8\img\1566266222956.png)

第 1 处比较容易理解，不要用 toArray() 无参方法把集合转换成数组，这样会导致泛型丢失，在第 2 处执行成功后，输出却为 null ；第 3 处正常执行，成功地把集合数据复制到 array3 数组中。第 2 处与第 3 处的区别在于即将复制进去的数组容量是否足够。如果容量不够，则弃用此数组，另起炉灶，关于此方法的源码如下：

![1566266401568](E:\git_repo\Hao_Learn\2019\8\img\1566266401568.png)

当入参数组容量小于集合大小时 使用 Arrays.copyOf() 方法，它的源码如下：

![1566266694746](E:\git_repo\Hao_Learn\2019\8\img\1566266694746.png)

用示例代码模拟可能出现的三种情况，分别为入参数组容量不够时、入参数组容量刚好时，以及入参数组容量超过集合大小时，并记录其执行时间。多次运行结果显示，当数组容量等于集合大小时，运行总是最快的，空间消耗也是最少的。由此证明，如果数组初始大小设置不当，不仅会降低性能，还会浪费空间。使用集合的 toArray (T[] array) 方法，转换为数组时，注意需要传入类型完全一样的数组，并且它的容量大小为 list.size ()。

## 6.5 集合与泛型

泛型与集合的联合使用，可以把泛型的功能发挥到极致。

#### List、`List<Object>`、 `List<?>` 三者的区别

List 完全没有类型限制和赋值限定，如果天马行空地乱用，迟早会类型转换失败的异常。很多程序员觉得 `List<Object>`的用法完全等同于 List，但在接受其他泛型赋值时会编译出错。`List<?>` 是一个泛型，在没有赋值之前，表示它可以接受任何类型的集合赋值，赋值之后就不能随便往里添加元素了。

![1566268907287](E:\git_repo\Hao_Learn\2019\8\img\1566268907287.png)

第一段说明：遍历没有问题，但强制转化为非 Object 的类型，则会抛出 ClassCastException 异常。

第二段说明：把 a1 赋值给 a2, a2 是 List Object> 类型的，也可以再往里装入三种不同的对象。很多程序员认为 List 和 `List<Object>` 是完全相同的，至少从目前这两段来看是这样的。

第三段说明：如果把 a1 的声明类型从 List 修改为`List<Object>`，那么第三段就会编译出错。`List<Object>`  赋值给 `List<Integer>` 是不允许的，若是反过来赋值，依然会编译出错。提示如下：

![1566271441949](E:\git_repo\Hao_Learn\2019\8\img\1566271441949.png)

注意，数组可以这样赋值，因为它是协变的，而集合不是。来看一段问题代码：

![1566269651568](E:\git_repo\Hao_Learn\2019\8\img\1566269651568.png)

进行了泛型限制，示例中 addAll 的实际参数是 getJSONArray 返回的 JSONArray 对象，它并非是 List ，更加不是 Integer 集合的子类，为何编译不报错？查看JSONArray 定义：
```Java
public final class JSONArray extends AbstractJSON implements JSON, List {} 
```

JSONArray 实现了 List，是非泛型集合，可以赋值给任何泛型限制的集合。编译可以通过，但在运行时报错，这是一个隐藏得比较深的 Bug ，最终导致发生线上故障。

第四段说明：问号在正则表达式中可以匹配任何字符， `List<?>`称为通配符集合。它可以接受任何类型的集合引用赋值，不能添加任何元素，但可以 remove 和 clear，并非 immutable 集合。`List<?>`一般作为参数来接收外部的集合，或者返回一个不知道具体元素类型的集合。

`List<T>`最大的问题是只能放置一种类型，如果随意转换类型的话，就是“破窗理论“，泛型就失去了类型安全的意义。

#### 区分`<? extends T>`与`<? super T>`的使用场景

为了放置多种受泛型约束的类型，JDK 的开发者顺应了民意，实现了`<? extends T>`与`<? super T>`两种语法，但是两者的区别非常微妙。简单来说，`<? extends T>`是 Get First，适用于消费集合元素为主的场景；`<? super T>`是Put Frist，适用于生产集合元素为主的场景。

`<? extends T>`可以**赋值**给任何 T 及 T 子类的集合，上界为 T， 取出来的类型带有泛型限制，向上强制转型为任何 T 及 T 父类的父类集合，即子类类型被擦除了。由于 null 可以表示任何类型，所以除 null 外，任何元素都不得添加进`<? extends T>` 集合内。

`<? super T>`可以**赋值**给任何 T 及 T 父类的集合，下界为 T 。在生活中，投票选举类似于`<? super T>`的操作。选举代表时，只能有代表以下的人往里投选票，即只能添加任何 T 及 T 子类的集合。而取数据时，根本不知道是谁的票，相当于泛型丢失，即只能返回Object对象。

extends 的场景是 put 功能受限，super 场景是 get 功能受限。

|操作|`<? extends T>`|`<? super T>`|
|-------|-------|-------|
|赋值|任何 T 及 T 子类的集合|任何 T 及 T 父类的父类集合|
|get|类型擦除，任何 T 及 T 父类的父类集合|get受限，泛型丢失，即只能返回Object对象|
|put|put受限，即只能插入null|任何 T 及 T 子类的集合|

## 6.6 元素的比较

#### Comparable 和 Comparator

Java 中两个对象相比较的方法通常用在元素排序中，常用的两个接口分别是Comparable 和 Comparator ，前者是自己和自己比，可以看作是自营性质的比较器；后者是第三方比较器，可以看作是平台性质的比较器。从词根上分析 Comparable 以 -able 结尾，表示它有自身具备某种能力的性质，表明 Comparable 对象本身是可以与同类型进行比较的，它的比较方法是 comparaTo ，而 Comparator 以 -or 结尾，表示自身是比较器的实践者，它的比较方法是 compare。

我们熟知的 Integer 和 String 实现的就是 Comparable 的自然排序。而我们在使用某个自定义对象时，可能需要按照自己定义的方式排序，比如在搜索列表对象 SearchResult 中进行大小比较时，先根据相关度排序，然后再根据浏览数排序，实现这样的自定义 Comparable 的示例代码如下：

![1566271753344](E:\git_repo\Hao_Learn\2019\8\img\1566271753344.png)

实现 Comparable 时，可以加上泛型限定，在编译阶段即可发现传入的参数非 SearchResult 对象，不需要在运行期进行类型检查和强制转换。

如果这个排序的规则不符合业务方的要求，那么就需要修改这个类的比较方法 compareTo，然而我们都知道开闭原则， 即最好不要对自己已经交付的类进行修改。因此推荐外部定义比较器，即 Comparator。

正因为 Comparator 的出现，业务方可以根据需要修改排序规则。如在上面的示例代码中， 如果业务方需要在搜索时将最近订单数 (recentOrders) 的权重调整到相关度与浏览数之间，则使用 Comparator 实现的比较器如下所示：

![1566272989334](E:\git_repo\Hao_Learn\2019\8\img\1566272989334.png)

在 JDK 中， Comparator 最典型的应用是在 Arrays.sort 中作为比较器参数进行排序：

![1566273035937](E:\git_repo\Hao_Learn\2019\8\img\1566273035937.png)

红色的`<? super T>`语法为下限通配，也就是将泛型类型参数限制为 T 或 T的某个父类，直到 Object 。该语法只能用在形参中来限定实参调用。如果本例中不加限定，假定 sort 对象是 Integer，那么传入 String 时就会编译报错，就是充分利用了多态的向下转型的功能。

约定俗成，不管是 Comparable 还是 Comparator，小于的情况返回 -1，等于的情况返回 0，大于的情况返回 1。当然，很多代码里只是判断是否大于或小于 0，如在集合中使用比较器进行排序时，直接使用正负来判断比较的结果。

![1566273353047](E:\git_repo\Hao_Learn\2019\8\img\1566273353047.png)

sort() 方法中的 TimSort 算法，是归并排序（Merge Sort）与插入排序（Insertion Sort）优化后的排序算法。

首先回顾一下归并排序的原理。长度为 1 的数组是排序好的，有 n 个元素的集合可以看成是 n个长度为 1 的有序子集合；对有序子集合进行两两归并，并保证结果子集合有序，最后得到 n/2 个长度为 2 的有序子集合，重复上一步骤直到所有元素归并成一个长度为 n 的有序集合。在此排序过程中，主要工作都在归并处理中，如何使归并过程更快，或者如何减少归并次数，成为优化归并排序的重点。
再回顾插入排序的工作原理。长度为 1 的数组是有序的，当有了 k 个己排序的元素，将第 k+1 个元素插入己有的 k 个元素中合适的位置，就会得到一个长度为 k+1 己排序的数组。假设有 n 个元素且已经升序排列的数组，并且在数组尾端有第 n+1 个元素的位置，此时如果想要添加一一个新的元素并保持数组有序，根据插入排序可以将新元素放到第 n+1个位置上，然后从后向前两两比较，如果新值较小则交换位置，直到新元素到达正确的位置。

2002年，Tim Peters 结合归并排序和插入排序的优点，实现了 TimSort 排序算法。该算法避免了归并排序和插入排序的缺点，相对传统归并排序，减少了归并次数；相对插入排序，引入了二分排序概念，提升了排序效率。Tim Sort 算法对于已经部分排序的数组，时间复杂度最优可达*O*(n)；对于随机排序的数组，时间复杂度为 *O*(*n*logn)，平均时间复杂度为 *O*(*n*logn)

因此 Java JDK7 中使用 TimSort 算法取代了原来的归并排序。它有两个主要优化：

1. 归并排序的分段不再从单个元素开始，而是每次先查找当前最大的排序好的数组片段run，然后对 run 进行扩展并利用二分排序，之后将该 run 其他已经排序好的 run 进行归并，产生排序好的大 run。

2. 引入二分排序，binarySort 。二分排序是对插入排序的优化，在插入排序中不再是从后向前逐个元素对比，而是引入了二分查找的思想，将一次查找新元素合适位置，时间复杂度由*O*(*n*)  降低到 *O*(*n*logn) 。

#### hashCode 和 equals

hashCode 和 equals 用来标识对象，两个方法协同工作可用来判断两个对象是否相等。众所周知，根据生成的哈希将数据离散开来，可以使存取元素更快。对象通过调用 Object.hashCode()生成哈希值，由于不可避免地会存在哈希值冲突的情况，因此当 hashCode 相同时，还需要再调用 equals 进行次值的比较；但是若 hashCode 不同，将直接判定 Objects 不同，跳过 equals，这加快了冲突处理效率。

Object  类定义中对 hashCode 和 equals 要求如下：

- 如果两个对象的 equals 的结果是相等的，则两个对象的 hashCode 的返回结果也必须是相同的。
- 任何时候覆写 equals，都必须同时覆写 hashCode。

HashMap 的 get 判断代码如下：

![1566281127923](E:\git_repo\Hao_Learn\2019\8\img\1566281127923.png)

equals 不相等时并不强制要求 hashCode 也不相等，但一个优秀的哈希算法应尽可能地让元素均匀分布，降低冲突概率，即在 equals 不相等时尽量使 hashCode 也不相等，这样 && 或 || 短路操作一旦生效，会极大地提高程序的执行效率。

如果自定义对象作为 Map 的键，那么必须覆写 hashCode 和 equals 。此外，因为 Set 存储的是不重复的对象，依据 hashCode 和 equals 进行判断，所以 Set 存储的自定义对象也必须覆写这两个方法。

如果覆写了 equals ，而没有覆写 hashCode，会发生什么呢？先看一个覆写了 equals 的例子：

![1566281800423](E:\git_repo\Hao_Learn\2019\8\img\1566281800423.png)

如果不覆写 hashCode()，即使 equals() 相等也毫无意义。Object.hashCode() 的实现是默认为每一个对象生成不同的 int 数值，它本身是 native 方法，一般与对象内存地址有关。下面查看 C++的源码实现：

![1566282242583](E:\git_repo\Hao_Learn\2019\8\img\1566282242583.png)

ObjectSynchronizer 的核心代码如下，从代码分析角度也印证了 hashCode 就是根据对象的地址进行相关计算得到 int 类型数值的：

![1566282264165](E:\git_repo\Hao_Learn\2019\8\img\1566282264165.png)

因为 EqualsObject 没有覆写 hashCode ，所以得到的是一个与对象地址相关的唯一值，回到刚 才的 HashSet 集合上，如果想存储不重复的元素，那么需要在EqualsObject 类中覆写 hashCode()：

![1566282338829](E:\git_repo\Hao_Learn\2019\8\img\1566282338829.png)

EqualsObject 的 name 属性是 String 类型， String 覆写了 hashCode()，所以可以直接调用。 equals() 的实现方式与类的具体处理逻辑有关，但又各不相同，因而应尽量分析源码来确定其判断结果 ，比如下列代码：

![1566282948897](E:\git_repo\Hao_Learn\2019\8\img\1566282948897.png)

第 1 处说明：局部变量类型推断( Local Variable Type Inference) 是 JDK10 引入的变量命名机制，一改 Java 是强类型语言的传统形象，这是 Java 致力于未来体积更小、面向生产效率的新语言特性，减少累赘的语法规则，当然这仅仅是一个语法糖， Java 仍然是一种静态语言。在初始化阶段，在处理 var 变量的时候，编译器会检测右侧代码的返回类型，并将其类型用于左侧，如下图所示：

![1566283095694](E:\git_repo\Hao_Learn\2019\8\img\1566283095694.png)

b 在第一次赋值时，类型推断为 Integer ，所以在第二次赋值为 double 时编译出错。如果一个方法内频繁地使用 var ，则会大大降低可读性，这是一个权衡，建议当用 var 定义变量时， 尽量不要超过两个。

第 2 处说明：尽量避免通过实例对象引用来调用 equals 方法，否则容易抛出空指针异常。推荐使用 JDK7 引入的 Objects 的 equals 方法，源码如下，可以有效地防止在 equals 调用时产生 NPE 问题：

![1566283261102](E:\git_repo\Hao_Learn\2019\8\img\1566283261102.png)

## 6.7 fail-fast 机制

fail-fast 机制是集合世界中比较常见的错误检测机制，通常出现在遍历集合元素的过程中。

它是一种对集合遍历操作时的错误检测机制，在遍历中途出现意料之外的修改时，通过 unchecked 异常暴力地反馈出来。这种机制经常出现在多线程环境下，当前线程会维护一个计数比较器，即 expectedModCount 记录已经修改的次数。在进入遍历前，会把实时修改次数
modCount 赋值给 expectedModCount，如果这两个数据不相等，则抛出异常。

java.util 下的所有集合类都是 fail-fast，而 concurrent 包中的集合类都是 fail-safe 。

人的大脑习惯用单线程方式处理日常逻辑，思维在某个时间段或某个深度上具有方向性。多线程的运行逻辑并非自然思维。我们通过 ArrayList.subList() 方法进一步阐述 fail-fast 这种机制。

在某种情况下，需要从一个主列表 master 中获取子列表 branch , master 集合元素个数的增加或删除，均会导致子列表的遍历、增加、删除，进而产生 fail-fast 异常。伪代码分析如下：

```Java
import java.util.*;

public class SubListFailFast {
    public static void main(String[] args) {
        List masterList = new ArrayList();
        masterList.add("one");
        masterList.add("two");
        masterList.add("three");
        masterList.add("four");
        masterList.add("five");
        List branchList = masterList.subList(0, 3);
        // 下方三行代码，如果不注释掉，则会导致branchList操作出现异常（第1处）
        masterList.remove(0);
        masterList.add("ten");
        masterList.clear();
        // 下方四行全部能够正确执行
        branchList.clear();
        branchList.add("six");
        branchList.add("seven");
        branchList.remove(0);
        // 正常遍历结束，只有一个元素：seven
        for (Object t : branchList) {
            System.out.println(t);
        }
        // 子列表修改导致主列表也被改动，输出：[seven , four , five]
        System.out.println(masterList);
    }
}
```

第 1 处说明，如果不注释掉， masterList 的任何关于元素个数的修改操作都会导致 branchList  的 crud 抛出 ConcurrentModificationException 异常。在实际调研中，大部分程序员知道 subList 子列表无法序列化，也知道它的修改会导致主列表的修改，但是并不知道主列表元素个数的改动会让子列表如此敏感，频频抛出异常。在实际代码中，这样的故障案例属于常见的类型。 subList 方法返回的是内部类 SubList 的对象，SubList 类是 ArrayList 的内部类， SubList 的定义如下，并没有实现序列化接口，无法网络传输：

```
private static class SubList<E> extends AbstractList<E> implements RandomAccess { ... } 
```

在 foreach 遍历元素时，使用删除方式测试 fail-fast 机制，查看如下代码：
```Java
import java.util.*;

public class ArrayListFailFast {
    public static void main(String[] args) {
        List<String> list = new ArrayList<String>();
        list.add("one");
        list.add("two");
        list.add("three");
        for (String s : list) {
            if ("two".equals(s)) {
                list.remove(s);
            }
        }
        System.out.println(list);
    }
}
```
ArrayList 的 foreach 的执行时的代码顺序：
1. 调用 ArrayList 的 iterator() ，返回一个内部类 Itr，该类继承了 `Iterator<E>`。
2. 对 Itr 初始化，再调用 hasNext()，判断集合中是否有下一个值。如果有，再调用 next()，
该方法首行代码为 checkForComodification()，检查 modCount 与 expectedModCount 是否相等，不相等则抛出 ConcurrentModificationException。
3. 创建临时变量 i，经过cursor = i + 1，lastRet = i，最后返回值为 elementData[ i ]。期间如 果 i 的值大于等于 size ，则抛出NoSuchElementException，若 i 的值大于等于 elementData.length ，则抛出 ConcurrentModificationException。

```java
public Iterator<E> iterator() {
		return new Itr();
}
private class Itr implements Iterator<E> {
		// 下一个要返回的元素的索引
        int cursor;       
        // 被返回的最后一个元素的索引；默认值是 -1
        int lastRet = -1; 
        // 记录已经修改的次数
        int expectedModCount = modCount;

        Itr() {}

        public boolean hasNext() {
            return cursor != size;
        }

        @SuppressWarnings("unchecked")
        public E next() {
            checkForComodification();
            int i = cursor;
            if (i >= size)
                throw new NoSuchElementException();
            Object[] elementData = ArrayList.this.elementData;
            if (i >= elementData.length)
                throw new ConcurrentModificationException();
            cursor = i + 1;
            return (E) elementData[lastRet = i];
        }

        final void checkForComodification() {
            if (modCount != expectedModCount)
                throw new ConcurrentModificationException();
        }
    }
```

在集合遍历时维护一个初始值为 0 的游标 cursor，从头到尾地进行扫描，在 cursor == size 时，退出遍历。如图 6-2 所示，执行 remove 后，所有元素往前拷贝， size = size-1， 即为 2，这时 cursor 也等于 2，因此在执行hasNext()， 结果为 false ，退出循环体，并没有机会执行到 next()  的第一行代码 checkForComodification()。

![1566289008898](E:\git_repo\Hao_Learn\2019\8\img\1566289008898.png)

我们可以使用 Iterator 机制进行遍历时的删除，如果是多线程并发，还需要在 Iterator 遍历时加锁，如下源码：


或者使用并发容器 CopyOnWriteArrayList 代替 ArrayList，该容器内部会对 Iterator 进行加锁操作。顺便简单介绍一个 COW （奶牛）家族，即 Copy-On-Write。它是并发的一种新思路，实行读写分离，如果是写操作，则复制一个新集合，在新集合内添加或删除元素。待一切修改完成之后，再将原集合的可引用指向新的集合。这样做的好处是可以高并发地对 COW 进行读和遍历操作，而不需要加锁，因为当前集合不会添加任何元素。

使用 COW 时应注意两点：第一，尽量设置合理的容量初始值，它扩容的代价比较大；第二，使用批量添加或删除方法，如 addAll 或 removeAll 操作，在高并发请求下，可以攒一下要添加或者删除的元素，避免增加一个元素复制整个集合。

如果集合数据是 100MB，再写入 50MB， 那么某个时间段内占用的内存就达到( 100MB x 2 ) + 50MB = 250MB，内存的大量占用会导致 GC 的频繁发生，从而降低服务器的性能。我们观察如下代码：

```Java
public static void main (String[] args) {
    List<Long> copy= new CopyOnWriteArrayList<Long>();
    
    long start = System.nanoTime();
    for (int i=0; i<20*10000; i++) {
        copy.add(System.nanoTime()) ; 
    }
}
```

循环 20 万次，不断地进行数据插入，这对 COW 类型的集合来说简直是灾难性的操作，本示例执行时间为 97.8s，如果换成 ArrayList，则只需 39 ms，差距巨大！要初始化这样的 COW 集合，建议先将数据填充到 ArrayList 集合中去， 然后把 ArrayList 集合当成 COW 参数，这就是使用批量添加的另一种方式。所以明显 COW 适用于读多写极少的场景。

COW 是 fail-safe 机制的，在并发包的集合中都是由这种机制实现的， fail-safe 是在安全的副本（或者没有修改操作的正本）上进行遍历 ，集合修改与副本的遍历是没有任何关系的，但是缺点也很明显，就是读取不到最新的数据。这也是 CAP 理论中 C ( Consistency) 与 A ( Availability)的矛盾，即一致性与可用性的矛盾。

## 6.8 Map 类集合

在数据元素的存储、查找、修改和遍历中， Java 中的 Map 类集合都与 Collection 类集合存在很大不同。它是与 Collection 平级的一个接口，在集合框架图上，它有一条微弱的依赖线与 Collection 类产生关联，那是因为部分方法返回 Collection 视图，比如 values() 方法返回的所有 Value 的列表。 Map 类集合中的存储单位是 KV 键值对，Map 类就是使用一定的哈希算法形成一组比较均匀的哈希值作为 Key，Value 值挂在 Key 上。 Map 类的特点如下：

- Map 类取代了旧的抽象类 Dictionary，拥有更好的性能。
- 没有重复的 Key ，可以有多个重复的 Value。
- Value 可以是 List、Map、Set 类对象。
- KV 是否允许为 null，以实现类约束为准。

Map 接口除提供传统的增删改查方式外，还有三个 Map 类特有的方法，即返回所有的 Key，返回所有的 Value ， 返回所有的 KV 键值对。源码加注释如下：

```Java
// 返回Map类对象中的Key的Set视图
Set<K> keySet();
// 返回Map类对象中的所有Value集合的Collection视图
// 返回集合实现类为 Values extends AbstractCollection<V>
Collection<V> values(); 
//返回Map类对象中的Key-Value对的Set视图
Set<Map.Entry<K,V>> entrySet();
```
通常这些返回的视图是支持清除操作的， 但是修改和增加元素会抛出异常，因为AbstractCollection 没有实现 add 操作，但是实现了 remove、clear 等相关操作。所以在使用这些视图返回集合时，注意不要操作此类相关方法。

![1566291534049](E:\git_repo\Hao_Learn\2019\8\img\1566291534049.png)

从 1.0 -> 1.2 -> 1.5，这几个重点的 KV 集合类见证了 Java 语言成为工业级语言的成长历程。从线程安全到线程不安全，再到线程安全，经历了否定之否定的过程，不断走向成熟。在大多数情况下，直接使用 ConcurrentHashMap 替代 HashMap 没有任何问题，在性能上区别并不大，而且更加安全。抽样调查发现，近八成的程序员认为 ConcurrentHashMap 可以置入 null 值，毕竟它与 HashMap 是近亲，而 HashMap 的 KV 都可以为 null 。比如，在某次配置 xml 时，如果只是把 Key 复制过来，没有做相关的 null 判断就置入 ConcurrentHashMap 就会导致 NPE 异常，但是子线程的异常并不会抛给主线程，所以排查颇费周折。在任何 Map 类集合中，都要尽量避免 KV 设置为 null 值。

#### 树（tree）

树是一种常用的数据结构，它是一个由有限节点（本书统称为节点，而不是结点）组成的一个具有层次关系的集合，数据就存在树的这些节点中。

- 最顶层只有一个节点，称为根节点， 类似于图 6-3 中在悬崖边上倒着生长的树，root 是根节点。
- 在分支处有一个节点，指向多个方向，如果某节点下方没有任何分叉的话，就是叶子节点。
- 从某节点出发，到叶子节点为止，最长简单路径上边的条数，称为该节点的高度。
- 从根节点出发，到某节点边的条数，称为该节点的深度。

如图 6-3 所示的树，根节点 root 的高度是 5，深度是 0；而节点 2 的高度是 4，深度是 1。树结构的特点如下：
1. 一个节点，即只有根节点，也可以是一棵树。
2. 其中任何一个节点与下面所有节点构成的树称为子树。
3. 根节点没有父节点，而叶子节点没有子节点。
4. 除根节点外，任何节点有且仅有一个父节点。
5. 任何节点可以有 0 ~ n 个子节点。

![1566292537991](E:\git_repo\Hao_Learn\2019\8\img\1566292537991.png)

至多有两个子节点的树称为二叉树，图 6-3 所示的恰好是二叉树。二分法是经典的问题拆解算法，二叉树是近似于二分法的一种数据结构实现，二叉树是高效算法实现的载体，在整个数据结构领域具有举足轻重的地位。在二叉树的世界中，最为重要的概念是平衡二叉树、二叉查找树、红黑树。

#### 平衡二叉树 

如果把图 6-3 中的左侧枝叶全部砍掉的话，那么剩余的部分还是树吗？是的，但只是以“树”之名，行“链表”之实，如图 6-4(a) 所示。如果以树的复杂结构来实现简单的链表功能，则完全埋没了树的特点。看来对于树的使用，需要进行某种条件的约束，如图 6-4(b)所示，让链表一样的树变得更有层次结构，平衡二叉树就呼之欲出了。图 6-4(b) 的高度差为 5，而右侧树由 9 与 8 组成的递归右子树的，高度差为 1，高度差是一棵树是否为平衡二叉树的决定条件。

平衡二叉树的性质如下：
1. 树的左右高度差不能超过1。
2. 任何往下递归的左子树与右子树，必须符合第一条性质。
3. 没有任何节点的空树或只有根节点的树也是平衡二叉树。

![1566293461228](E:\git_repo\Hao_Learn\2019\8\img\1566293461228.png)

#### 二叉查找树

二叉查找树又称二叉搜索树，即 Binary Search Tree，其中 Search 也可以替换为Sort ，所以也称为二叉排序树。 Java 中集合的最终目的就是加工数据，二叉查找树也是如此。树如其名，二叉查找树非常擅长数据查找。二叉查找树额外增加了如下要求：对于任意节点来说，它的左子树上所有节点的值都小于它，而它的右子树上所有节点的值都大于它。查找过程从树的根节点开始，沿着简单的判断向下走，小于节点值的往左边走，大于节点值的往右边走，直到找到目标数据或者到达叶子节点还未找到。
遍历所有节点的常用方式有三种：前序遍历、中序遍历、后序遍历。它们三者的规律如下：

1. 在任何递归子树中，左节点一定在右节点之前先遍历。
2. 前序、中序、后序，仅指根节点在遍历时的位置顺序。即前序遍历的顺序是根节点、左节点、右节点，中序遍历的顺序是左节点、根节点、右节点；而后序遍历的顺序则是左节点、右节点、根节点。

二叉查找树容易构造，但是如果缺少约束条件，随着数据不断地增加或删除容易失衡，很可能往一个方向野蛮生长，成为查找复杂度为 *O*(*n*) 的树。所以为了保持二叉树重要的平衡性，需要引入一种检测机制，随着插入删除动态地调整树结构。
有很多算法的实现，如 AVL 树、红黑树、SBT(Size Balanced Tree)、Treap( 树堆）等。

#### AVL 树

AVL 树算法是以苏联数学家 Adelson-Velsky 和 Landis 名字命名的平衡二叉树算法，可以使二叉树的使用效率最大化。 AVL 树是一种平衡二叉查找树，增加和删除节点后通过树形旋转重新达到平衡。右旋是以某个节点为中心 将它沉入当前右子节点的位置，而让当前的左子节点作为新树的根节点，也称为顺时针旋转；同理，左旋是以某个节点为中心，将它沉入当前左子节点的位置 而让当前右子节点作为新树的根节点，也称为逆时针旋转。
AVL 树就是通过不断旋转来达到树平衡的，下方的左旋和右旋只是旋转操作层面的简单示意图，我们应体会如何通过旋转达到一种新的平衡状态，不再基于插入和删除进行展开，右旋示意图如图 6-7 所示。

![1566294324479](E:\git_repo\Hao_Learn\2019\8\img\1566294324479.png)

图 6-7 所示左侧是非平衡状态，需要进行平衡化处理，根节点的左子树与右子树
高度差超过 1，向右旋转。在旋转过程中，节点 15 成为新的根节点，而节点 16 移动到节点 17 的左节点上。而左旋转则反之，如图 6-8 所示。

![1566309391170](E:\git_repo\Hao_Learn\2019\8\img\1566309391170.png)

#### 红黑树

红黑树是于 1972 年发明的，当时称为对称二叉 B 树， 1978 年得到优化，正式命名为红黑树。它的主要特征是在每个节点上增加一个属性来表示节点的颜色，可以是红色，也可以是黑色。

红黑树和 AVL 树类似，都是在进行插入和删除元素时，通过特定的旋转来保持自身平衡的，从而获得较高的查找性能。与 AVL 树相比，红黑树并不追求所有递归子树的高度差不超过 1，而是保证从根节点到叶子节点的最长路径不超过最短路径的 2 倍，所以它的最坏运行时间也是 *O*(log*n*) 。

红黑树通过重新着色和左右旋转，更加高效地完成了插入和删除操作后的自平衡调整。当然，红黑树在本质上还是二叉查找树，它额外引入了 5 个约束条件：
1. 节点只能是红色或黑色。
2. 根节点必须是黑色。
3. 所有 NIL 节点都是黑色的。 NIL ，即叶子节点下挂的两个虚节点。
4. 一条路径上不能出现相邻的两个红色节点。
5. 在任何递归子树内，根节点到叶子节点（即任一节点）的所有路径上包含相同数目的黑色节点。

总结一下，即“有红必有黑，红红不相连”，上述 5 个约束条件保证了红黑树的新增、删除、查找的最坏时间复杂度均为 *O*(log*n*）。 如果一个树的左子节点或右子节点不存在，则均认定为黑色。红黑树的任何旋转在 3 次之内均可完成。

#### 红黑树与 AVL 树的比较

先从复杂度分析说起，任意节点的黑深度（ Black Depth）是指当前节点到 NIL
（数尾端）途径的黑色节点个数。

根据约束条件的第4、5条，可以推出对于任意高度的节点，它的黑深度都满足`Black Depth >= height / 2 `。也就是说，对于任意包含 n 个节点的红黑树而言，它的根节点高度 `h <= 2log~2~( n+1 )` 。常规 BST 操作比如查找、插入、删除等，时间复杂度为 *O*(*h*) ，即取决于树的高度 。当树失衡时，时间复杂度将有可能恶化到 *O*(*n*)，即h=n 。所以，当我们能保证树的高度始终保持在 *O*(log*n*）时，便能保证所有操作的时间复杂度都能保持在*O*(log*n*） 以内。常规 BST（二叉搜索树）操作比如查找、插入、删除等，时间复杂度为 *O*(*h*） ，即取决于树的高度 h。当树失衡时，时间复杂度将有可能恶化到 *O*(*n*），即 h=n 。所以，当我们能保证树的高度始终保持在*O*(log*n*）时，便能保证所有操作的时间复杂度都能保持在*O*(log*n*）以内。

红黑树的平衡性并不如 AVL 树，它维持的只是一种大致上的平衡，并不严格保证左右子树的高度差不超过 1。这导致在相同节点数的情况下，红黑树的高度可能更高 ，也就是说，平均查找次数会高于相同情况下的 AVL 树。在插入时，红黑树和 AVL 树都能在至多两次旋转内恢复平衡。在删除时，由于红黑树只追求大致上的平衡，因此红黑树能在至多三次旋转内恢复平衡，而追求绝对平衡的 AVL 树，则至多需要 O(logn 次旋转。

面对频繁的插入和删除 ，红黑树更为合适；面对低频修改、大量查询时， AVL树将更为合适。

#### TreeMap

TreeMap 是按照 Key 的排序结果来组织内部结构的 Map 类集合，它改变了Map 类散乱无序的形象，其最大的特点是 Key 的有序性。

![1566738596756](E:\git_repo\Hao_Learn\2019\8\img\1566738596756.png)

在 TreeMap 的接口继承树中，有两个与众不同的接口 SortedMap 和NavigableMap。SortedMap 接口表示它的 Key 是**有序不可重复的**，支持**获取头尾 Key-Value元素**，或者**根据 Key 指定范围获取子集合**等。插入的 Key 必须实现 Comparable 或者提供额外的比较器 Comparator ，所以 **Key 不允许为 null ，但是 Value 可以**；NavigableMap 接口继承了 SortedMap 接口，**根据指定的搜索条件返回最匹配的 Key-Value 元素**。

HashMap 是通过使用覆写的 hashCode 和equals 方法来达到 Key 去重的目的，TreeMap 依靠 Comparable 或 Comparator 来实现 Key 的去重。

因为如果没有覆盖正确的方法，那么 TreeMap 的最大特性将无法发挥出来，甚至在运行时会出现 ClassCastException 异常。

TreeMap的内部类`Entry<K,V>`，储存红黑树节点的载体类，继承了`Map.Entry<K,V>`。节点颜色信息是红黑树的精髓所在，默认是黑色。

TreeMap 通过 put() 和 deleteEntry() 实现红黑树的增加和删除节点操作。以插入为例，在插入之前，需要明确三个前提条件：
1. 需要调整的新节点总是红色的。
2. 如果插入的新节点的父节点是黑色的，无需调整，因为依然能符合红黑树的
5 个约束条件。
3. 如果插入新节点的父节点是红色的，因为红黑树规定不能出现相邻的两个红色节点，所以进入循环判断，或重新着色，或左右旋转，最终达到红黑树的五个约束条件。

循环退出条件：如果是根节点 ，则直接退出，设置为黑色即可；如果不是根节点，并且父节点为红色，会一直进行调整，直到退出循环。

TreeMap 的插入操作就是按 Key 的对比往下遍历，大于比较节点值的向右走，小子比较节点值的向左走，先按照二叉查找树的特性进行操作，无须关心节点颜色与树的平衡，后续会重新着色和旋转，保持红黑树的特性。

```Java
public V put(K key, V value) {
	// 先把 TreeMap 的根节点 root 引用赋值给当前节点
	Entry<K,V> t = root;
	// 如果当前节点为 null ，即是空树，新增的 KV 形成的节点就是根节点
	if (t == null) {
		// 看似多此一举，实际预检了 Key 是否可以比较,
		compare(key, key); 
		root = new Entry<>(key, value, null);
		size = 1;
		modCount++;
		return null;
	}
	// 用来接收比较结果
	int cmp;
	Entry<K,V> parent;
	// 构造方法中置入的外部比较器
	Comparator<? super K> cpr = comparator;
	// 根据二叉查找树的特性，找到新节点插入的合适位置
	if (cpr != null) {
		do {
			parent = t;
			cmp = cpr.compare(key, t.key);
			if (cmp < 0)
				t = t.left;
			else if (cmp > 0)
				t = t.right;
			else
				return t.setValue(value);
		} while (t != null);
	}
	// 在没有指定比较嚣的情况下,调用自然排序的 Comparable 比较
	else { 
		if (key == null)
			throw new NullPointerException();
		@SuppressWarnings("unchecked")
			Comparable<? super K> k = (Comparable<? super K>) key;
		do {
			parent = t;
			cmp = k.compareTo(t.key);
			if (cmp < 0)
				t = t.left;
			else if (cmp > 0)
				t = t.right;
			else
				return t.setValue(value);
		} while (t != null);
	}
	Entry<K,V> e = new Entry<>(key, value, parent);
	// 对 parent 维护
	if (cmp < 0)
		parent.left = e;
	else
		parent.right = e;
	fixAfterInsertion(e);
	size++;
	modCount++;
	return null;
}

@SuppressWarnings("unchecked")
final int compare(Object k1, Object k2) {
	return comparator==null ? ((Comparable<? super K>)k1).compareTo((K)k2)
		: comparator.compare((K)k1, (K)k2);
}

private void fixAfterInsertion(Entry<K,V> x) {
	// 虽然内部类 Entry 的属性 color 默认为黑色，但新节点一律先赋值为红色
	// 这样可以避免插入新节点时违反性质五，只需专注于满足性质四即可。
	x.color = RED;

	// 若该节点为根节点或叶子节点，或该节点的父亲为黑色，则退出循环
	while (x != null && x != root && x.parent.color == RED) {
		// 父亲是爷爷的左孩子，且为红色
		if (parentOf(x) == leftOf(parentOf(parentOf(x)))) {
			Entry<K,V> y = rightOf(parentOf(parentOf(x)));
			// 右叔是红色
			if (colorOf(y) == RED) {
				// 则将父亲和右叔设置为黑色，爷爷设置为红色
				setColor(parentOf(x), BLACK);
				setColor(y, BLACK);
				setColor(parentOf(parentOf(x)), RED);
				// 将当前节点设置为爷爷之后循环，继续调整
				x = parentOf(parentOf(x));
			// 右叔是黑色	
			} else {
				// 若该节点是父亲的右孩子，则需先对父亲进行一次左旋
				// 之后父亲变为该节点的左孩子
                // 注意当前节点为之前的父亲！
				if (x == rightOf(parentOf(x))) {
					x = parentOf(x);
					rotateLeft(x);
				}
				// 将当前节点的父节点设置为黑色，曾经的爷爷设置为红色
				// 因为爷爷变成红色了，所有右边缺少了一个黑色节点
				// 则需要对爷爷进行右旋，即将该（黑色）节点放置在之前爷爷的位置上
				setColor(parentOf(x), BLACK);
				setColor(parentOf(parentOf(x)), RED);
				rotateRight(parentOf(parentOf(x)));
			}
		// 父亲是爷爷的右孩子
		} else {
			Entry<K,V> y = leftOf(parentOf(parentOf(x)));
			// 左叔是红色
			if (colorOf(y) == RED) {
				// 则将父亲和左叔设置为黑色，爷爷设置为红色
				setColor(parentOf(x), BLACK);
				setColor(y, BLACK);
				setColor(parentOf(parentOf(x)), RED);
				// 将当前节点设置为爷爷之后循环，继续调整
				x = parentOf(parentOf(x));
			// 左叔是黑色
			} else {
				// 若该节点是父亲的左孩子，则需先对父亲进行一次右旋
				// 之后父亲变为该节点的右孩子
				if (x == leftOf(parentOf(x))) {
					x = parentOf(x);
					rotateRight(x);
				}
				// 注意当前节点为之前的父亲！
				// 将该节点设置为黑色，曾经的爷爷设置为红色
				// 因为爷爷变成红色了，所有左边缺少了一个黑色节点
				// 则需要对爷爷进行左旋，即将该（黑色）节点放置在之前爷爷的位置上
				setColor(parentOf(x), BLACK);
				setColor(parentOf(parentOf(x)), RED);
				rotateLeft(parentOf(parentOf(x)));
			}
		}
	}
	// 将根节点置为黑色
	root.color = BLACK;
}

private void rotateLeft(Entry<K,V> p) {
	if (p != null) {
		Entry<K,V> r = p.right;
		// 1. 先修改该节点与其右孩子的关系（p认子），将 p.right 设置为 r.left。
		p.right = r.left;
		//如果 r.left 不为空（叶子节点），则需要将其parent 设置为 p，即维护一
		if (r.left != null)
			r.left.parent = p;
		// 2. 之后修改将 r.parent 设置为 p.parent（r认父）
		r.parent = p.parent;
		// 如果 p.parent为空，则 p为根节点，则将 root设置为r
		if (p.parent == null)
			root = r;
		// 否则将 p.parent的对应孩子设置为r
		else if (p.parent.left == p)
			p.parent.left = r;
		else
			p.parent.right = r;
		// 3. 最后将 r和p 与其原有的关系断开（一刀两断），即p认父，r认子
		// 将 r和rl 的关系断掉，将 r.left设置为p
		// 将 p和pp 的关系断掉，将 p.parent设置为r
		r.left = p;
		p.parent = r;
	}
}

private void rotateRight(Entry<K,V> p) {
	if (p != null) {
		Entry<K,V> l = p.left;
		p.left = l.right;
		if (l.right != null) l.right.parent = p;
		l.parent = p.parent;
		if (p.parent == null)
			root = l;
		else if (p.parent.right == p)
			p.parent.right = l;
		else p.parent.left = l;
		l.right = p;
		p.parent = l;
	}
}
```

总体来说， TreeMap 的时间复杂度比 HashMap 要高一些，但是合理利用好TreeMap 集合的有序性和稳定性，以及支持范围查找的特性，往往在数据排序的场景中特别高效。另外，TreeMap 是线程不安全的集合，不能在多线程之间进行共享数据的写操作。在多线程进行写操作时，需要添加互斥机制，或者把对象放在 `Collections.synchroinzedMap(treeMap)` 中实现同步。

JDK8 之后的 HashMap、TreeSet、ConcurrentHashMap 也使用红黑树的方式管理节点。如果只是对单个元素进行排序，使用 TreeSet 即可。 TreeSet 底层其实就是 TreeMap, Value 共享使用一个静态 Object 对象，如下源码所示：

```Java
private static final Object PRESENT = new Object() ;
public boolean add(E e) {
    return treeMap.put(e,PRESENT) == null;
}
```

#### HashMap

HashMap 的死链问题及扩容数据丢失问题是慎用 HashMap 的两个主要原因。

例如，某个应用在 init() 方法中初始化一个 static 的 HashMap 集合对象，从数据库提取数据到集合中。应用启动过程中仅单线程调用一次初始化方法，不应该有任何问题。但机缘巧合下 init()， 被执行了两次，启动失败、 CPU 使用率飙升， dump 分析发现存在HashMap 死链。第1种解决方案是用ConcurrentHashMap 替代 HashMap；第2种解决方案是使用 `Collections.synchronizedMap(hashMap)` 包装成同步集合，第3种解决方案是对init() 同步操作 。此案例最终选择第3种解决方案，毕竟只有启动时调用而已。

![1566910336828](E:\git_repo\Hao_Learn\2019\8\img\1566910336828.png)

JDK 7 HashMap 新增元素的过程：

```Java
public V put(K key, V value) {
	// 数组为空，则初始化扩容
	if (table == EMPTY_TABLE) {
		inflateTable(threshold);
	}
	// 存储空键的KV对
	if (key == null)
		return putForNullKey(value);
	int hash = hash(key);
	int i = indexFor(hash, table.length);
	// 此循环通过 hashCode 返回值找到对应的数组下标位置
	for (Entry<K,V> e = table[i]; e != null; e = e.next) {
		Object k;
		// 为了覆盖旧值
		if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
			V oldValue = e.value;
			e.value = value;
			e.recordAccess(this);
			return oldValue;
		}
	}

	// 还没有添加元素就进行 modCount++，将为后续留下很多隐患
	modCount++;
	// 添加元素，参数i为table数组的下标
	addEntry(hash, key, value, i);
	return null;
}

void addEntry(int hash, K key, V value, int bucketIndex) {
	// 如果元素的个数达到扩容阈值threshold且数组下标位置已经存在元素，则进行扩容
	if ((size >= threshold) && (null != table[bucketIndex])) {
		// 扩容2倍，size是实际存放元素的个数，而length是数组的容量大小
		resize(2 * table.length);
		hash = (null != key) ? hash(key) : 0;
		bucketIndex = indexFor(hash, table.length);
	}

	createEntry(hash, key, value, bucketIndex);
}

// 插入元素时，应插入头部，而不是尾部
void createEntry(int hash, K key, V value, int bucketIndex) {
	// 不管原来的数组对应的下标元素是否为null，都作为Entry的bucketIndex的next值
	Entry<K,V> e = table[bucketIndex]; // （第1处）
	// 即使原来是链表，也把整条链都挂在新插入的节点下
	table[bucketIndex] = new Entry<>(hash, key, value, e);
	size++;
}
```
在 createEntry() 方法中，新添加的元素直接放在 slot 槽上，使新添加的元素在下次提取时可以更快地被访问到。如果两个线程同时执行到第 1 处时，那么一个线程的赋值就会被另一个覆盖掉，这是对象丢失的原因之一。

![1566912645677](E:\git_repo\Hao_Learn\2019\8\img\1566912645677.png)

理想的哈希集合对象的存放应该符合：

- 只要对象不一样，hashCode 就不一样；
- 只要 hashCode 不一样，得到的 hashCode 与 hashSeed 位运算的 hash 就不一样；
- 只要 hash 不一样，存放在数组上的 slot 就不一样。

晗希碰撞的概率取决于 hashCode 计算方式和空间容量大小。

JDK7中 resize () 是如何进行数据迁移的：
```Java
void resize(int newCapacity) {
	// 获取旧表
	Entry[] oldTable = table;
	int oldCapacity = oldTable.length;
	// int MAXIMUM_CAPACITY = 1073741824 = 1 << 30
	if (oldCapacity == MAXIMUM_CAPACITY) {
		// 扩容阈值设置为 ‭2147483647‬，并返回，不能再扩容了
		threshold = Integer.MAX_VALUE;
		return;
	}
	Entry[] newTable = new Entry[newCapacity];
	// JDK8移除hashSeed计算，因为计算时会调用Random.nextInt()，存在性能问题
	transfer(newTable, initHashSeedAsNeeded(newCapacity));
	// 在此步骤完成前，旧表上依然可以进行元素的增加操作，这是对象丢失的原因之一
	table = newTable;
	threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);
}

// 从旧表迁移数据到新表
void transfer(Entry[] newTable, boolean rehash) {
	// 新表大小已经指定为2 * oldTable.length
	int newCapacity = newTable.length;
	// 使用 foreach 方式遍历整个数组
	for (Entry<K,V> e : table) {
		// 如果此 slot 上存在元素，则进行链表遍历（也有可能是单个节点），
		// 直到null != e，退出循环
		while(null != e) {
			Entry<K,V> next = e.next;
			// 当前元素总是直接放在数组下标的 slot 上．而不是放在链表的最后
			if (rehash) {
				e.hash = null == e.key ? 0 : hash(e.key);
			}
			int i = indexFor(e.hash, newCapacity);
			// 因为新数组上可能有元素（没有的话就是null），
			// 所以把原来 slot 上的元素作为 e.next
			// 新迁移过来的节点直接放置在 slot 位置上
			// 形象来说就是，将节点放入两者之间
			e.next = newTable[i];
			newTable[i] = e;
			// 链表继续向下遍历
			e = next;
		}
	}
}
```

transfer() 数据迁移方法在数组非常大时会非常消耗资源。当前线程迁移过程中，其他线程新增的元素有可能落在已经遍历过的哈希槽上，在遍历完成之后 table 数组引用指向了 newTable 这时新增元素就会丢失，被无情地垃圾回收。

如果 resize 完成，执行了 table = newTable ，则后续的元素就可以在新表上进行插入操作。但是如果多个线程同时执行 resize ，每个线程又都会 `new Entry[newCapacity]`， 这是线程内的局部数组对象，线程之间是不可见的。迁移完成后，resize 的线程会赋值给 table 线程共享变量，从而覆盖其他线程的操作，因此在其他线程进行插入中，之前操作的对象会被无情地丢弃。

HashMap 在高并发场景中，新增对象丢失原因如下：

- 并发赋值时被覆盖。
- 己遍历区间新增元素会丢失。
- 新表被覆盖。
- 迁移丢失。在迁移过程中，有并发时， next 被提前置成 null。

数据丢失是 HashMap 除死链外带入的另一个高并发问题，但通常不被重视。因为数据丢失的环节非常长，而且不会形成脏数据，所以不易察觉，不像死链那样火烧眉毛，比较明显。

接下来分析死链问题，transfer() 正是生产死链的地下黑工厂：

![1566914930388](E:\git_repo\Hao_Learn\2019\8\img\1566914930388.png)

扩展说明一下，由于 Integer 的 hashCode() 就是自身的值，因此有些人误以为Long 的 hashCode() 也是自身值,实际并非如此。以图 6-23 为例,先获取 Long    ( 1534820390196514000L ）的二进制值，然后右移 32 位后,再与原来的值进行异或，最后进行 int 的强制类型转换，相当于高位被截掉，如图 6-23 阴影部分所示。

![1566914813338](E:\git_repo\Hao_Learn\2019\8\img\1566914813338.png)

这样做的原因是 hashCode 的返回值是 int ，如果此集合内某些 Key 是由 int 向上转型而来的，那些 long 的值直接截取高位，会形成很大的冲突；如果仅拿高位，当 long 的取值范围在`Integer.MAX_VALUE` 内时，结果都是0。所以将高位与低位进行异或，有助于泊松分布。

![1566915116476](E:\git_repo\Hao_Learn\2019\8\img\1566915116476.png)

而对于死链的生成，需要先明确三点：
1. 原先没有死链的同一个 slot 上节点遍历一定能够按顺序走完。因为 e 和next 都是线程内的局部变量，是绝对不会互相干扰的，所以 while 循环在此次生成死链的过程中是会正常退出的。
2. table 数组是各线程都可以共享修改的对象。
3. put()、get()、transfer() 三种操作在运行到此拥有死链的 slot 上，CPU使用率都会飙升。

两个线程 A 和 B执行 transfer 方法，虽然 newTable 是局部变量，但是原先table 中的 Entry 链表是共享的。产生问题的根源是 Entry 的 next 被并发修改。这可能导致：
1. 对象丢失。
2. 两个对象互链。
3. 对象自己互链。
形成环路的原因是两个线程都执行完第一个节点的遍历操作后，到第二个节点时，产生互链，如图 6-26 所示。

![1566915653875](E:\git_repo\Hao_Learn\2019\8\img\1566915653875.png)

JDK7 是先扩容，然后进行新增元素操作， JDK8 是增加元素之后扩容。

JDK8 的 HashMap 改进了这种从头节点就开始操作数据迁移的做法，采用对原先链表的头尾节点引用，保证“有序性”。

#### ConcurrentHashMap 

JDK8 对 ConcurrentHashMap 进行了脱胎换骨式的改造，使用了大量的 lock-free 技术来减轻因锁的竞争而对性能造成的影响。它是学习并发编程的一个绝佳示例，此类超过 6300 行代码，涉及 volatile、CAS、锁、链表、红黑树等众多知识点。

ConcurrentHashMap 是在 JDK5 中引入的线程安全的哈希式集合，在 JDK8 之前采用了分段锁的设计理念，相当于 Hashtable 与 HashMap 的折中版本，这是效率与一致性权衡后的结果。分段锁是由内部类 Segment 实现的，它继承于 ReentrantLock ，用来管理它辖区的各个 HashEntry。Segment 通过加锁的方式，保证每个 Segment 内都不发生冲突。

JDK11 版本对 JDK7 版本的ConcurrentHashMap 进行了三点改造：
1. 取消分段锁机制，进一步降低冲突概率。
2. 引入红黑树结构。
3. 使用了更加优化的方式统计集合内的元素数量。首先， Map 原有的 size() 方法最大只能表示到 `2^31^ - 1`, ConcurrentHashMap 额外提供了 `mappingCount()`用来返回集合内元素的数量，最大可以表示到 `2^63^ - 1`。此外，元素总数更新时，使用了 CAS 多种优化以提高并发能力。

重要字段：
```Java
// 默认为null，ConcurrentHashMap 存放数据的地方，扩容时大小总是2的幂次方
// 初始化发生在第一次插入操作，数组默认初始化大小为 16
transient volatile Node<K,V>[] table;
// 默认为null，扩容时新生成的数组，其大小为原数组的两倍
private transient volatile Node<K,V>[] nextTable;
// 存储单个KV数据节点。内部有 key、value、hash、next 指向下一个节点
// 它有4个在 ConcurrentHashMap 类内部定义的子类：
// TreeBin、TreeNode、ForwardingNode、ReservationNode
// 前3个子类都重写了查找元素的重要方法 find()
static class Node<K,V> implements Map.Entry<K,V> { ... }

// 它并不存储实际数据，维护对桶内红黑树的读写锁，存储对红黑树节点的引用
static final class TreeBin<K,V> extends Node<K,V> { ... }
// 在红黑树结构中，实际存储数据的节点
static final class TreeNode<K,V> extends Node<K,V> { ... }
// 扩容转发节点，放置此节点后，外部对原有哈希槽的操作会转发到 nextTable 上
static final class ForwardingNode<K,V> extends Node<K,V> { ... }
// 占位加锁节点。执行某些方法时，对其加锁，如 computeIfAbsent 和 compute
static final class ReservationNode<K,V> extends Node<K,V> { ... }

// 默认为0，用来控制table的初始化和扩容操作
// sizeCtl = -1，表示正在初始化中
// sizeCtl = -n，表示（n-1）个线程正在进行扩容，即-1 -（线程数）
// sizeCtl > 0，初始化或扩容中需要使用的容量
// sizeCtl = 0，默认值，使用默认容量进行初始化
private transient volatile int sizeCtl;
// 集合size小于64，无论如何，都不会使用红黑树结构
// 转化为红黑树还有一个条件是 TREEIFY_THRESHOLD
static final int MIN_TREEIFY_CAPACITY = 64;
// 同一个哈希桶内存储的元素个数超过此阈值时
// 存储结构有链表转换为红黑树
static final int TREEIFY_THRESHOLD = 8;
// 同一个哈希桶内存储的元素个数小于等于此阈值时
// 从红黑树回退至链表结构，因为元素个数较少时，链表更快
static final int UNTREEIFY_THRESHOLD = 6;
```

![1566996504082](E:\git_repo\Hao_Learn\2019\8\img\1566996504082.png)

table 的长度为 64 ，数据存储结构分为两种：链表和红黑树。当某个槽内的元素个数增加到超过 8 个且 table 的容量大于或等于 64 时， 由链表转为红黑树，当某个槽内的元素个数减少到 6 个时，由红黑树重新转回链表。链表转红黑树的过程，就是把给定顺序的元素构造成一课红黑树的过程。需要注意的是，当table 的容量小于 64 时，只会扩容，并不会把链表转为红黑树。在在转化过程中，使用同步块锁住当前槽的首元素，防止其他进程对当前槽进行增删改操作，转化完成后利用 CAS 替换原有链表。因为 TreeNode 节点也存储了 next 引用，所以红黑树转链表的操作就变得非常简单，只需从 TreeBin 的 first 元素开始遍历所有的节点，并把节点从 TreeNode 类型转化为 Node 类型即可，当构造好新的链表之后，会同样利用 CAS 替换原有红黑树。相对来说，链表转红黑树更为复杂，流程图如图 6-28 所示。

![1566996696176](C:\Users\18622\AppData\Roaming\Typora\typora-user-images\1566996696176.png)

触发上述存储结构转化最主要的操作是增加元素， 即 put() 方法。基本思想与HashMap 一致，区别就是增加了锁的处理， ConcurrentHashMap 元素插入流程图如图 6-29 所示。

![1566996819187](E:\git_repo\Hao_Learn\2019\8\img\1566996819187.png)

ForwardingNode 在 table 扩容时使用，内部记录了扩容后的 table，即nextTable 。当 table 需要进行扩容时，依次遍历当前 table 中的每一个槽，如果不为 null ，则需要把其中所有的元素根据 hash 值放入扩容后的 nextTable 中， 而原 table 的槽内会放置一个 ForwardingNode 节点。正如其名，此节点会把 find() 请求转发到扩容后的 nextTable 上。而执行 put() 的线程如果碰到此节点，也会协助进行迁移。

ReservationNode 在 computeIfAbsent() 及其相关方法中作为一个预留节点使用。computeIfAbsent() 会先判断相应的 Key 值是否已存在，如果不存在，则调用由用户实现的自定义方法来生成 Value 值， 组成 KV 键值对，随后插入此哈希集合中。在并发场景下，从得知 Key 不存在到插入哈希集合的时间间隔内，为了防止哈希槽被其他线程抢占，当前线程会使用一个 ReservationNode 节点放到槽中并加锁，从而保证了线程的安全性。

正常的写操作，都会想对 hash 桶的第一个节点进行加锁，但是 null 是不能加锁，所以就要new一个占位符出来，放在这个空 hash 桶中成为第一个节点，把占位符当锁的对象，这样就能对整个 hash 桶加锁了。put() /remove() 不使用ReservationNode 是因为它们都特殊处理了下，并且这种特殊情况实际上还更简单，put() 直接使用CAS操作，remove() 直接不操作，都不用加锁。但是computeIfAbsent() 和 compute() 这个两个方法在碰见这种特殊情况时稍微复杂些，代码多一些，不加锁不好处理，所以需要 ReservationNode 来帮助完成对hash桶的加锁操作。

ConcurrentHashMap 在涉及元素总数的相关更新和计算时 ，会最大限度地减少锁的使用 ，以减少线程间的竞争与互相等待。在这个设计思路下， JDK8 的ConcurrentHashMap 对元素总数的计算又做了进一步的优化，具体表现在put()、remove()、size() 中，涉及元素总数的更新和计算，都彻底避免了锁的使用，取而代之的是众多的 CAS 操作。

![1566997697517](C:\Users\18622\AppData\Roaming\Typora\typora-user-images\1566997697517.png)

可以看到在 JDK7 版本中，ConcurrentHashMap 在统计元素总数时已经开始避免使用锁了，毕竟加锁操作会极大地影响到其他线程对于哈希元素的修改。

在 JDK8 的 put() 中，对于哈希元素总数的更新，是置于对某个槽的锁之外的，主要会用到的属性如下：

```Java
// 记录了元素总数值，主要用在无竞争状态下
// 在总数更新后，通过 CAS 方式直接更新这个值
private transient volatile long baseCount;
// 一个计数器单元．维护了一个 value 值
@sun.misc.Contended static final class CounterCell { ... }
// 在竟争激烈的状态下启用，线程会把总数更新情况存放到该结构内
// 当竞争进一步加剧时，会通过扩容减少竞争
private transient volatile CounterCell[] counterCells;
```

正是借助 baseCount 和 counterCells 两个属性，并配合多次使用 CAS 方法，JDK8 中的 ConcurrentHashMap 避免了锁的使用。思路：

- 当并发量较小时，优先使用 CAS 的方式直接更新 baseCount。
- 当更新 baseCount 冲突，则会认为进入到比较激烈的竞争状态，counterCells 减少竞争，通过 CAS 的方式把总数更新情况记录在 counterCells 对应的位置上。
- 如果更新 counterCells 上的某个位置时出现了多次失败，则会通过扩容 counterCells 的方式减少冲突。
- 当 countCells 处在扩容期间时，会尝试更新 baseCount 值。

对于元素总数的统计，逻辑就非常简单了，只需要让 baseCount 加上各 counterCells 内的数据，就可以得出哈希内的元素总数，整个过程完全不需要借助锁。

# 第七章 并发与多线程

并发是指在某个时间段内，多任务交替处理的能力；并行是指同时处理多任务的能力。它们的核心区别在于进程是否同时执行。
在并发环境下，由于程序的封闭性被打破，出现了以下特点：
1. 并发程序之间有相互制约的关系。直接制约体现为一个程序需要另一个程序的计算结果；间接制约体现为多个程序竞争共享资源，如处理器，缓冲区等。
2. 并发程序的执行过程是断断续续的。程序需要记忆现场指令及执行点。
3. 当并发数设置合理并且CPU拥有足够的处理功能时，并发会提高程序的运行效率。

## 7.1 线程安全

线程是 CPU 调度和分派的基本单位，为了更充分地利用 CPU 资源，一般都会使
用多线程进行处理。多线程的作用是提高任务的平均执行速度，但是会导致程序可理解性变差，编程难度加大。

线程可以拥有自己的操作枝、程序计数器、局部变量表等资源，它与同一进程内的其他线程共享该进程的所有资源。线程在生命周期内存在多种状态。

![1567081121222](E:\git_repo\Hao_Learn\2019\8\img\1567081121222.png)

1. NEW，即新建状态，是线程被创建且未启动的状态。创建线程的方式有三种：第一种是继承自 Thread 类，第二种是实现 Runnable 接口，第三种是实现 Callable 接口。相比第一种，推荐第二种方式，因为继承自 Thread 类往往不符合里氏代换原则，而实现 Runnable 接口可以使编程更加灵活，对外暴露的细节比较少，让使用者专注于实现线程的 run() 方法上。第三种 Callable 接口的 call () 声明如下：

```Java
/*
 * 计算一个返回值，或者如果不能这样做，就抛出一个异常
 */
V call() throws Exception; 
```

由此可知，Callable 与 Runnable 有两点不同：第一，可以通过 call() 获得返回值。前两种方式都有一个共同的缺陷，即在任务执行完成后，无法直接获取执行结果，需要借助共享变量等获取 ，而 Callable 和 Future 则很好地解决了这个问题； 第二， call() 可以抛出异常。而 Runnable 只有通过 setDefaultUncaughtExceptionHandler() 的方式才能在主线程中捕捉到子线程异常。
2. RUNNABLE，即就绪状态，是调用 start() 之后运行之前的状态。 线程的start() 不能被多次调用，否则会抛出 IllegalStateException 异常。
3. RUNNING，即运行状态，是run() 正在执行时线程的状态。 线程可能会由于某些因素而退出 RUNNING ，如时间、异常、锁、调度等。
4. BLOCKED，即阻塞状态，进入此状态，有以下种情况。

- 同步阻塞：锁被其他线程占用。
- 主动阻塞：调用 Thread 的某些方法，主动让出 CPU 执行权 ，比如 sleep()、join() 等。
- 等待阻塞：执行了 wait() 。

5. DEAD ，即终止状态，是 run() 执行结束，或同异常退出后的状态，此状态不可逆转。

保证高并发场景下的线程安全，可以从以下四个维度考量：
1. 数据单线程内可见。单线程总是安全的。通过限制数据仅在单线程内可见，可以避免数据被其他线程篡改。最典型的就是线程局部变量，它存储在独立虚拟机栈帧的局部变量表中，与其他线程毫无瓜葛。 ThreadLocal 就是采用这种方式来实现线程安全的。
2. 只读对象。只读对象总是安全的。它的特性是允许复制、拒绝写入。最典型的只读对象有 String、Integer 等。一个对象想要拒绝任何写入，必须要满足以下条件：使用 final 关键字修饰类，避免被继承；使用 private final 关键字避免属性被中途修改；没有任何更新方法；返回值不能可变对象为引用。
3. 线程安全类。 某些线程安全类的内部有非常明确的线程安全机制。比如StringBuffer 就是一个线程安全类，它采用 synchronized 关键字来修饰相关方法。
4. 同步与锁机制。如果想要对某个对象进行并发更新操作，但又不属于上述三类，需要开发工程师在代码中实现安全的同步机制。虽然这个机制支持的并发场景很有价值，但非常复杂且容易出现问题。

线程安全的核心理念就是“要么只读，要么加锁”。

并发包主要分成以下几个类族：
1. 线程同步类。这些类使线程间的协调更加容易，支持了更加丰富的线程协调场景，逐步淘汰了使用 Object 的 wait() 和 notify() 进行同步的方式。主要代表为 CountDownLatch、Semaphore、CyclicBarrier 等。
2. 并发集合类。 集合并发操作的要求是执行速度快，提取数据准。 主要代表为 ConcurrentHashMap、ConcurrentSkipListMap、CopyOnWriteArrayList、BlockingQueue 等。
3. 线程管理类。 虽然 Thread 和 ThreadLocal 在 JDK1.0 就已经引入，但是真正把 Thread 发扬光大的是线程池。
4. 锁相关类。锁以 Lock 接口为核心，派生出在一些实际场景中进行互斥操作的锁相关类。最有名的是 ReentrantLock。锁的很多概念在弱化，是因为锁的实现在各种场景中已经通过类库封装进去了。

## 7.2 什么是锁

单机单线程时代没有锁的概念，但自从出现了资源竞争，人们意识到需要对部分场景的执行现场加锁。计算机的锁也是从开始的悲观锁，发展到后来的乐观锁、偏向锁、分段锁等。锁主要提供了两种特性：互斥性和不可见性。

Java 中常用锁实现的方式有两种：
1. 用并发包中的锁类

并发包的类族中， Lock 是 JUC 包的顶层接口，它的实现逻辑并未用到synchronized ，而是利用了 volatile 的可见性。

![1567082877403](E:\git_repo\Hao_Learn\2019\8\img\1567082877403.png)

ReentrantLock 对于 Lock 接口的实现主要依赖了Sync，而 Sync 继承了 AbstractQueuedSynchronizer（ AQS），它是 JUC 包实现同步的基础工具。在 AQS 中，定义了一个 `volatile int state` 变量作为共享资源 ，如果线程获取资源失败，则进入同步 FIFO 队列中等待；如果成功获取资源就执行临界区代码。执行完释放资源时，会通知同步队列中的等待线程来获取资源后出队并执行。

AQS 是抽象类，内置自旋锁实现的同步队列，封装入队和出队的操作，提供独占、共享、中断等特性的方法。 AQS 的子类可以定义不同的资源实现不同性质的方法：

- 可重入锁 ReentrantLock ，定义 state 为 0 时可以获取资源并置为 1。若已获得资源，state 不断加 1 ，在释放资源时 state 减 1，直至为 0；
- CountDownLatch 初始时定义了资源总量 state = count, countDown() 不断将 state 减 1，当 state = 0时才能获得锁，释放后 state 就一直为 0 。所有线程调用 await() 都不会等待 ，所以 CountDownLatch 是一次性的，用完后如果再想用就只能重新创建一个；
- 如果希望循环使用，推荐使用基于 ReentrantLock 实现的 CyclicBarrier；
- Semaphore 与 CountDownLatch 略有不同，同样也是定义了资源总量state = permits，当 state > 0 时就能获得锁，并将 state 减 1 ，当 state = 0 时只能等待其他线程释放锁，当释放锁时 state 加 1，其他等待线程又能获得这个锁。当 Semphore 的 permits 定义为 1 时，就是互斥锁，当 permits > 1 就是共享锁。

2. 利用同步代码块

同步代码块一般使用 Java 的 synchronized 关键字来实现，有两种方式对方法进行加锁操作：第一，在方法签名处加 synchronized 关键字；第二，使用synchronized（对象或类）进行同步。这里的原则是锁的范围尽可能小，锁的时间尽可能短，即能锁对象，就不要锁类，能锁代码块，就不要锁方法。

synchronized 锁特性由 JVM 负责实现。在 JDK 的不断优化迭代中， synchronized 锁的性能得到极大提升，特别是偏向锁的实现，使得 synchronized 已经不是昔日那个低性能且笨重的锁了。 JVM 底层是通过监视锁来实现 synchronized 同步的。监视锁即 monitor，是每个对象与生俱来的一个隐藏字段。使用 synchronized 时， JVM会根据 synchronized 的当前使用环境，找到对应对象的 monitor ，再根据 monitor 的状态进行加/解锁的判断。例如，线程在进入同步方法或代码块时，会获取该方法或代码块所属对象的 monitor， 进行加锁判断。如果成功加锁就成为该 monitor 的唯一持有者。
monitor 在被释放前，不能再被其他线程获取。

JVM 就是利用 CAS 在对象头上设置线程 ID ，表示这个对象偏向于当前线程，这就是偏向锁。偏向锁是为了在资源没有被多线程竞争的情况下尽量减少锁带来的性能开销。在锁对象的对象头中，有一个 ThreadId 字段，当第一个线程访问锁时， 如果该锁没有被其他线程访问过，Threadld 字段为空，那么 JVM 让其持有偏向锁，并将 Threadld 字段的值设置为该线程的 ID。当下一次获取锁时，会判断当前线程的 ID 是否与锁对象的 Threadld 一致。如果一致，那么该线程不会再重复获取锁，从而提高了程序的运行效率。如果出现锁的竞争情况，那么偏向锁会被撤销并升级为轻量级锁。如果资源的竞争非常激烈，会升级为重量级锁。偏向锁可以降低无竞争开销，它不是互斥锁 ，不存在线程竞争的情况，省去再次同步判断的步骤，提升了性能。

## 7.3 线程同步

#### 同步是什么

资源共享的两个原因是资源紧缺和共建需求。线程共享 CPU 是从资源紧缺的维度来考虑的，而多线程共享同一变量，通常是从共建需求的维度来考虑的。

在多个线程对同一变量进行写操作时，如果操作没有原子性，就可能产生脏数据。所谓原子性是指不可分割的一系列操作指令，在执行完毕前不会被任何其他操作中断，即要么全部执行，要么全部不执行。如果每个线程的修改都是原子操作，就不存在线程同步问题。

#### volatile

计算机并不会根据代码顺序按部就班地执行相关指令，CPU 在处理信息时会进行**指令优化**，分析哪些取数据动作可以合并进行，哪些存数据动作可以合并进行。

happen before 是时钟顺序的先后，并不能保证线程交互的可见性。可见性是指某线程修改共享变量的指令对其他线程来说都是可见的，它反映的是指令执行的实时透明度。

每个线程都有独占的内存区域，线程本地内存保存引用变量在堆内存中的副本，线程对变量的所有操作都在本地内存区域中进行，执行结束后再同步到堆内存中去。这里必然有一个时间差，在这个时间差内，该线程对副本的操作，对于其他线程都是不可见的。

volatile 的英文本义是“挥发、不稳定的”，延伸意义为敏感的。当使用 volatile 修饰变量时，意味着任何对此变量的操作都会在内存中进行，不会产生副本，以保证共享变量的可见性，局部阻止了指令重排的发生。

双重检查锁定（ Double-checked Locking ）问题：对象引用在没有同步的情况下进行读操作，导致用户可能会获取未构造完成的对象。对于此问题，一种较为简单的解决方案是用 volatile 关键字修饰目标属性（适用于 JDK5 及以上版本）， 这样 service 就限制了编译器对它的相关读写操作，对它的读写操作进行指令重排，确定对象实例化之后才返回引用。锁也可以确保变量的可见性，但是实现方式和 volatile 略有不同。线程在得到锁时读入副本，释放时写回内存，锁的操作尤其要符合 happen before 原则。

volatile 解决的是多线程共享变量的可见性问题，类似于 synchronized ，但不具备 synchronized 的互斥性，所以对 volatile 变量的操作并非都具有原子性。它只是轻量级的线程操作可见方式，并非同步方式，如果是多写场景，一定会产生线程安全问题。如果是一写多读的并发场景，使用 volatile 修饰变量则非常合适。 volatile 一写多读最典型的应用是 CopyOnWriteArrayList 。它在修改数据时会把整个集合的数据全部复制出来，对写操作加锁，修改完成后，再用setArray() 把 array 指向新的集合。使用 volatile 可以便读线程尽快地感知 array 的修改，不进行指令重排，操作后即对其他线程可见。

如果不确定共享变量是否会被多个线程并发写，保险的做法是使用同步代码块来实现线程同步。另外，因为所有的操作都需要同步给内存变量，所以volatile 一定会使线程的执行速度变慢，故要审慎定义和使用 volatile 属性。

#### 信号量同步

信号量同步是指在不同的线程之间，通过传递同步信号量来协调线程执行的先后次序。

CountDownLatch 是基于执行时间的同步类。在实际编码中，可能需要处理基于空闲信号的同步情况。比如海关安检的场景，任何国家公民在出国时，都要走海关的查验通道。假设某机场的海关通道共有 3 个窗口 一批需要出关的人排成长队，每个人都是一个线程。当 3 个窗口中的任意一个出现空闲时，工作人员指示队列中第一个人出队到该空闲窗口接受查验。对于上述场景， JDK 中提供了一个 Semaphore 的信号同步类，只有在调用 Semaphore 对象的 acquire() 成功后，才可以往下执行，完成后执行 release() 释放持有的信号量，下一个线程就可以马上获取这个空闲信号量进入执行。

CyclicBarrier 是基于同步到达某个点的信号量触发机制。CyclicBarrier 命名上即可知道它是一个可以循环使用 （Cyclic）的屏障式 （Barrier）多线程协作方式。采用这种方式进行刚才的安检服务，就是 3 个人同时进去，只有 3 个人都完成安检，才会放下一批进来。这是一种非常低效的安检方式。但在某种场景就是非常正确的方式，假设在机场排队打车时，现场工作人员统一指挥，每次放 3 辆车进来 ，坐满后开走，再放下一批车和人进来。通过 CyclicBarrier 的 reset()来释放线程资源。

## 7.4 线程池

#### 线程池的好处

线程池协调多个线程，并实现类似主次线程隔离、定时执行、周期执行等任务。线程池的作用包括：

- 利用线程池管理并**复用**线程、**控制**最大并发数等。
- 实现任务线程队列**缓存策略和拒绝机制**。
- 实现某些与**时间**相关的功能，如定时执行、周期执行等。
- **隔离线程环境**。通过配置独立的线程池将服务隔离开，避免各服务线程相互影响。

ThreadPoolExecutor 的构造方法如下：

```Java
public ThreadPoolExecutor(
				int corePoolSize,
				int maximumPoolSize,
				long keepAliveTime,
				TimeUnit unit,
				BlockingQueue<Runnable> workQueue,
				ThreadFactory threadFactory,
				RejectedExecutionHandler handler) {
	if (corePoolSize < 0 ||
		maximumPoolSize <= 0 ||
		maximumPoolSize < corePoolSize ||
		keepAliveTime < 0)
		throw new IllegalArgumentException();
	if (workQueue == null || threadFactory == null || handler == null)
		throw new NullPointerException();
	this.acc = System.getSecurityManager() == null ?
			null :
			AccessController.getContext();
	this.corePoolSize = corePoolSize;
	this.maximumPoolSize = maximumPoolSize;
	this.workQueue = workQueue;
	this.keepAliveTime = unit.toNanos(keepAliveTime);
	this.threadFactory = threadFactory;
	this.handler = handler;
}
```

1. corePoolSize 表示常驻核心线程数。如果等于 0，则任务执行完之后没有任何请求进入时销毁线程池的线程；如果大于 0，即使本地任务执行完毕，核心线程也不会被销毁。这个值的设置非常关键，设置过大会浪费资源，设置过小会导致线程频繁地创建或销毁。
2. maximumPoolSize 表示线程池能够容纳同时执行的最大线程数，必须大于或等于 1。如果待执行的线程数大于此值，需要借助第 5 个参数的帮助，将线程缓存在队列中。如果 maximumPoolSize 与 corePoolSize 相等，即是固定大小线程池。
3. keepAliveTime 表示线程池中的线程空闲时间，当某线程空闲时间达该值时，就会被销毁，直到只剩下 corePoolSize 个线程为止，避免浪费内存和句柄资源。在默认情况下，当线程池的线程数大于 corePoo!Size 时，keepAliveTime 才会起作用。
4. TimeUnit 表示时间单位。 keepAliveTime 的时间单位通常是TimeUnit.SECONDS。
5. workQueue 表示缓存队列。当请求的线程数大于 maximumPoolSize 线程进入 BlockingQueue 阻塞队列。LinkedBlockingQueue 是单向链表，使用锁来控制入队和出队的原子性，两个锁分别控制元素的添加和获取，是一个生产消费模型队列。
6. threadFactory 表示线程工厂。它用来生产一组相同任务的结程。线程池的命名是通过给这个 factory 增加组名前缀来实现的。在虚拟机栈分析时，就可以知道线程任务是由哪个线程工厂产生的。
7. handler 表示执行拒绝策略的对象。当超过workQueue 的任务缓存区上限时，就可以通过该策略处理请求，这是一种简单的限流保护。友好的拒绝策略可以是如下三种：

- 保存到数据库进行削峰填谷。在空闲时再提取出来执行。
- 转向某个提示页面。
- 打印日志。

在构造方法中，队列、线程工厂、拒绝处理服务都必须有实例对象，但在实际编程中，很少有程序员对这三者进行实例化，而通过 Executors 这个线程池静态工厂提供默认实现。

![1567234536395](E:\git_repo\Hao_Learn\2019\8\img\1567234536395.png)

核心方法 Executor.execute () 没有在抽象类 AbstractExecutorService 里实现。因为所有的任务都在这个方法里执行，不同实现会带来不同的执行策略。

通过 Executors 的静态工厂方法可以创建三个线程池的包装对象：ForkJoinPool、ThreadPooIExecutor、ScheduledThreadPoolExecutor。

Executors 核心的方法有五个：

1. Executors.newWorkStealingPool：JDK8 引入，创建持有足够线程的线程池支持给定的并行度，并通过使用多个队列减少竞争，此构造方法中 CPU 数量设置为默认的并行度。

```Java
public static ExecutorService newWorkStealingPool() {
        return new ForkJoinPool
            (Runtime.getRuntime().availableProcessors(),
             ForkJoinPool.defaultForkJoinWorkerThreadFactory,
             null, true);
    }
```

2. Executors.newCachedThreadPool：maximumPoolSize 最大可以至Integer.MAX_VALUE， 是高度可伸缩的线程池。 keepAliveTime 默认为 60 秒，工作线程处于空闲状态，则回收工作线程。如果任务数增加，再次创建出新线程处理任务。

3. Executors.newScheduledThreadPool：线程数最大至 Integer.MAX_VALUE，是 ScheduledExecutorService 接口家族的实现类，支持定时及周期性任务执行。相 Timer，ScheduledExecutorService 更安全，功能更强大，与 newCachedThreadPool 的区别是不回收工作线程。

4. Executors.newSingleThreadExecutor：创建个单线程的线程池，相当于单线程串行执行所有任务，保证接任务的提交顺序依次执行。

5. Executors.newFixedThreadPool : 输入的参数即是固定线程数，既是核心线程数也是最大线程数，不存在空闲线程，所以 keepAliveTime 等于 0。

```Java
public static ExecutorService newFixedThreadPool(int nThreads) {
	return new ThreadPoolExecutor(nThreads, 
		nThreads, 0L, TimeUnit.MILLISECONDS, 
		new LinkedBlockingQueue<Runnable>());
}

public LinkedBlockingQueue() {
	this(Integer.MAX_VALUE);
}
```

使用这样的无界队列，如果瞬间请求非常大，会有 OOM 的风险。除newWorkStealingPool 外，其他四个创建方式都存在资源耗尽的风险。

Executors 中默认的线程工厂和拒绝策略过于简单，通常对用户不够友好。

线程工厂需要做创建前的准备工作，对线程池创建的线程必须明确标识，并为线程本身指定有意义的名称和相应的序列号。可以通过实现 ThreadFactory 接口及其 newThread() 方法快速、统一地创建线程任务，方便出错时回溯。

拒绝策略应该考虑到业务场景，返回相应的提示或者友好地跳转。可以通过实现 RejectedExecutionHandler 接口及其 rejectedExecution() 方法，来打印出当前线程池状态。

ThreadPoolExecutor 中提供了四个公开的内部静态类
• AbortPolicy（默认）：丢弃任务并抛出 RejectedExecutionException 异常。
• DiscardPolicy：丢弃任务，但是不抛出异常，这是不推荐的做法。
• DiscardOldestPolicy：抛弃队列中等待最久的任务，然后把当前任务加入队列中。
• CallerRunsPolicy ：调用任务的 run() 方法绕过线程池直接执行。

#### 线程池源码详解

在 ThreadPoolExecutor 的属性定义中频繁地用位移运算来表示线程池状态，位移运算是改变当前值的一种高效手段，包括左移与右移。

```Java
// 初始值为 线程池能接受新任务且线程数为0
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
// Integer有32位，最左边3位表示线程池状态，右边29位表示工作线程数
private static final int COUNT_BITS = Integer.SIZE - 3;
// 线程容量，但实际为掩码，用于位的与运算
// 000 - 11111111111111111111111111111
private static final int CAPACITY   = (1 << COUNT_BITS) - 1;

// 这样设计的好处是可以通过比较值的大小来确定线程池的状态。
// 111 - 00000000000000000000000000000
// 此状态表示线程池能接受新任务
private static final int RUNNING    = -1 << COUNT_BITS;
// 000 - 00000000000000000000000000000
// 此状态表示线程池不能接受新任务，但可以继续执行队列中的任务
private static final int SHUTDOWN   =  0 << COUNT_BITS;
// 001 - 00000000000000000000000000000
// 此状态表示线程池全面拒绝，并中断正在处理的任务
private static final int STOP       =  1 << COUNT_BITS;
// 010 - 00000000000000000000000000000
// 此状态表示线程池中所有的任务都被终止了
private static final int TIDYING    =  2 << COUNT_BITS;
// 011 - 00000000000000000000000000000
// 此状态表示已清理完现场
private static final int TERMINATED =  3 << COUNT_BITS;

// c & 111 - 00000000000000000000000000000，有0得0，可得到状态值
private static int runStateOf(int c)     { return c & ~CAPACITY; }
// c & 000 - 11111111111111111111111111111，有0得0，可得到线程数
private static int workerCountOf(int c)  { return c & CAPACITY; }
// 有1得1，可合并出ctl
private static int ctlOf(int rs, int wc) { return rs | wc; }

private static boolean runStateLessThan(int c, int s) {
	return c < s;
}

private static boolean runStateAtLeast(int c, int s) {
	return c >= s;
}

private static boolean isRunning(int c) {
	return c < SHUTDOWN;
}
```

ThreadPoolExecutor 关于 execute 方法的实现：

```Java
public void execute(Runnable command) {
	if (command == null)
		throw new NullPointerException();
	

	int c = ctl.get();
	// 如果工作线程数小于核心线程数，则创建线程任务并执行
	if (workerCountOf(c) < corePoolSize) {
		// 判断常驻核心线程数
		if (addWorker(command, true))
			return;
		// 如果创建任务失败，防止外部已经在线程池中加入新任务，重新获取一下
		c = ctl.get();
	}

	// 只有线程池处于RUNNING状态，才执行workQueue.offer - 置入队列
	if (isRunning(c) && workQueue.offer(command)) {
		int recheck = ctl.get();
		// 如果线程池当前不是RUNNING状态，则将刚加入队列的任务移除，之后唤醒拒绝策略
		if (! isRunning(recheck) && remove(command))
			reject(command);
		// 如果之前的线程已经被消费完，新建一个线程，判断最大允许线程数
		else if (workerCountOf(recheck) == 0)
			addWorker(null, false);
	}
	// 核心池和队列都已满，尝试创建一个新线程，判断最大允许线程数
	else if (!addWorker(command, false))
		// 如果创建失败，则唤醒拒绝策略
		reject(command);
}
```

发生拒绝的理由有两个：线程池状态为非 RUNNING 状态；等待队列己满。

```Java
// 根据当前线程池状态，检查是否可以添加新的任务线程，如果可以则创建并启动任务
private boolean addWorker(Runnable firstTask, boolean core) {
	retry: // 配合循环语旬出现的label ，类似于goto作用。
	for (;;) {
		int c = ctl.get();
		int rs = runStateOf(c);

		// 如果RUNNING状态，则条件为假，不执行后面的判断
		// 如果为STOP及之上的状态，或者初始线程firstTask不为空，或者队列为空
		// 都会直接导致创建失败
		if (rs >= SHUTDOWN &&
			! (rs == SHUTDOWN &&
			   firstTask == null &&
			   ! workQueue.isEmpty()))
			return false;

		for (;;) {
			int wc = workerCountOf(c);
			// 如果线程数超过容量则不能再添加新的线程。
			// 如果线程数超过常驻核心线程数 最大允许线程数
			if (wc >= CAPACITY ||
				wc >= (core ? corePoolSize : maximumPoolSize))
				return false;
			// 将当前活动线程数+1
			// 使用 Atomiclnteger 对象的加1操作是原子性的
			// 该方法执行失败的概率非常低。即使失败，
			// 再次执行时成功的概率也是极高的，类似于自旋锁原理。
			if (compareAndIncrementWorkerCount(c))
				break retry;
			
			// ctl是可变化的，需要经常读取最新值
			c = ctl.get(); 
			// 如果线程池已关闭，则再次循环
			if (runStateOf(c) != rs)
				continue retry;
			// 否则，由于WorkerCount更改，CAS失败；retry内部循环
		}
	}

	// 开始创建工作线程
	boolean workerStarted = false;
	boolean workerAdded = false;
	Worker w = null;
	try {
		// 利用Worker构造方法中的线程池工厂创建线程，并封装成工作线程Worker类
		w = new Worker(firstTask);
		// 获取Worker中的属性对象thread
		final Thread t = w.thread;
		if (t != null) {
			// 在进行ThreadPoolExecutor的敏感操作时，需要加主锁，避免在添加和启动线程时被干扰
			final ReentrantLock mainLock = this.mainLock;
			mainLock.lock();
			try {
				// 当保持锁的时候重新检查
				// 如果ThreadFactory发生故障或在获取锁之前关闭，则退出
				int rs = runStateOf(ctl.get());
				// 线程池为RUNNING状态 或 线程池为RUNNING状态且初始线程firstTask为空
				if (rs < SHUTDOWN ||
					(rs == SHUTDOWN && firstTask == null)) {
					if (t.isAlive()) // 预检t是否启动
						throw new IllegalThreadStateException();
					// private final HashSet<Worker> workers = new HashSet<Worker>();
					// 运用HashSet存储了线程池中所有的工作线程，只有在保持主锁的时候才访问
					workers.add(w);
					int s = workers.size();
					// largestPoolSize 为整个线程池在运行期间的最大并发任务个数
					if (s > largestPoolSize)
						largestPoolSize = s;
					workerAdded = true;
				}
			} finally {
				mainLock.unlock();
			}
			if (workerAdded) {
				// 通过查看下面Worker类的源码，发现启动的是新创建的线程t，
				// 而非execute方法的参数command指向的线程
				t.start();
				workerStarted = true;
			}
		}
	} finally {
		// 线程启动失败，需要移除刚添加工作线程并减去当前活动线程数
		if (! workerStarted)
			addWorkerFailed(w);
	}
	return workerStarted;
}

private void addWorkerFailed(Worker w) {
	final ReentrantLock mainLock = this.mainLock;
	mainLock.lock();
	try {
		// 移除工作线程
		if (w != null)
			workers.remove(w);
		// 减去当前活动线程数
		decrementWorkerCount();
		tryTerminate();
	} finally {
		mainLock.unlock();
	}
}

private void decrementWorkerCount() {
	do {} while (! compareAndDecrementWorkerCount(ctl.get()));
}

// 使用了CAS
private boolean compareAndDecrementWorkerCount(int expect) {
	return ctl.compareAndSet(expect, expect - 1);
}

public final boolean compareAndSet(int expect, int update) {
	return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
}
```

```Java
private final class Worker
        extends AbstractQueuedSynchronizer
        implements Runnable
{
	final Thread thread;
	Runnable firstTask;

	Worker(Runnable firstTask) {
		// AbstractQueuedSynchronized 的方法
		setState(-1); // 在调用runWorker之前禁止线程被中断
		this.firstTask = firstTask;
		this.thread = getThreadFactory().newThread(this);
	}

	// 当thread被start()之后，执行runWorker
	public void run() {
		runWorker(this);
	}
}
```

使用线程池要注意如下几点：
1. 合理设置各类参数，应根据实际业务场景来设置合理的工作线程数。
2. 线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。
3. 创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。

线程池不允许使用 Executors ，而是通过 ThreadPoolExecutor 的方式创建 ，这样的处理方式能更加明确线程池的运行规则，规避资源耗尽的风险。

## 7.5 ThreadLocal

ThreadLocal 初衷是在线程并发时，解决变量共享问题，但由于过度设计，比如弱引用和哈希碰撞，导致理解难度大、使用成本高，反而成为故障高发点，容易出现内存泄漏、脏数据、共享对象更新等问题。

#### 引用类型

对象在堆上创建之后所持有的引用其实是一种变量类型，引用之间可以通过赋值构成一条引用链。引用的可达性是判断能否被垃圾回收的基本条件。JVM 会据此自动管理内存的分配与回收，不需要开发工程师干预。但在某些场景下，即使引用可达，也希望能够根据语义的强弱进行有选择的回收，以保证系统的正常运行。根据引用类型语义的强弱来决定垃圾回收的阶段，我们可以把引用分为强引用、软引用、弱引用和虚引用四类。

1. 强引用（Strong Reference）， 最为常见。如 Object object = new Object()；这样的
变量声明和定义就会产生对该对象的强引用。只要对象有强引用指向，并且 GC Roots 可达，那么 Java 内存回收时，即使濒临内存耗尽，也不会回收该对象。

2. 软引用（Soft Reference），引用力度弱于强引用，是用在非必需对象的场景。在即将 OOM 之前，垃圾回收器会把这些软引用指向的对象加入回收范围，以获得更多的内存空间，让程序能够继续健康运行。主要用来缓存服务器中间计算结果及不需要实时保存的用户行为等。

3. 弱引用（Weak Reference），引用强度较前两者更弱，也是用来描述非必需对象的。如果弱引用指向的对象只存在弱引用这一条线路，则在下一次 YGC 时会被回收。由于 YGC 时间的不确定性，弱引用何时被回收也具有不确定性。弱引用主要用于指向某个易消失的对象，在强引用断开后，此引用不会劫持对象。调用 WeakReference.get() 可能返回 null ，要注意空指针异常。

4. 虚引用（Phantom Reference），是极弱的一种引用关系，定义完成后，就无法通过该引用获取指向的对象。为一个对象设置虚引用的唯一目的就是希望能在这个对象被回收时收到一个系统通知。虚引用必须与引用队列联合使用，当垃圾回收时，如果发现存在虚引用，就会在回收对象内存前，把这个虚引用加入与之关联的引用队列中。

![1566870450364](E:\git_repo\Hao_Learn\2019\8\img\1566870450364.png)

软引用、弱引用、虚引用均存在带有队列的构造方法：
```java
public SoftReference(T referent, ReferenceQueue<? super T> q){ ... } 
```

软引用一般用于在同一服务器内缓存中间结果。如果命中缓存，则提取缓存结果，否则重新计算或获取。但是，软引用肯定不是用来缓存高频数据的，万一服务器重启或者软引用触发大规模回收，所有的访问将直接指向数据库，导致数据库的压力时大时小，甚至崩溃。

`System.gc()`会建议垃圾收集器尽快进行垃圾收集，具体何时执行仍由 JVM 来判断。`System.runFinalization()`的作用是强制调用已经失去引用对象的`finalize()`。在代码中同时调用这两者，有利于更快地执行垃圾回收。

在 JVM 启动参数加`-XX:+PrintGCDetails` （或高版本 JDK 使用 `-Xlog:gc`）来  
观察 GC 的触发情况。

在 YGC 下，可以轻松地回收 WeakReference 指向的对象。 WeakReference 典型的应用是在 WeakHashMap 中。WeakHashMap 适用于缓存不敏感的临时信息的场景。例如，用户登录系统后的浏览路径在关闭浏览器后可以自动清空。

WeakReference 这种特性也用在了 ThreadLocal 上。 JDK 中的设计原意是在 ThreadLocal 对象消失后，线程对象再持有这个 ThreadLocal 对象是没有任何意义的，应该进行回收，从而避免内存泄漏。这种设计的出发点很好，但在实际业务场景中却并非如此，弱引用的设计方式反而增加了对 ThreadLocal 和 Thread 体系的理解难度。

除强引用外，其他三种引用可以减少对象在生命周期中所占用的内存大小。如果控制得当，垃圾回收就能够随意地释放这些对象。如果使用了这些引用，就应该避免强引用劫持，即把强引用置为 null ，否则这三种引用就无法发挥它们的价值。

#### Threadlocal 价值

ThreadLocal 不能被翻译为线程本地化或本地线程，英语恰当的名称应该叫作`CopyValueIntoEveryThread`。

```Java
public T get() {
	Thread t = Thread.currentThread();
	ThreadLocalMap map = getMap(t);
	if (map != null) {
		ThreadLocalMap.Entry e = map.getEntry(this);
		if (e != null) {
			@SuppressWarnings("unchecked")
			T result = (T)e.value;
			return result;
		}
	}
	return setInitialValue();
}
```
每个线程都有自己的 ThreadLocalMap，如果 map == null ，则直接执行 setlnitialValue() 。如果 map 已经创建，就表示 Thread 类的 threadLocals 属性已经初始化，如果 e == null ，依然会执行到 setlnitialValue()。setlnitialValue() 的源码如下：

```Java
protected T initialValue() {
	return null;
}

private T setInitialValue() {
	// 这是一个保护方法，CsGameByThreadLocal中初始化ThreadLocal对象时已覆写
	T value = initialValue();
	Thread t = Thread.currentThread();
	// getMap的源码就是提取线程对象t的ThreadLocalMap属性：t.threadLocals 
	ThreadLocalMap map = getMap(t);
	if (map != null)
		map.set(this, value);
	else
		createMap(t, value);
	return value;
}
```
```Java
private static final ThreadLocalRandom RANDOM = ThreadLocalRandom.current();
```
threadLocalRandom 可以生成单独的Random 实例，此类在 JDK7 中引入，它使得每个线程都可以有自己的随机数生成器。要避免 Random 实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一 seed 而导致性能下降。

ThreadLocal 对象通常是由 private static 修饰的，因为都需要复制进入本地线程，所以非 static 作用不大。需要注意的是， ThreadLocal 无法解决共享对象的更新问题，使用某个引用来操作共享对象时，依然需要进行线程同步。

![1566873826525](E:\git_repo\Hao_Learn\2019\8\img\1566873826525.png)

ThreadLocal 有个静态内部类叫 ThreadLocalMap，它还有一个静态内部类叫 Entry，在 Thread 中的 ThreadLocalMap 属性的赋值是在 ThreadLocal 类中的 createMap() 中进行的。 ThreadLocal 与 ThreadLocalMap 有三组对应的方法 get() 、set() 和 remove()， 在ThreadLocal 中对它们只做校验和判断 ，最终的实现会落在ThreadLocalMap 上。 Entry 继承自 WeakReference，没有方法，只有一个 value 成员变量，它的 key 是 ThreadLocal 对象。

![1566874718278](E:\git_repo\Hao_Learn\2019\8\img\1566874718278.png)

- 1 个 Thread 有且仅有 1 个 ThreadLocalMap 对象；
- 1 个 ThreadLocalMap 对象存储多个 Entry 对象；
- 1 个 Entry 对象的 Key 弱引用指向 1 个 ThreadLocal 对象；
- 1 个 ThreadLocal 对象可以被多个线程所共享；
- ThreadLocal 对象不持有 Value, Value 由线程的 Entry 对象持有。

图中的红色虚线箭头是重点，也是 ThreadLocal 中难以理解的地方， Entry的源码如下：

```Java
static class Entry extends WeakReference<ThreadLocal<?>> {
	/** The value associated with this ThreadLocal. */
	Object value;

	Entry(ThreadLocal<?> k, Object v) {
		super(k);
		value = v;
	}
}
```

所有 Entry 对象都被 ThreadLocalMap 类实例化对象 threadLocals 持有。当线程对象执行完毕时，线程对象内的实例属性均会被垃圾回收。源码中的红色字标识的 ThreadLocal 的弱引用，即使线程正在执行中， 只要 ThreadLocal 对象引用被置成 null, Entry 的 Key 就会自动在下一次 YGC 时被垃圾回收。而在 ThreadLocal 使用 set() 和 get() 又会自动地将那些 key == null 的 value 置为 null，使 value 能够被垃圾回收，避免内存泄漏，但是理想很丰满，现实很骨感，ThreadLocal 如源码注释所述：

ThreadLocal 对象通常作为私有静态变量使用，那么其生命周期至少不会随着线程结束而结束。

线程使用 ThreadLocal 有三个重要方法：
1. set()：如果没有 set 操作的 ThreadLocal ，容易引起脏数据问题。
2. get()：始终没有 get 操作的 ThreadLocal 对象是没有意义的。
3. remove()：如果没有 remove 操作，容易引起内存泄露。

ThreadLocal ，它通常用于同一个线程内，跨类、跨方法传递数据。如果没有 ThreadLocal ，那么相互之间的信息传递，势必要靠返回值和参数，这样无形之中，有些类甚至有些框架会互相耦合。

通过 Thread 构造方法，可以把当前线程的变量继续往下传递给它创建的子线程，源码如下：

```Java
public Thread(ThreadGroup group, Runnable target, String name,
				long stackSize) {
	init(group, target, name, stackSize);
}

private void init(ThreadGroup g, Runnable target, String name,
                      long stackSize) {
	init(g, target, name, stackSize, null, true);
}

private void init(ThreadGroup g, Runnable target, String name,
					long stackSize, AccessControlContext acc,
					boolean inheritThreadLocals) {
	if (name == null) {
		throw new NullPointerException("name cannot be null");
	}
	this.name = name;

	Thread parent = currentThread();
	SecurityManager security = System.getSecurityManager();
	if (g == null) {
		// 确定它是否是小程序
		// 如果有安全管理器，请询问安全管理器做什么。
		if (security != null) {
			g = security.getThreadGroup();
		}

		// 如果安全管理器对这件事没有强烈的意见，请使用父线程组。
		if (g == null) {
			g = parent.getThreadGroup();
		}
	}

		// 无论是否显式传入线程组，都要检查访问。
	g.checkAccess();

	// 我们有必要的权限吗
	if (security != null) {
		if (isCCLOverridden(getClass())) {
		security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION);
		}
	}

	g.addUnstarted();

	this.group = g;
	this.daemon = parent.isDaemon();
	this.priority = parent.getPriority();
	if (security == null || isCCLOverridden(parent.getClass()))
		this.contextClassLoader = parent.getContextClassLoader();
	else
		this.contextClassLoader = parent.contextClassLoader;
	this.inheritedAccessControlContext =
			acc != null ? acc : AccessController.getContext();
	this.target = target;
	setPriority(priority);
	if (inheritThreadLocals && parent.inheritableThreadLocals != null)
	// createlnheritedMap() 其实就是调用 ThreadLocalMap 的私有构造方法来产生一个实例对象，把父线程的不为 null 的线程变量都拷贝过来
		this.inheritableThreadLocals =
			ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
	// 存储指定的堆栈大小，以防VM关心
	this.stackSize = stackSize;

	// 设置线程ID
	tid = nextThreadID();
}

static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) {
	return new ThreadLocalMap(parentMap);
}

private ThreadLocalMap(ThreadLocalMap parentMap) {
	// table 就是存储
	Entry[] parentTable = parentMap.table;
	int len = parentTable.length;
	setThreshold(len);
	table = new Entry[len];

	for (int j = 0; j < len; j++) {
		Entry e = parentTable[j];
		if (e != null) {
			@SuppressWarnings("unchecked")
			ThreadLocal<Object> key = (ThreadLocal<Object>) e.get();
			if (key != null) {
				Object value = key.childValue(e.value);
				Entry c = new Entry(key, value);
				int h = key.threadLocalHashCode & (len - 1);
				while (table[h] != null)
					h = nextIndex(h, len);
				table[h] = c;
				size++;
			}
		}
	}
}
```
淘宝在很多场景下就是通过 ThreadLocal 来透传全局上下文的，比如用 ThreadLocal 来存储监控系统的某个标记位，暂且命名为 traceId 。某次请求下所有的 traceld 都是一致的，以获得可以统一解析的日志文件。但在实际开发过程中，发现子线程里的 traceld 为 null ，跟主线程的 traceId 并不一致，所以这就需要刚才说到的 InheritableThreadLocal 来解决父子线程之间共享线程变量的问题，使整个连接过程中 traceId 一致。实现代码如下所示：

```Java
public class RequestProcessTrace {
	private static final InheritableThreadLocal<FullLinkContext> FULL_LINK_THREADLOCAL = new InheritableThreadLocal<>();
	public static FullLinkContext getContext() {
		FullLinkContext fullLinkContext = FULL_LINK_THREADLOCAL.get();
		if (fullLinkContext == null ) {
			FULL_LINK_THREADLOCAL.set(new FullLinkContext()) ;
			fullLinkContext = FULL_LINK_THREADLOCAL.get () ;
		}
		return fullLinkContext;
	}

	public static class FullLinkContext {
		private String traceId;
		public String getTraceid () {
			if (StringUtils.isEmpty(traceid)) {
				FrameWork.startTrace(null, "gujin");
				traceid = FrameWork.getTraceId();
			}
			return traceId;
		}
		public void setTraceid(String traceid) {
			this.traceId = traceId;
		}
	}
}
```

使用 ThreadLocal 和 InheritableThreadLocal 透传上下文时，需要注意线程间切换、异常传输时的处理，避免在传输过程中因处理不当而导致的上下文丢失。

最后， SimpleDateFormat 是线程不安全的类，定义为 static 对象，会有数据同步风险。通过源码可以看出， SimpleDateFonnat 内部有一个 Calendar 对象，在日期转字符串或字符串转日期的过程中，多线程共享时有非常高的概率产生错误，推荐的方式之一就是使用 ThreadLocal，让每个线程单独拥有这个对象。示例代码如下：

```Java
private static final ThreadLocal<DataFormat> DATE_FORMAT_THREADLOCAL = new ThreadLocal<DateFormat>() {
    @Override
    protected DateFormat initialValue() {
        return new SimpleDataFormat("yyyy-MM-dd");
    }
}
```

#### Thread Local 副作用

ThreadLocal 的主要问题是会产生脏数据和内存泄漏。这两个问题通常是在线程池的线程中使用 ThreadLocal 引发的，因为线程池有线程复用和内存常驻两个特点。

1. 脏数据

线程复用会产生脏数据。由于线程池会重用 Thread 对象 ，那么与 Thread 绑定类的静态属性 ThreadLocal 变量也会被重用。如果在实现的线程 run() 方法体中不显式地调用 remove() 清理与线程相关的 ThreadLocal 信息，那么倘若下一个线程不调用set() 设置初始值，就可能 get() 到重用的线程信息，包括 ThreadLocal 所关联的线程对象的 value 值。

2. 内存泄漏

在源码注释中提示使用 static 关键字来修饰 ThreadLocal 。在此场景下 ，寄希望于 ThreadLocal 对象失去引用后，触发弱引用机制来回收 Entry 的 Value 就不现实了。在上例中，如果不进行 remove() 操作，那么这个线程执行完成后，通过 ThreadLocal 对象持有的 String 对象是不会被释放的。

以上两个问题的解决办法很简单，就是在每次用完 ThreadLocal 时， 必须要及时调用 remove() 进行清理。



# 第八章 单元测试

单元测试的目的是在集成测试和功能测试之前对软件中的可测试单元进行逐一检查和验证。单元测试是程序功能的基本保障，是软件产品上线前非常重要的一环。

单元测试的好处包括但不限于以下几点：
1. 提升软件质量

优质的单元测试可以保障开发质量和程序的鲁棒性。

软件工程界的一条金科玉律：越早发现的缺陷，其修复成本越低。一流的测试能发现未发生的故障；二流的测试能快速定位故障的发生点；三流的测试则疲于奔命，一直跟在故障后面进行功能回归。

2. 促进代码优化

单元测试是由开发工程师编写和维护的，这会促使开发工程师不断重新审视自己的代码，白盒地去思考代码逻辑，更好地对代码进行设计，甚至想方设法地优化测试用例的执行效率。

3. 提升研发效率

4. 增加重构自信

代码重构往往是牵一发而动全身的。当修改底层数据结构时，上层服务经常会受
到影响。有时候只是简单地修改一个字段名称，就会引起一系列错误。

## 8.1 单元测试的基本原则

宏观上，单元测试要符合 AIR 原则；微观上，单元测试的代码层面要符合 BCDE原则。

AIR 原则具体包括：

- A：Automatic（自动化）
- I：Independent（独立性）
- R：Repeatable（可重复）

单元测试中不允许使用 System.out 来进行人工验证，而必须使用断言来验证。

为了保证单元测试稳定可靠且便于维护，需要保证其独立性。用例之间不允许互相调用，也不允许出现执行次序的先后依赖。

在主流测试框架中， JUnit 的用例执行顺序是无序的，而 TestNG 支持测试用例的顺序执行（默认测试类内部各测试用例是按字典序升序执行的，也可以通过 XML 或 注解 priority 的方式来配置执行顺序）。

单元测试是可以重复执行的，不能受到外界环境的影响。

编写单元测试时要保证测试粒度足够小，这样有助于精确定位问题，单元测试用例默认是方法级别的。单测不负责检查跨类或者跨系统的交互逻辑，那是集成测试需要覆盖的范围。编写单元测试用例时，为了保证被测模块的交付质量，需要符合 BCDE 原则：

- B：Border，边界值测试，包括循环边界、特殊取值、特殊时间点、数据顺序等。
- C：Correct，正确的输入，并得到预期的结果。
- D：Design，与设计文档相结合，来编写单元测试。
- E：Error，单元测试的目标是证明程序有错，而不是程序无错。

进行Mock：

- 功能因素。比如被测试方法内部调用的功能不可用。
- 时间因素。比如双十一还没有到来，与此时间相关的功能点。
- 环境因素。政策环境，如支付宝政策类新功能，多端环境，如PC 、手机等。
- 数据因素。线下数据样本过小，难以覆盖各种线上真实场景。
- 其他因素。为了简化测试编写 开发者也可以将一些复杂的依赖采用 Mock
方式实现。

最简单的 Mock 方式是硬编码，更为优雅的方式是使用配置文件，最佳的方式是
使用相应的 Mock 框架，例如 JMockit、EasyMock、JMock 等。 Mock 的本质是让我们写出更加稳定的单元测试，隔离上述因素对单元测试的影响，使结果变得可预测，做到真正的“单元”测试。

## 8.2 单元测试覆盖率

1. 粗粒度的覆盖

粗粒度的覆盖包括类覆盖和方法覆盖两种。

2. 细粒度的覆盖

- 行覆盖（ Line Coverage ）

行覆盖也称为语句覆盖，用来度量可执行的语句是否被执行到。行覆盖率的计算公式的分子是执行到的语句行数，分母是总的可执行语句行数。行覆盖的覆盖强度并不高，但由于容易计算，因此在主流的覆盖率工具中，它依然是一个十分常见的参考指标。

- 分支覆盖（Branch Coverage）

分支覆盖也称为判定覆盖，用来度量程序中每一个判定分支是否都被执行到。分支覆盖率的计算公式中的分子是代码中被执行到的分支数，分母是代码中所有分支的总数。

- 条件判定覆盖（Condition Decision Coverage）

条件判定覆盖要求设计足够的测试用例，能够让判定中每个条件的所有可能情况至少被执行一次，同时每个判定本身的所有可能结果也至少执行一次。

＠CsvSource 注解使得我们可以通过定义一个 String 数组来定义多次运行测试时的参数列表，而每一个 String 值通过逗号分隔后的结果，就是每一次测试运行时的实际参数值。

分支覆盖只要求覆盖分支所有可能的结果，可以看出它是条件判定覆盖的一个子集。

- 条件组合覆盖

条件组合覆盖是指判定中所有条件的各种组合情况都出现至少一次。

对于一个包含了 n 个条件的判定，至少需要 2^n^ 个测试用例才可以。虽然这种覆盖足够严谨，但无疑给编写测试用例增加了指数级的工作量。

- 路径覆盖（Path Coverage）

路径覆盖要求能够测试到程序中所有可能的路径。

## 8.3 单元测试编写

#### JUnit 单元测试框架

JUnit5.x 由以下三个主要模块组成：

- JUnit Platform：用于在 JVM 上启动测试框架，统一命令行、 Gradle 和 Maven 等方式执行测试的入口。
- JUnit Jupiter：包含 JUnit5.x 全新的编程模型和扩展机制。
- JUnit Vintage：用于在新的框架中兼容运行 JUnit3.x 和 JUnit4.x 测试用例。

![1567169895599](E:\git_repo\Hao_Learn\2019\8\img\1567169895599.png) 

＠DisplayName 注解可以标注测试用例名，但仅仅对于采用 IDE 或图形化方式展示测试运行结果的场景有效

分组测试和数据驱动测试也是单元测试中十分实用的技巧。其中，分组测试能够实现测试在运行频率维度上的分层。通过@Tag ，并在 Maven 中配置以下设置实现：
```xml
<build>
    <plugins>
        <plugin>
            <artifactid>maven-surefire-plugin</artifactid>
            <version>2.22.0</version>
            <configuration>
                <properties>
                    <includeTags>fast</includeTags>
                    <excludeTags>slow</excludeTags>
                </properties>
            </configuration>
        </plugin>
    </plugins>
</build>
```


数据驱动测试适用于计算密集型的算法单元，这些功能单元内部逻辑复杂，对于不同的输入会得到截然不同的输出，通过＠TestFactory 注解可以实现。

```Java
@DisplayName("售票器类型测试")
public class ExchangeRateConverterTest {

    @TestFactory
    @DisplayName("时间售票检查")
    Stream<DynamicTest> oddNumberDynamicTestWithStream() {
    	ticketSeller.setCloseTime(LocalTime.of(l2, 20, 25, 0));
		return Stream.of(
			Lists.list("提前购票", LocalTime.of(12, 20, 24, 0), true),
			Lists.list("准点购买", Loca1Time.of(12, 20, 25, 0), true),
			Lists.list("晚点购票", Loca1Time.of(12, 20, 26, 0), false)
		)
		.map(data -> DynamicTest.dynamicTest((String)data.get(0),
			() -> assertThat(ticketSeller.cloudSellAt(data.get(l)))
			.isEqualTo(data.get(2)))); 
	}

}
```

#### 断言与假设

关注测试方法的细节处理， 这就离不开断言（assert）和假设（assume）：断言封装好了常用的判断逻辑 ，当不满足条件时，该测试用例会被认定为测试失败；假设与断言类似，只不过当条件不满足时，测试会直接退出而不是认定为测试失败，最终记录的状态是跳过。

常用的断言被封装在 org.junit.jupiter.api.Assertions 类中，均为静态方法：

![1567172813144](E:\git_repo\Hao_Learn\2019\8\img\1567172813144.png)

相较于断言，假设提供的静态方法更加简单，被封装在 org.junit.jupiter.api.Assumptions 类中，同样为静态方法：

![1567172874816](E:\git_repo\Hao_Learn\2019\8\img\1567172874816.png)

相对于假设，断言更为重要。这些断言方法中的大多数从 JUnit 的早期版本就已经存在，并且在最新的 JUnit 5.x 版本中依然保持着很好的兼容性。

对于断言的选择，优先采用更精确的断言。

对于非相等情况的判定，比如大于、小于或者更复杂的情况，可以使用 assertTrue 或 assertFalse 表达；对于特别复杂的条件判定，直接使用任何一种断言方法都不容易表达时，则可以使用 Java 语句自行构造条件，然后在不符合预期的情况下直接使用 fail 断言方法将测试标记为失败。

assertTimeout 和 assertTimeoutPreemptively 断言的差异在于，前者会在操作超时后继续执行，并在最终的测试报告中记录操作的实际执行时间；后者在到达指定时间后立即结束，在最终的报告中只体现出操作超时，但不包含实际执行的耗时。

断言负责验证逻辑 以及数据的合法性和完整性，所以有一种说法：“在单元测
试方法中没有断言就不是完整的测试”。

AssertJ 的最大特点是流式断言（Fluent Assertions），与 Builder Chain（构造链）模式或 Java8 的 stream&filter 写法类似。它允许一个目标对象通过各种 Fluent Assert API 的连接判断，进行多次断言，并且对 IDE 更友好。

AssertJ 的 assertThat 的处理方法和之前有些不同，它利用 Java 的泛型，而且增加了目标类型对应的 XxxxAssert 类，其签名为：`public static AbstractCharSequenceAssert<?, String> assertThat(String actual)`，而 JUnit 中的`public static void assertThat()`是 void 返回。

如果是我们自定义的 JavaBean 该如何判断？
1. AssertJ 通过 AssertJ assertions generator 来生成 对应的 XxxAssert 类
2. 辅助我们对模板 JavaBean 对象进行断言 API 判断。

![1567173574113](E:\git_repo\Hao_Learn\2019\8\img\1567173574113.png)

AssertJ 的断言代码要清爽许多，流式断言充分利用了 Java 8 之后的匿名方法和 Stream 类型的特点，很好地对 JUnit 断言方法进行了补充。
