# 2019.9.11

## 搭建Redis Cluster

```shell
# 安装ruby环境
yum -y install ruby
yum -y install rubygems

# 修改六个redis的配置文件
vi redis.conf
# 修改以下设置
daemonize yes
port * # 6401-6406
cluster-enabled yes

# 注意安装集群的时候，防火墙中不仅要开放redis的端口，而且需要开放集群总线端口,集群总线端口为redis客户端连接的端口 +10000

# 创建启动redis节点的脚本文件
vi start-all.sh
# 启动redis
cd redis1
./src/redis-server redis.conf
cd ..
cd redis2
./src/redis-server redis.conf
cd ..
cd redis3
./src/redis-server redis.conf
cd ..
cd redis4
./src/redis-server redis.conf
cd ..
cd redis5
./src/redis-server redis.conf
cd ..
cd redis6
./src/redis-server redis.conf
cd ..

# 创建创建redis集群的脚本文件
vi create-cluster.sh
# 创建redis集群
./redis1/src/redis-cli --cluster create 39.96.30.7:6401 39.96.30.7:6402 39.96.30.7:6403 39.96.30.7:6404 39.96.30.7:6405 39.96.30.7:6406 --cluster-replicas 1

# 创建关闭redis节点并删除集群信息的脚本文件
vi stop-all.sh
# 关闭redis
./redis1/src/redis-cli -h 172.16.42.3 -p 6401 shutdown
./redis2/src/redis-cli -h 172.16.42.3 -p 6402 shutdown
./redis3/src/redis-cli -h 172.16.42.3 -p 6403 shutdown
./redis4/src/redis-cli -h 172.16.42.3 -p 6404 shutdown
./redis5/src/redis-cli -h 172.16.42.3 -p 6405 shutdown
./redis6/src/redis-cli -h 172.16.42.3 -p 6406 shutdown

# 删除相关缓存文件
rm -f redis*/nodes.conf
rm -f redis*/dump.rdb
rm -f redis*/appendonly.aof

# 修改文件权限
chmod 777 start-all.sh stop-all.sh create-cluster.sh
-----

# 访问redis集群节点
./redis1/src/redis-cli -c -h 39.96.30.7 -p 6401
./redis1/src/redis-cli -c -h 172.16.42.3 -p 6401

cluster nodes
cluster info
```

#### 关于spring-redis

spring-data-redis针对jedis提供了如下功能：
```
1. 连接池自动管理，提供了一个高度封装的“RedisTemplate”类

2. 针对jedis客户端中大量api进行了归类封装,将同一类型操作封装为operation接口

ValueOperations：简单K-V操作
SetOperations：set类型数据操作
ZSetOperations：zset类型数据操作
HashOperations：针对map类型的数据操作
ListOperations：针对list类型的数据操作

3. 提供了对key的“bound”(绑定)便捷化操作API，可以通过bound封装指定的key，然后进行一系列的操作而无须“显式”的再次指定Key，即BoundKeyOperations：

BoundValueOperations
BoundSetOperations
BoundListOperations
BoundSetOperations
BoundHashOperations

4. 将事务操作封装，有容器控制。

5. 针对数据的“序列化/反序列化”，提供了多种可选择策略(RedisSerializer)

JdkSerializationRedisSerializer：POJO对象的存取场景，使用JDK本身序列化机制，将pojo类通过ObjectInputStream/ObjectOutputStream进行序列化操作，最终redis-server中将存储字节序列。是目前最常用的序列化策略。

StringRedisSerializer：Key或者value为字符串的场景，根据指定的charset对数据的字节序列编码成string，是“new String(bytes, charset)”和“string.getBytes(charset)”的直接封装。是最轻量级和高效的策略。

JacksonJsonRedisSerializer：jackson-json工具提供了javabean与json之间的转换能力，可以将pojo实例序列化成json格式存储在redis中，也可以将json格式的数据转换成pojo实例。因为jackson工具在序列化和反序列化时，需要明确指定Class类型，因此此策略封装起来稍微复杂。【需要jackson-mapper-asl工具支持】

OxmSerializer：提供了将javabean与xml之间的转换能力，目前可用的三方支持包括jaxb，apache-xmlbeans；redis存储的数据将是xml工具。不过使用此策略，编程将会有些难度，而且效率最低；不建议使用。【需要spring-oxm模块的支持】
```


#### 解决jedis和spring-data-redis导包版本不兼容问题

|jedis|spring-data-redis|spring|jdk|
|---|---|---|---|
|2.4.2|1.5.2.RELEASE|4.2.4.RELEASE|1.8|
|2.7.3|1.5.2.RELEAS|4.2.4.RELEASE|1.8|
|2.8.1|1.7.2.RELEASE|4.2.4.RELEASE|1.8|
|2.9.0|1.8.1.RELEASE|5.1.6.RELEASE|1.8|
|2.9.0|2.1.6.RELEASE|5.1.6.RELEASE|1.8|
|2.9.0|2.1.8.RELEASE|5.1.6.RELEASE|1.8|
|2.9.3|2.1.8.RELEASE|5.1.6.RELEASE|1.8|
|2.10.1|2.1.8.RELEASE|5.1.6.RELEASE|1.8|

#### 在Maven中添加依赖

```xml
<dependencies>
    <dependency>
    	<groupId>org.springframework.boot</groupId>
    	<artifactId>spring-boot-starter-data-redis</artifactId>
    </dependency>
    <dependency>
        <groupId>redis.clients</groupId>
        <artifactId>jedis</artifactId>
    </dependency>
</dependencies>
```

#### application.yml

```yml
#redis-cluster
spring:
  redis:
    cluster:
      timeout: 2000
      max-redirects: 100
      password:
      maxIdle: 200
      maxTotal: 1000
      maxWaitMillis: 2000
      testOnBorrow: true
      testOnReturn: true
      nodes: 39.96.30.7:6401, 39.96.30.7:6402, 39.96.30.7:6403, 39.96.30.7:6404, 39.96.30.7:6405, 39.96.30.7:6406
```


#### RedisCluster配置类

```Java
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.cache.annotation.CachingConfigurerSupport;
import org.springframework.cache.annotation.EnableCaching;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.DependsOn;
import org.springframework.core.env.MapPropertySource;
import org.springframework.data.redis.connection.RedisClusterConfiguration;
import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;
import redis.clients.jedis.JedisPoolConfig;

import java.util.HashMap;
import java.util.Map;

/**
 * Created by hao hao on 2019/9/9 0009.
 */
@Configuration
@EnableCaching
public class RedisClusterConfig extends CachingConfigurerSupport {

    private JedisPoolConfig poolConfig(int maxIdle, int maxTotal, long maxWaitMillis, boolean testOnBorrow,
                                       boolean testOnReturn) {
        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();
        jedisPoolConfig.setMaxIdle(maxIdle);
        jedisPoolConfig.setMaxTotal(maxTotal);
        jedisPoolConfig.setMaxWaitMillis(maxWaitMillis);
        jedisPoolConfig.setTestOnBorrow(testOnBorrow);
        jedisPoolConfig.setTestOnReturn(testOnReturn);
        return jedisPoolConfig;
    }

    private RedisClusterConfiguration redisCluterConfig(String clusterNodes, Long timeout, int redirects) {
        Map<String, Object> source = new HashMap<>();
        source.put("spring.redis.cluster.nodes", clusterNodes);
        source.put("spring.redis.cluster.timeout", timeout);
        source.put("spring.redis.cluster.max-redirects", redirects);
        return new RedisClusterConfiguration(new MapPropertySource("RedisClusterConfiguration", source));
    }

    @Bean(name = "redisConnectionFactory")
    public JedisConnectionFactory redisConnectionFactory(@Value("${spring.redis.cluster.timeout}") Long timeout,
                                                         @Value("${spring.redis.cluster.max-redirects}") int redirects,
                                                         @Value("${spring.redis.cluster.maxIdle}") int maxIdle,
                                                         @Value("${spring.redis.cluster.maxTotal}") int maxTotal,
                                                         @Value("${spring.redis.cluster.maxWaitMillis}") long maxWaitMillis,
                                                         @Value("${spring.redis.cluster.testOnBorrow}") boolean testOnBorrow,
                                                         @Value("${spring.redis.cluster.testOnReturn}") boolean testOnReturn,
                                                         @Value("${spring.redis.cluster.nodes}") String clusterNodes,
                                                         @Value("${spring.redis.cluster.password}") String password ) {
        JedisConnectionFactory connectionFactory = new JedisConnectionFactory(
                redisCluterConfig(clusterNodes, timeout, redirects),
                poolConfig(maxIdle, maxTotal, maxWaitMillis, testOnBorrow, testOnReturn));
        return connectionFactory;
    }

    @Bean(name = "stringRedisTemplate")
    public StringRedisTemplate stringRedisTemplate(@Qualifier("redisConnectionFactory") JedisConnectionFactory jedisConnectionFactory) {
        StringRedisTemplate template = new StringRedisTemplate();
        template.setConnectionFactory(jedisConnectionFactory);
        return template;
    }

    @SuppressWarnings("rawtypes")
    @Bean(name = "redisTemplate")
    @DependsOn("redisConnectionFactory")
    public RedisTemplate redisTemplate(JedisConnectionFactory redisConnectionFactory) {
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        template.setConnectionFactory(redisConnectionFactory);
        template.setKeySerializer(new GenericJackson2JsonRedisSerializer());
        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());
        template.setHashKeySerializer(new GenericJackson2JsonRedisSerializer());
        template.setHashValueSerializer(new GenericJackson2JsonRedisSerializer());
        return template;
    }
}
```

#### 通过 Jedis 实现的 RedisCluster 的工具类

```Java
package com.cc.kbms.utils;

import com.cc.kbms.domain.entity.KnowledgeHotspot;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.DefaultTypedTuple;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.data.redis.core.ZSetOperations;
import org.springframework.stereotype.Component;

import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;
import java.util.Set;


/**
 * Created by hao hao on 2019/9/9 0009.
 */
@Component
public class JedisClusterUtil {

    private static StringRedisTemplate stringRedisTemplate;
    private static RedisTemplate<String, Object> redisTemplate;
    private static ZSetOperations<String, Object> zSetOperations;

    @Autowired
    public JedisClusterUtil(StringRedisTemplate stringRedisTemplate, RedisTemplate<String, Object> redisTemplate) {
        JedisClusterUtil.stringRedisTemplate = stringRedisTemplate;
        JedisClusterUtil.redisTemplate = redisTemplate;
        JedisClusterUtil.zSetOperations = redisTemplate.opsForZSet();
    }

    /**
     * 将一个元素及其 score 值加入到有序集 key 当中。
     * @param key
     * @param value
     * @param score
     * @return
     */
    public static Boolean add(String key, String value, double score) {
        return zSetOperations.add(key, value, score);
    }

    /**
     * 将多个元素加入到有序集 key 当中。
     * @param key
     * @param tuples
     * @return
     */
    public static Long add(String key, Set<ZSetOperations.TypedTuple<Object>> tuples) {
        return zSetOperations.add(key, tuples);
    }

    /**
     * 为有序集 key 的成员 member 的 score 值加上增量 delta 。可以通过传递一个负数值 delta ，让 score 减去相应的值。
     * @param key
     * @param value
     * @param delta
     * @return 返回值为     member 成员的新 score 值
     */
    public static Double incrementScore(String key, String value, double delta){
        return zSetOperations.incrementScore(key, value, delta);
    }

    /**
     * 返回有序集 key 中，成员 member 的 score 值。
     * @param key
     * @param o
     * @return
     */
    public static Double score(String key, Object o) {
        return zSetOperations.score(key, o);
    }

    /**
     * 返回有序集 key 中成员 member 的排名。
     * @param key
     * @param o
     * @return
     */
    public static Long rank(String key, Object o) {
        return zSetOperations.rank(key, o);
    }

    /**
     * 返回有序集 key 的元素的数量。
     * @param key
     * @return
     */
    public static Long zCard(String key) {
        return zSetOperations.zCard(key);
    }

    /**
     * 按 score 值递增返回有序集 key 中，指定区间内的成员。
     * @param key
     * @param start
     * @param end
     * @return
     */
    public static Set<Object> range(String key, long start, long end) {
        return zSetOperations.range(key, start, end);
    }

    /**
     * 按 score 值递减返回有序集 key 中，指定区间内的成员。
     * @param key
     * @param start
     * @param end
     * @return
     */
    public static Set<ZSetOperations.TypedTuple<Object>> reverseRange(String key, long start, long end)  {
        return zSetOperations.reverseRangeWithScores(key, start, end);
    }

	/**
     * 将从Redis实时获取的TypedTuple转换成存放热点知识列表的List集合
     * @param tupleSet
     * @return
     */
    public static List<KnowledgeHotspot> tupleSetToHotspotList(Set<ZSetOperations.TypedTuple<Object>> tupleSet) {
        List<KnowledgeHotspot> knowledgeHotspots = new ArrayList<>();
        Iterator iterator = tupleSet.iterator();
        String kb_id;
        Double kb_query_rate;
        while (iterator.hasNext()){
            // 获取下一条数据
            DefaultTypedTuple<Object> defaultTypedTuple = (DefaultTypedTuple<Object>) iterator.next();
            // 获取知识ID和查询频率
            kb_id = defaultTypedTuple.getValue().toString();
            kb_query_rate = defaultTypedTuple.getScore();
            knowledgeHotspots.add(new KnowledgeHotspot().setKb_id(kb_id).setKb_query_rate(kb_query_rate));
        }
        return knowledgeHotspots;
    }

    /**
     * 返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。
     * @param key
     * @param min
     * @param max
     * @param offset
     * @param count
     * @return
     */
    public static Set<Object> reverseRangeByScore(String key, double min, double max, long offset, long count)  {
        return zSetOperations.reverseRangeByScore(key, min, max, offset, count);
    }


    /**
     * 移除有序集 key 中的一个或多个成员，不存在的成员将被忽略。
     * @param key
     * @param values
     * @return 返回值为被成功移除的成员的数量，不包括被忽略的成员。
     */
    public static Long remove(String key, Object... values) {
        return zSetOperations.remove(key, values);
    }

    /**
     * 移除有序集 key 中，指定排名(rank)区间内的所有成员。
     * @param key
     * @param start
     * @param end
     * @return 返回值为被成功移除的成员的数量。
     */
    public static Long removeRange(String key, long start, long end) {
        return zSetOperations.removeRange(key, start, end);
    }

    /**
     * 移除有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。
     * @param key
     * @param min
     * @param max
     * @return 返回值为被成功移除的成员的数量。
     */
    public static Long removeRangeByScore(String key, double min, double max) {
        return zSetOperations.removeRangeByScore(key, min ,max);
    }

}
```

#### 数据处理的一些例子

```Java
/**
     * 获取Redis中的实时热点知识
     * @param count
     * @return
     */
    List<Map<String, Object>> getHotspotsInRedis(Long count) {
        List<Map<String, Object>> list = new ArrayList<>();
        // 获取Redis中的数据
        Set<ZSetOperations.TypedTuple<Object>> tupleSet = JedisClusterUtil.reverseRange(hotspotSetKey, 0L, count - 1);
        // 将数据转换成List
        List<KnowledgeHotspot> knowledgeHotspots = JedisClusterUtil.tupleSetToHotspotList(tupleSet);
        // 在数据库中查询对应的知识，此时的顺序是按照Score排序的
        list = knowledgeHotspotService.findByList(knowledgeHotspots);
        // 检测Redis和数据库中的知识是否同步
        if(knowledgeHotspots.size() == list.size()){
            for (int i = 0; i < list.size(); i++) {
                list.get(i).put("kb_query_rate", knowledgeHotspots.get(i).getKb_query_rate());
            }
        }else{  //不同步时，需要根据数据库中的数据进行整合
//          // 使用Redis数据的list构建一个键为知识id，值为热点知识实体类的map
            Map<String, KnowledgeHotspot> tempMap = knowledgeHotspots.stream().collect(Collectors.toMap(KnowledgeHotspot::getKb_id, Function.identity()));
            // 遍历数据库数据并为每一条数据添加其热点查询频率，由于在数据库查询时就是按照热点查询频率排序所以不需要改变list的顺序
            list.stream().forEach(item -> item.put("kb_query_rate", tempMap.get(item.get("id")).getKb_query_rate()));
        }
        return list;
    }
```

#### 注解缓存的使用

@Cacheable：在方法执行前Spring先查看缓存中是否有数据，如果有数据，则直接返回缓存数据；没有则调用方法并将方法返回值放进缓存。
@CachePut：将方法的返回值放到缓存中。
@CacheEvict：删除缓存中的数据。

## Linux查看文件指定行数内容

```shell

tail date.log               	# 输出文件末尾的内容，默认10行
tail -20  date.log       		# 输出最后20行的内容
tail -n -20  date.log    		# 输出倒数第20行到文件末尾的内容
tail -n +20  date.log   		# 输出第20行到文件末尾的内容
tail -f date.log                # 实时监控文件内容增加，默认10行。

head date.log           		# 输出文件开头的内容，默认10行
head -15  date.log     			# 输出开头15行的内容
head -n +15 date.log 			# 输出开头到第15行的内容
head -n -15 date.log  			# 输出开头到倒数第15行的内容

# tail 和 head 加上 -n 参数后 都代表输出到指定行数
# tail 是指定行数到结尾，head是开头到指定行数
# +数字 代表整数第几行，-数字 代表倒数第几行

# sed -n "开始行，结束行p" 文件名    
sed -n '70,75p' date.log        # 输出第70行到第75行的内容
sed -n '6p;260,400p;' 文件名     # 输出第6行 和 260到400行
sed -n 5p 文件名                 # 输出第5行
```

总结：
cat 	从第一行開始显示档案内容。
tac 	从最后一行開始显示档案内容。

more      分页显示档案内容。
less	与 more 相似，但支持向前翻页

head       仅仅显示前面几行
tail          仅仅显示后面几行

n             带行号显示档案内容
od           以二进制方式显示档案内容

sed         显示指定行数的文档

## java中的 if(){} 和 if(){}else if(){} 的区别

1. 在java当中，如果两个if判断同级，if判断条件的代码都会去判断，不管前面的if判断条件是否成立，都会去判断执行下一个if的代码。
2. 如果是if()else if(){}的话，当前面的if判断条件成立的话，就不会再去判断else if的条件，有多个else if的时候，会去挨个进行判断，只要有一个符合条件，后面的else if都不会再去判断，当前面的判断条件都没成立，并且结尾有一个else，就会执行最后else中的代码。

## Spring中使用@Autowired注解静态实例对象

将@Autowired 注解到类的构造函数上。很好理解，Spring扫描到AutowiredTypeComponent的bean，然后赋给静态变量component。记得配置包扫描注解@ComponentScan。

```Java
@Component
public class TestClass {

    private static AutowiredTypeComponent component;

    @Autowired
    public TestClass(AutowiredTypeComponent component) {
        TestClass.component = component;
    }

}
```

## 定时任务

```Java
package com.cc.kbms.schedule;

import com.cc.common.exception.CcException;
import com.cc.common.utils.CcDateUtil;
import com.cc.kbms.domain.entity.KnowledgeHotspot;
import com.cc.kbms.service.KnowledgeHotspotService;
import com.cc.kbms.utils.JedisClusterUtil;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.data.redis.core.ZSetOperations;
import org.springframework.scheduling.annotation.EnableScheduling;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

import java.util.List;
import java.util.Set;

/**
 * Created by hao hao on 2019/9/10 0010.
 *
 * 热点知识查询条数
 * hotspot-count: 100
 * 
 * 每日凌晨一点执行定时任务，并清理缓存
 * hotspot-cron: 0 0 1 * * *
 * 
 * Redis集群中，热点知识Set集合的Key
 * hotspot-key: Hotspot
 */
 
@Slf4j
@Component
@EnableScheduling
public class KnowledgeHotspotScheduled {

    @Autowired
    KnowledgeHotspotService knowledgeHotspotService;

    @Value("${knowledge.hotspot-key}") 
    private String hotspotSetKey;

    @Value("${knowledge.hotspot-count}")
    private Integer hotspotCount = 100; // 热点知识查询条数，默认为100条


    /**
     * 定时任务，每日指定时间[knowledge.latest-cron]执行，
     * 清除超出设定值[knowledge.latest-count]的最新知识记录
     */
    @Scheduled(cron = "${knowledge.hotspot-cron}")
    public void execute() throws CcException {
        log.info(">> [scheduled]读取配置文件，knowledge.hotspot-count={}", hotspotCount);

        Set<ZSetOperations.TypedTuple<Object>> tupleSet = JedisClusterUtil.reverseRange(hotspotSetKey, 0L, hotspotCount.longValue() - 1);
        if (tupleSet.size() < hotspotCount) {
            log.info(">> [scheduled]热点知识条数小于设定的hotspotCount，不需要进行删除操作！");
            return;
        }

        // MaxScore
        Double maxScore = tupleSet.iterator().next().getScore();
        log.info(">> [scheduled]热点知识的最大查询频率是{}", maxScore);
        Double minScore = 0.0;

        // 清空缓存
        // JedisClusterUtil.removeRangeByScore(hotspotSetKey, minScore, maxScore);

        // 获取需要添加的集合
        List<KnowledgeHotspot> knowledgeHotspots = JedisClusterUtil.tupleSetToHotspotList(tupleSet);

        // 先清空再存储在数据库中
        int deleteCount = knowledgeHotspotService.deleteHotspotBelowKbQueryRate(maxScore);
        knowledgeHotspotService.addHotspotList(knowledgeHotspots);
        String currentTime = CcDateUtil.getTime();
        log.info(">> [scheduled]已删除历史热点数据 {} 条，插入最新热点数据 {} 条，执行完成时间为 {}", deleteCount, knowledgeHotspots.size(), currentTime);
    }
}

```

## mysql in查询保持in集合顺序

```sql
select * from table 
where id IN (3,6,9,1,2,5,8,7) 
order by field(id,3,6,9,1,2,5,8,7); 
```